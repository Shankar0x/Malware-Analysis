{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 11:31:22.002197: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-10 11:31:22.218752: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-10 11:31:22.858277: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/cudnn-8.4/8.4/lib64:/cm/local/apps/cuda/libs/current/lib64:/cm/shared/apps/cuda11.2/toolkit/11.2.0/targets/x86_64-linux/lib:/cm/local/apps/gcc/7.2.0/lib:/cm/local/apps/gcc/7.2.0/lib64:/home/ok_sikha/anaconda3/envs/tf_gpu_segnet/lib/\n",
      "2023-02-10 11:31:22.858362: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/cudnn-8.4/8.4/lib64:/cm/local/apps/cuda/libs/current/lib64:/cm/shared/apps/cuda11.2/toolkit/11.2.0/targets/x86_64-linux/lib:/cm/local/apps/gcc/7.2.0/lib:/cm/local/apps/gcc/7.2.0/lib64:/home/ok_sikha/anaconda3/envs/tf_gpu_segnet/lib/\n",
      "2023-02-10 11:31:22.858373: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has been created in the same format as AFD dataset. The columns are the port numbers associated with each hash values. \n",
    "\n",
    "For a corresponding hash and port number, the cell will contain the proportion of times that hash has invoked that particular port number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hash</th>\n",
       "      <th>443</th>\n",
       "      <th>80</th>\n",
       "      <th>8080</th>\n",
       "      <th>53</th>\n",
       "      <th>123</th>\n",
       "      <th>22</th>\n",
       "      <th>138</th>\n",
       "      <th>5938</th>\n",
       "      <th>5353</th>\n",
       "      <th>...</th>\n",
       "      <th>445</th>\n",
       "      <th>49687</th>\n",
       "      <th>1433</th>\n",
       "      <th>139</th>\n",
       "      <th>3446</th>\n",
       "      <th>5190</th>\n",
       "      <th>8886</th>\n",
       "      <th>10</th>\n",
       "      <th>3331</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0287E8B45AA0DA648018C2646589D914.csv</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0489FCE05A991A539AC3DDAFA8543D31.csv</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OneDrive.lnk.csv</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>046E51DD65D775956F933E8DDCD162F9.csv</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XboxGameBar.lnk.csv</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 236 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Hash       443        80      8080  \\\n",
       "0  0287E8B45AA0DA648018C2646589D914.csv  0.250000  0.250000  0.083333   \n",
       "1  0489FCE05A991A539AC3DDAFA8543D31.csv  0.166667  0.250000  0.083333   \n",
       "2                      OneDrive.lnk.csv  0.172414  0.482759  0.000000   \n",
       "3  046E51DD65D775956F933E8DDCD162F9.csv  0.307692  0.076923  0.000000   \n",
       "4                   XboxGameBar.lnk.csv  0.229167  0.250000  0.000000   \n",
       "\n",
       "         53       123        22       138      5938      5353  ...  445  \\\n",
       "0  0.083333  0.083333  0.083333  0.083333  0.083333  0.000000  ...  0.0   \n",
       "1  0.083333  0.083333  0.166667  0.083333  0.083333  0.000000  ...  0.0   \n",
       "2  0.068966  0.034483  0.034483  0.034483  0.034483  0.034483  ...  0.0   \n",
       "3  0.269231  0.038462  0.038462  0.038462  0.038462  0.038462  ...  0.0   \n",
       "4  0.208333  0.020833  0.020833  0.020833  0.020833  0.020833  ...  0.0   \n",
       "\n",
       "   49687  1433  139  3446  5190  8886   10  3331  Labels  \n",
       "0    0.0   0.0  0.0   0.0   0.0   0.0  0.0   0.0       0  \n",
       "1    0.0   0.0  0.0   0.0   0.0   0.0  0.0   0.0       0  \n",
       "2    0.0   0.0  0.0   0.0   0.0   0.0  0.0   0.0       0  \n",
       "3    0.0   0.0  0.0   0.0   0.0   0.0  0.0   0.0       0  \n",
       "4    0.0   0.0  0.0   0.0   0.0   0.0  0.0   0.0       0  \n",
       "\n",
       "[5 rows x 236 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loding NTD Dataset\n",
    "df = pd.read_csv('NTD_Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>443</th>\n",
       "      <th>80</th>\n",
       "      <th>8080</th>\n",
       "      <th>53</th>\n",
       "      <th>123</th>\n",
       "      <th>22</th>\n",
       "      <th>138</th>\n",
       "      <th>5938</th>\n",
       "      <th>5353</th>\n",
       "      <th>1900</th>\n",
       "      <th>...</th>\n",
       "      <th>445</th>\n",
       "      <th>49687</th>\n",
       "      <th>1433</th>\n",
       "      <th>139</th>\n",
       "      <th>3446</th>\n",
       "      <th>5190</th>\n",
       "      <th>8886</th>\n",
       "      <th>10</th>\n",
       "      <th>3331</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 235 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        443        80      8080        53       123        22       138  \\\n",
       "0  0.250000  0.250000  0.083333  0.083333  0.083333  0.083333  0.083333   \n",
       "1  0.166667  0.250000  0.083333  0.083333  0.083333  0.166667  0.083333   \n",
       "2  0.172414  0.482759  0.000000  0.068966  0.034483  0.034483  0.034483   \n",
       "3  0.307692  0.076923  0.000000  0.269231  0.038462  0.038462  0.038462   \n",
       "4  0.229167  0.250000  0.000000  0.208333  0.020833  0.020833  0.020833   \n",
       "\n",
       "       5938      5353      1900  ...  445  49687  1433  139  3446  5190  8886  \\\n",
       "0  0.083333  0.000000  0.000000  ...  0.0    0.0   0.0  0.0   0.0   0.0   0.0   \n",
       "1  0.083333  0.000000  0.000000  ...  0.0    0.0   0.0  0.0   0.0   0.0   0.0   \n",
       "2  0.034483  0.034483  0.034483  ...  0.0    0.0   0.0  0.0   0.0   0.0   0.0   \n",
       "3  0.038462  0.038462  0.038462  ...  0.0    0.0   0.0  0.0   0.0   0.0   0.0   \n",
       "4  0.020833  0.020833  0.020833  ...  0.0    0.0   0.0  0.0   0.0   0.0   0.0   \n",
       "\n",
       "    10  3331  Labels  \n",
       "0  0.0   0.0       0  \n",
       "1  0.0   0.0       0  \n",
       "2  0.0   0.0       0  \n",
       "3  0.0   0.0       0  \n",
       "4  0.0   0.0       0  \n",
       "\n",
       "[5 rows x 235 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the Hash column from the dataset\n",
    "df = df.drop('Hash', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>443</th>\n",
       "      <th>80</th>\n",
       "      <th>8080</th>\n",
       "      <th>53</th>\n",
       "      <th>123</th>\n",
       "      <th>22</th>\n",
       "      <th>138</th>\n",
       "      <th>5938</th>\n",
       "      <th>5353</th>\n",
       "      <th>1900</th>\n",
       "      <th>...</th>\n",
       "      <th>3333</th>\n",
       "      <th>445</th>\n",
       "      <th>49687</th>\n",
       "      <th>1433</th>\n",
       "      <th>139</th>\n",
       "      <th>3446</th>\n",
       "      <th>5190</th>\n",
       "      <th>8886</th>\n",
       "      <th>10</th>\n",
       "      <th>3331</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>757 rows Ã— 234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          443        80      8080        53       123        22       138  \\\n",
       "0    0.250000  0.250000  0.083333  0.083333  0.083333  0.083333  0.083333   \n",
       "1    0.166667  0.250000  0.083333  0.083333  0.083333  0.166667  0.083333   \n",
       "2    0.172414  0.482759  0.000000  0.068966  0.034483  0.034483  0.034483   \n",
       "3    0.307692  0.076923  0.000000  0.269231  0.038462  0.038462  0.038462   \n",
       "4    0.229167  0.250000  0.000000  0.208333  0.020833  0.020833  0.020833   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "752  0.200000  0.100000  0.100000  0.100000  0.100000  0.200000  0.100000   \n",
       "753  0.153846  0.076923  0.076923  0.230769  0.076923  0.153846  0.076923   \n",
       "754  0.000000  0.000000  0.000000  0.111111  0.000000  0.222222  0.111111   \n",
       "755  0.200000  0.100000  0.100000  0.100000  0.100000  0.200000  0.100000   \n",
       "756  0.187500  0.187500  0.062500  0.062500  0.062500  0.125000  0.062500   \n",
       "\n",
       "         5938      5353      1900  ...  3333       445  49687    1433  139  \\\n",
       "0    0.083333  0.000000  0.000000  ...   0.0  0.000000    0.0  0.0000  0.0   \n",
       "1    0.083333  0.000000  0.000000  ...   0.0  0.000000    0.0  0.0000  0.0   \n",
       "2    0.034483  0.034483  0.034483  ...   0.0  0.000000    0.0  0.0000  0.0   \n",
       "3    0.038462  0.038462  0.038462  ...   0.0  0.000000    0.0  0.0000  0.0   \n",
       "4    0.020833  0.020833  0.020833  ...   0.0  0.000000    0.0  0.0000  0.0   \n",
       "..        ...       ...       ...  ...   ...       ...    ...     ...  ...   \n",
       "752  0.100000  0.000000  0.000000  ...   0.0  0.000000    0.0  0.0000  0.0   \n",
       "753  0.076923  0.000000  0.000000  ...   0.0  0.076923    0.0  0.0000  0.0   \n",
       "754  0.000000  0.000000  0.000000  ...   0.0  0.000000    0.0  0.0000  0.0   \n",
       "755  0.100000  0.000000  0.000000  ...   0.0  0.000000    0.0  0.0000  0.0   \n",
       "756  0.062500  0.000000  0.000000  ...   0.0  0.000000    0.0  0.0625  0.0   \n",
       "\n",
       "     3446  5190  8886   10    3331  \n",
       "0     0.0   0.0   0.0  0.0  0.0000  \n",
       "1     0.0   0.0   0.0  0.0  0.0000  \n",
       "2     0.0   0.0   0.0  0.0  0.0000  \n",
       "3     0.0   0.0   0.0  0.0  0.0000  \n",
       "4     0.0   0.0   0.0  0.0  0.0000  \n",
       "..    ...   ...   ...  ...     ...  \n",
       "752   0.0   0.0   0.0  0.0  0.0000  \n",
       "753   0.0   0.0   0.0  0.0  0.0000  \n",
       "754   0.0   0.0   0.0  0.0  0.0000  \n",
       "755   0.0   0.0   0.0  0.0  0.0000  \n",
       "756   0.0   0.0   0.0  0.0  0.0625  \n",
       "\n",
       "[757 rows x 234 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,:-1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "752    1\n",
       "753    1\n",
       "754    1\n",
       "755    1\n",
       "756    1\n",
       "Name: Labels, Length: 757, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Labels']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605, 234)\n",
      "(605,)\n",
      "(152, 234)\n",
      "(152,)\n"
     ]
    }
   ],
   "source": [
    "# Do TTS\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "x_train, x_test, y_train, y_test = tts(X,y,test_size=0.2) \n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "\n",
    "This is a shallow neural network with 3 layers. Smaller neural network preferred over deeper one because of the lack of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 5)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 40)                240       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                820       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,081\n",
      "Trainable params: 1,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 11:31:41.002425: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-10 11:31:41.722783: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14493 MB memory:  -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:3b:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(5,))\n",
    "\n",
    "x = tf.keras.layers.Dense(40,activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dense(20,activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs,outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "224/224 [==============================] - 2s 6ms/step - loss: 1104061.5000 - accuracy: 0.5489 - val_loss: 596438.3125 - val_accuracy: 0.5109\n",
      "Epoch 2/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 141457.9219 - accuracy: 0.5573 - val_loss: 3572.3159 - val_accuracy: 0.5395\n",
      "Epoch 3/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 557.2422 - accuracy: 0.5384 - val_loss: 0.6786 - val_accuracy: 0.6275\n",
      "Epoch 4/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 1.4193 - accuracy: 0.5897 - val_loss: 0.6727 - val_accuracy: 0.5972\n",
      "Epoch 5/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6725 - accuracy: 0.5894 - val_loss: 0.6710 - val_accuracy: 0.5983\n",
      "Epoch 6/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6722 - accuracy: 0.5932 - val_loss: 0.6699 - val_accuracy: 0.6017\n",
      "Epoch 7/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6698 - accuracy: 0.5902 - val_loss: 0.6688 - val_accuracy: 0.6017\n",
      "Epoch 8/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6701 - accuracy: 0.5929 - val_loss: 0.6681 - val_accuracy: 0.6000\n",
      "Epoch 9/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 225.8417 - accuracy: 0.5916 - val_loss: 0.6689 - val_accuracy: 0.5994\n",
      "Epoch 10/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6710 - accuracy: 0.5895 - val_loss: 0.6685 - val_accuracy: 0.6011\n",
      "Epoch 11/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6712 - accuracy: 0.5908 - val_loss: 0.6676 - val_accuracy: 0.5966\n",
      "Epoch 12/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6693 - accuracy: 0.5913 - val_loss: 0.6669 - val_accuracy: 0.6011\n",
      "Epoch 13/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6683 - accuracy: 0.5902 - val_loss: 0.6664 - val_accuracy: 0.6017\n",
      "Epoch 14/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6673 - accuracy: 0.5922 - val_loss: 0.6668 - val_accuracy: 0.6022\n",
      "Epoch 15/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6669 - accuracy: 0.5915 - val_loss: 0.6657 - val_accuracy: 0.5978\n",
      "Epoch 16/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6686 - accuracy: 0.5902 - val_loss: 0.6654 - val_accuracy: 0.6022\n",
      "Epoch 17/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.9686 - accuracy: 0.5933 - val_loss: 0.6643 - val_accuracy: 0.6000\n",
      "Epoch 18/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6689 - accuracy: 0.5926 - val_loss: 0.6637 - val_accuracy: 0.6017\n",
      "Epoch 19/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6670 - accuracy: 0.5919 - val_loss: 0.6627 - val_accuracy: 0.6028\n",
      "Epoch 20/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6665 - accuracy: 0.5971 - val_loss: 0.6617 - val_accuracy: 0.6062\n",
      "Epoch 21/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6656 - accuracy: 0.5944 - val_loss: 0.6615 - val_accuracy: 0.6045\n",
      "Epoch 22/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6671 - accuracy: 0.5922 - val_loss: 0.6619 - val_accuracy: 0.6017\n",
      "Epoch 23/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6661 - accuracy: 0.5933 - val_loss: 0.6610 - val_accuracy: 0.6028\n",
      "Epoch 24/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6669 - accuracy: 0.5909 - val_loss: 0.6624 - val_accuracy: 0.6022\n",
      "Epoch 25/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6660 - accuracy: 0.5930 - val_loss: 0.6611 - val_accuracy: 0.6022\n",
      "Epoch 26/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6645 - accuracy: 0.5934 - val_loss: 0.6608 - val_accuracy: 0.6017\n",
      "Epoch 27/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6643 - accuracy: 0.5936 - val_loss: 0.6602 - val_accuracy: 0.6028\n",
      "Epoch 28/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6655 - accuracy: 0.5927 - val_loss: 0.6601 - val_accuracy: 0.6022\n",
      "Epoch 29/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6633 - accuracy: 0.5930 - val_loss: 0.6598 - val_accuracy: 0.6006\n",
      "Epoch 30/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6637 - accuracy: 0.5937 - val_loss: 0.6590 - val_accuracy: 0.6028\n",
      "Epoch 31/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6637 - accuracy: 0.5934 - val_loss: 0.6596 - val_accuracy: 0.6028\n",
      "Epoch 32/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6628 - accuracy: 0.5958 - val_loss: 0.6575 - val_accuracy: 0.6039\n",
      "Epoch 33/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6610 - accuracy: 0.5946 - val_loss: 0.6562 - val_accuracy: 0.6045\n",
      "Epoch 34/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6599 - accuracy: 0.5940 - val_loss: 0.6556 - val_accuracy: 0.6039\n",
      "Epoch 35/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6576 - accuracy: 0.5943 - val_loss: 0.6537 - val_accuracy: 0.6078\n",
      "Epoch 36/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6580 - accuracy: 0.5975 - val_loss: 0.6541 - val_accuracy: 0.6034\n",
      "Epoch 37/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6574 - accuracy: 0.5954 - val_loss: 0.6529 - val_accuracy: 0.6034\n",
      "Epoch 38/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6558 - accuracy: 0.5964 - val_loss: 0.6517 - val_accuracy: 0.6039\n",
      "Epoch 39/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6551 - accuracy: 0.5988 - val_loss: 0.6488 - val_accuracy: 0.6134\n",
      "Epoch 40/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6527 - accuracy: 0.6037 - val_loss: 0.6478 - val_accuracy: 0.6123\n",
      "Epoch 41/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6505 - accuracy: 0.6048 - val_loss: 0.6476 - val_accuracy: 0.6067\n",
      "Epoch 42/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6512 - accuracy: 0.5999 - val_loss: 0.6463 - val_accuracy: 0.6056\n",
      "Epoch 43/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6496 - accuracy: 0.5983 - val_loss: 0.6447 - val_accuracy: 0.6062\n",
      "Epoch 44/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6467 - accuracy: 0.6023 - val_loss: 0.6442 - val_accuracy: 0.6062\n",
      "Epoch 45/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6486 - accuracy: 0.5968 - val_loss: 0.6431 - val_accuracy: 0.6073\n",
      "Epoch 46/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6456 - accuracy: 0.6000 - val_loss: 0.6416 - val_accuracy: 0.6073\n",
      "Epoch 47/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6445 - accuracy: 0.6023 - val_loss: 0.6409 - val_accuracy: 0.6067\n",
      "Epoch 48/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6519 - accuracy: 0.5992 - val_loss: 0.6422 - val_accuracy: 0.6045\n",
      "Epoch 49/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6455 - accuracy: 0.6009 - val_loss: 0.6397 - val_accuracy: 0.6045\n",
      "Epoch 50/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6435 - accuracy: 0.6002 - val_loss: 0.6395 - val_accuracy: 0.6050\n",
      "Epoch 51/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6457 - accuracy: 0.5939 - val_loss: 0.6384 - val_accuracy: 0.6062\n",
      "Epoch 52/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6427 - accuracy: 0.6016 - val_loss: 0.6394 - val_accuracy: 0.6067\n",
      "Epoch 53/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6420 - accuracy: 0.6010 - val_loss: 0.6390 - val_accuracy: 0.6078\n",
      "Epoch 54/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6407 - accuracy: 0.6034 - val_loss: 0.6372 - val_accuracy: 0.6062\n",
      "Epoch 55/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6400 - accuracy: 0.6024 - val_loss: 0.6369 - val_accuracy: 0.6078\n",
      "Epoch 56/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6432 - accuracy: 0.6010 - val_loss: 0.6360 - val_accuracy: 0.6062\n",
      "Epoch 57/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6401 - accuracy: 0.6021 - val_loss: 0.6358 - val_accuracy: 0.6073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6415 - accuracy: 0.6025 - val_loss: 0.6359 - val_accuracy: 0.6062\n",
      "Epoch 59/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6401 - accuracy: 0.6000 - val_loss: 0.6346 - val_accuracy: 0.6073\n",
      "Epoch 60/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6408 - accuracy: 0.6054 - val_loss: 0.6356 - val_accuracy: 0.6073\n",
      "Epoch 61/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6398 - accuracy: 0.6033 - val_loss: 0.6351 - val_accuracy: 0.6084\n",
      "Epoch 62/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6403 - accuracy: 0.6037 - val_loss: 0.6366 - val_accuracy: 0.6213\n",
      "Epoch 63/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6461 - accuracy: 0.6010 - val_loss: 0.6356 - val_accuracy: 0.6140\n",
      "Epoch 64/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6378 - accuracy: 0.6066 - val_loss: 0.6352 - val_accuracy: 0.6090\n",
      "Epoch 65/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6388 - accuracy: 0.6017 - val_loss: 0.6356 - val_accuracy: 0.6090\n",
      "Epoch 66/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6482 - accuracy: 0.6068 - val_loss: 0.6344 - val_accuracy: 0.6190\n",
      "Epoch 67/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6413 - accuracy: 0.6045 - val_loss: 0.6355 - val_accuracy: 0.6190\n",
      "Epoch 68/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6397 - accuracy: 0.6023 - val_loss: 0.6347 - val_accuracy: 0.6207\n",
      "Epoch 69/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6392 - accuracy: 0.6020 - val_loss: 0.6359 - val_accuracy: 0.6202\n",
      "Epoch 70/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6396 - accuracy: 0.6035 - val_loss: 0.6348 - val_accuracy: 0.6207\n",
      "Epoch 71/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6378 - accuracy: 0.6079 - val_loss: 0.6325 - val_accuracy: 0.6202\n",
      "Epoch 72/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6418 - accuracy: 0.6073 - val_loss: 0.6323 - val_accuracy: 0.6196\n",
      "Epoch 73/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6400 - accuracy: 0.6110 - val_loss: 0.6322 - val_accuracy: 0.6190\n",
      "Epoch 74/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6396 - accuracy: 0.6094 - val_loss: 0.6324 - val_accuracy: 0.6196\n",
      "Epoch 75/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6417 - accuracy: 0.6094 - val_loss: 0.6332 - val_accuracy: 0.6202\n",
      "Epoch 76/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6390 - accuracy: 0.6111 - val_loss: 0.6325 - val_accuracy: 0.6202\n",
      "Epoch 77/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6393 - accuracy: 0.6105 - val_loss: 0.6330 - val_accuracy: 0.6202\n",
      "Epoch 78/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6398 - accuracy: 0.6108 - val_loss: 0.6331 - val_accuracy: 0.6190\n",
      "Epoch 79/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6407 - accuracy: 0.6111 - val_loss: 0.6332 - val_accuracy: 0.6190\n",
      "Epoch 80/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6407 - accuracy: 0.6094 - val_loss: 0.6328 - val_accuracy: 0.6224\n",
      "Epoch 81/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6409 - accuracy: 0.6121 - val_loss: 0.6320 - val_accuracy: 0.6207\n",
      "Epoch 82/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6393 - accuracy: 0.6133 - val_loss: 0.6316 - val_accuracy: 0.6207\n",
      "Epoch 83/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6371 - accuracy: 0.6110 - val_loss: 0.6322 - val_accuracy: 0.6190\n",
      "Epoch 84/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6414 - accuracy: 0.6105 - val_loss: 0.6316 - val_accuracy: 0.6196\n",
      "Epoch 85/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6413 - accuracy: 0.6079 - val_loss: 0.6313 - val_accuracy: 0.6207\n",
      "Epoch 86/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6423 - accuracy: 0.6083 - val_loss: 0.6315 - val_accuracy: 0.6213\n",
      "Epoch 87/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6392 - accuracy: 0.6105 - val_loss: 0.6347 - val_accuracy: 0.6207\n",
      "Epoch 88/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6429 - accuracy: 0.6100 - val_loss: 0.6329 - val_accuracy: 0.6196\n",
      "Epoch 89/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6399 - accuracy: 0.6098 - val_loss: 0.6331 - val_accuracy: 0.6207\n",
      "Epoch 90/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6376 - accuracy: 0.6117 - val_loss: 0.6325 - val_accuracy: 0.6218\n",
      "Epoch 91/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6402 - accuracy: 0.6115 - val_loss: 0.6344 - val_accuracy: 0.6207\n",
      "Epoch 92/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6383 - accuracy: 0.6122 - val_loss: 0.6343 - val_accuracy: 0.6207\n",
      "Epoch 93/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6383 - accuracy: 0.6107 - val_loss: 0.6331 - val_accuracy: 0.6218\n",
      "Epoch 94/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6383 - accuracy: 0.6122 - val_loss: 0.6328 - val_accuracy: 0.6218\n",
      "Epoch 95/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6375 - accuracy: 0.6119 - val_loss: 0.6339 - val_accuracy: 0.6218\n",
      "Epoch 96/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6387 - accuracy: 0.6122 - val_loss: 0.6347 - val_accuracy: 0.6263\n",
      "Epoch 97/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6381 - accuracy: 0.6110 - val_loss: 0.6304 - val_accuracy: 0.6207\n",
      "Epoch 98/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6383 - accuracy: 0.6105 - val_loss: 0.6310 - val_accuracy: 0.6207\n",
      "Epoch 99/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6381 - accuracy: 0.6104 - val_loss: 0.6320 - val_accuracy: 0.6230\n",
      "Epoch 100/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6375 - accuracy: 0.6110 - val_loss: 0.6311 - val_accuracy: 0.6218\n",
      "70/70 - 0s - loss: 0.6247 - accuracy: 0.6186 - 174ms/epoch - 2ms/step\n",
      "Test loss:  0.6246729493141174\n",
      "Test accuracy:  0.6185566782951355\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=100, validation_split=0.2)\n",
    "test_score = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss: \", test_score[0])\n",
    "print(\"Test accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 5)]               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               768       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 4)                 36        \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 94,374\n",
      "Trainable params: 94,374\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(5,))\n",
    "\n",
    "x = tf.keras.layers.Dense(128,activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(64,activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(32,activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(16,activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(8,activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(4,activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(2,activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs,outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "224/224 [==============================] - 2s 8ms/step - loss: 230.8671 - accuracy: 0.5014 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 2/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 3/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 4/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 5/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5006 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 6/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 7/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5008 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 8/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 9/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 10/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 11/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 12/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5014 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 13/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 14/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 15/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 16/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 17/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 18/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 19/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5014 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 20/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 21/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5008 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 22/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 23/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 24/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 25/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 26/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 27/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 28/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 29/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 30/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.4944 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 31/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 32/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 33/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 34/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 35/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 36/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 37/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 38/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 39/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 40/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 41/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 42/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.4952 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 43/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 44/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 45/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 46/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 47/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 48/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 49/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 50/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 51/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 52/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 53/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 54/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.4994 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 55/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 56/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 57/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 59/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 60/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 61/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5011 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 62/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 63/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5011 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 64/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 65/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 66/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5006 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 67/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 68/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 69/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 70/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 71/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 72/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 73/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 74/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 75/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 76/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 77/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 78/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 79/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 80/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 81/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 82/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 83/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5017 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 84/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 85/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 86/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 87/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 88/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 89/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 90/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 91/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 92/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5011 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 93/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 94/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 95/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 96/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 97/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 98/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6931 - accuracy: 0.5017 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 99/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 100/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "70/70 - 0s - loss: 0.6936 - accuracy: 0.4841 - 231ms/epoch - 3ms/step\n",
      "Test loss:  0.6936006546020508\n",
      "Test accuracy:  0.48408785462379456\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=100, validation_split=0.2)\n",
    "test_score = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss: \", test_score[0])\n",
    "print(\"Test accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 5)]               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 2000)              12000     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1000)              2001000   \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 500)               500500    \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 100)               50100     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 10)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 2)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,564,632\n",
      "Trainable params: 2,564,632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(5,))\n",
    "\n",
    "x = tf.keras.layers.Dense(2000,activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dense(1000,activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(500,activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(100,activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(10,activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(2,activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs,outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "224/224 [==============================] - 2s 6ms/step - loss: 10765.0303 - accuracy: 0.4979 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 2/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 3/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 4/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 5/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 6/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 7/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 8/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 9/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 10/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 11/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 12/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 13/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 14/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 15/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 16/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 17/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 18/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 19/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 20/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6934 - val_accuracy: 0.4986\n",
      "Epoch 21/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 22/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 23/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 24/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 25/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 26/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 27/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 28/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 29/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 30/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 31/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 32/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 33/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 34/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5014 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 35/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 36/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 37/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 38/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5020 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 39/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 40/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 41/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6931 - accuracy: 0.5006 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 42/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 43/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 44/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 45/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 46/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5028 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 47/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 48/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 49/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 50/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 51/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 52/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 53/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 54/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 55/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 56/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 57/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 59/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 60/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 61/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 62/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 63/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 64/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 65/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 66/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5014 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 67/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 68/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 69/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 70/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 71/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 72/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 73/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 74/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 75/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 76/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 77/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 78/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 79/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 80/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 81/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 82/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 83/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 84/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5017 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 85/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6931 - accuracy: 0.5036 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 86/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 87/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 88/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 89/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6934 - val_accuracy: 0.4986\n",
      "Epoch 90/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 91/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 92/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 93/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 94/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 95/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 96/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 97/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 98/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.4986\n",
      "Epoch 99/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "Epoch 100/100\n",
      "224/224 [==============================] - 1s 6ms/step - loss: 0.6932 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.4986\n",
      "70/70 - 0s - loss: 0.6933 - accuracy: 0.4841 - 206ms/epoch - 3ms/step\n",
      "Test loss:  0.6933283805847168\n",
      "Test accuracy:  0.48408785462379456\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=100, validation_split=0.2)\n",
    "test_score = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss: \", test_score[0])\n",
    "print(\"Test accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that this method is not giving good results. This could be directly arrtibuted to the lack of data. \n",
    "\n",
    "There are 234 columns but only 757 rows. Hence the models are unable to classify benignware and malware with this scarce information alone. Need => More data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4f5c1426ea6378ce27c73cf8ba7b159bf97b2caa18fb16fe687269a4604e900"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
