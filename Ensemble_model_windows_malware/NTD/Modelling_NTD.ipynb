{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5766814c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37ef5cf",
   "metadata": {},
   "source": [
    "From the previous approach from \"Failed_Modelling_NTD.ipynb\" it is clear that lack of data led to poor performance. Hence the raw dataframe can be preprocessed and fit in a neural network. \n",
    "\n",
    "This is done in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28848aca",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d75307e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DestIP</th>\n",
       "      <th>Dport</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>number_of_flows</th>\n",
       "      <th>average_of_duration</th>\n",
       "      <th>standard_deviation_duration</th>\n",
       "      <th>percent_of_standard_deviation_duration</th>\n",
       "      <th>total_size_of_flows_orig</th>\n",
       "      <th>total_size_of_flows_resp</th>\n",
       "      <th>ratio_of_sizes</th>\n",
       "      <th>...</th>\n",
       "      <th>dns_success_vowelchangeratio</th>\n",
       "      <th>dns_noerror</th>\n",
       "      <th>dns_nxdomain</th>\n",
       "      <th>dns_othererrors</th>\n",
       "      <th>dns_status_ratio</th>\n",
       "      <th>cert_subject</th>\n",
       "      <th>cert_issuer</th>\n",
       "      <th>Src_P</th>\n",
       "      <th>Dest_IP</th>\n",
       "      <th>Dest_P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.921680e+11</td>\n",
       "      <td>443.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.683142</td>\n",
       "      <td>0.962513</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>7106</td>\n",
       "      <td>35509</td>\n",
       "      <td>4.997045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.012602e+10</td>\n",
       "      <td>443.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.539588</td>\n",
       "      <td>0.028155</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>22045</td>\n",
       "      <td>71284</td>\n",
       "      <td>3.233568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CN=graph.windows.net</td>\n",
       "      <td>CN=DigiCert SHA2 Secure Server CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.921680e+11</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.019783</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>754</td>\n",
       "      <td>1580</td>\n",
       "      <td>2.095491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.921680e+11</td>\n",
       "      <td>8080.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>172</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.127907</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.921680e+11</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.012315</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>1051</td>\n",
       "      <td>1568</td>\n",
       "      <td>1.491912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11149</th>\n",
       "      <td>1.922292e+11</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>48.828145</td>\n",
       "      <td>0.511401</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11150</th>\n",
       "      <td>2.132272e+11</td>\n",
       "      <td>5938.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>115.190587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>144</td>\n",
       "      <td>72</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11151</th>\n",
       "      <td>2.019017e+10</td>\n",
       "      <td>443.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>89.115231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20365</td>\n",
       "      <td>45444</td>\n",
       "      <td>2.231476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11152</th>\n",
       "      <td>1.170182e+11</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>48.608211</td>\n",
       "      <td>0.024178</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11153</th>\n",
       "      <td>2.019707e+10</td>\n",
       "      <td>443.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>120.100360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>514</td>\n",
       "      <td>907</td>\n",
       "      <td>1.764591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11154 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             DestIP   Dport  Protocol  number_of_flows  average_of_duration  \\\n",
       "0      1.921680e+11   443.0       1.0               25             0.683142   \n",
       "1      4.012602e+10   443.0       1.0                4             0.539588   \n",
       "2      1.921680e+11    80.0       1.0                5             0.019783   \n",
       "3      1.921680e+11  8080.0       1.0              172             0.000033   \n",
       "4      1.921680e+11    53.0       2.0               25             0.012315   \n",
       "...             ...     ...       ...              ...                  ...   \n",
       "11149  1.922292e+11    80.0       1.0                2            48.828145   \n",
       "11150  2.132272e+11  5938.0       1.0                1           115.190587   \n",
       "11151  2.019017e+10   443.0       1.0                1            89.115231   \n",
       "11152  1.170182e+11    80.0       1.0                2            48.608211   \n",
       "11153  2.019707e+10   443.0       1.0                1           120.100360   \n",
       "\n",
       "       standard_deviation_duration  percent_of_standard_deviation_duration  \\\n",
       "0                         0.962513                                0.320000   \n",
       "1                         0.028155                                0.250000   \n",
       "2                         0.001679                                0.400000   \n",
       "3                         0.000006                                0.127907   \n",
       "4                         0.002622                                0.120000   \n",
       "...                            ...                                     ...   \n",
       "11149                     0.511401                                0.000000   \n",
       "11150                     0.000000                                0.000000   \n",
       "11151                     0.000000                                0.000000   \n",
       "11152                     0.024178                                0.500000   \n",
       "11153                     0.000000                                0.000000   \n",
       "\n",
       "       total_size_of_flows_orig  total_size_of_flows_resp  ratio_of_sizes  \\\n",
       "0                          7106                     35509        4.997045   \n",
       "1                         22045                     71284        3.233568   \n",
       "2                           754                      1580        2.095491   \n",
       "3                             0                         0       -1.000000   \n",
       "4                          1051                      1568        1.491912   \n",
       "...                         ...                       ...             ...   \n",
       "11149                         0                         2       -1.000000   \n",
       "11150                       144                        72        0.500000   \n",
       "11151                     20365                     45444        2.231476   \n",
       "11152                         0                         2       -1.000000   \n",
       "11153                       514                       907        1.764591   \n",
       "\n",
       "       ...  dns_success_vowelchangeratio  dns_noerror  dns_nxdomain  \\\n",
       "0      ...                           0.0          0.0           0.0   \n",
       "1      ...                           0.0          0.0           0.0   \n",
       "2      ...                           0.0          0.0           0.0   \n",
       "3      ...                           0.0          0.0           0.0   \n",
       "4      ...                           0.0         25.0           0.0   \n",
       "...    ...                           ...          ...           ...   \n",
       "11149  ...                           0.0          0.0           0.0   \n",
       "11150  ...                           0.0          0.0           0.0   \n",
       "11151  ...                           0.0          0.0           0.0   \n",
       "11152  ...                           0.0          0.0           0.0   \n",
       "11153  ...                           0.0          0.0           0.0   \n",
       "\n",
       "       dns_othererrors  dns_status_ratio          cert_subject  \\\n",
       "0                  0.0               0.0                     -   \n",
       "1                  0.0               0.0  CN=graph.windows.net   \n",
       "2                  0.0               0.0                   NaN   \n",
       "3                  0.0               0.0                   NaN   \n",
       "4                  0.0               0.0                   NaN   \n",
       "...                ...               ...                   ...   \n",
       "11149              0.0               0.0                   NaN   \n",
       "11150              0.0               0.0                   NaN   \n",
       "11151              0.0               0.0                   NaN   \n",
       "11152              0.0               0.0                   NaN   \n",
       "11153              0.0               0.0                   NaN   \n",
       "\n",
       "                             cert_issuer  Src_P  Dest_IP  Dest_P  \n",
       "0                                      -    NaN      NaN     NaN  \n",
       "1      CN=DigiCert SHA2 Secure Server CA    NaN      NaN     NaN  \n",
       "2                                    NaN    NaN      NaN     NaN  \n",
       "3                                    NaN    NaN      NaN     NaN  \n",
       "4                                    NaN    NaN      NaN     NaN  \n",
       "...                                  ...    ...      ...     ...  \n",
       "11149                                NaN    NaN      NaN     NaN  \n",
       "11150                                NaN    NaN      NaN     NaN  \n",
       "11151                                NaN    NaN      NaN     NaN  \n",
       "11152                                NaN    NaN      NaN     NaN  \n",
       "11153                                NaN    NaN      NaN     NaN  \n",
       "\n",
       "[11154 rows x 105 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sun4rowNetworknormal_backdoortrain_Dataclubbed.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1087a91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DestIP</th>\n",
       "      <th>Dport</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>number_of_flows</th>\n",
       "      <th>average_of_duration</th>\n",
       "      <th>standard_deviation_duration</th>\n",
       "      <th>percent_of_standard_deviation_duration</th>\n",
       "      <th>total_size_of_flows_orig</th>\n",
       "      <th>total_size_of_flows_resp</th>\n",
       "      <th>ratio_of_sizes</th>\n",
       "      <th>...</th>\n",
       "      <th>dns_success_vowelchangeratio</th>\n",
       "      <th>dns_noerror</th>\n",
       "      <th>dns_nxdomain</th>\n",
       "      <th>dns_othererrors</th>\n",
       "      <th>dns_status_ratio</th>\n",
       "      <th>cert_subject</th>\n",
       "      <th>cert_issuer</th>\n",
       "      <th>Src_P</th>\n",
       "      <th>Dest_IP</th>\n",
       "      <th>Dest_P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.921680e+11</td>\n",
       "      <td>443.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.683142</td>\n",
       "      <td>0.962513</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>7106</td>\n",
       "      <td>35509</td>\n",
       "      <td>4.997045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.012602e+10</td>\n",
       "      <td>443.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.539588</td>\n",
       "      <td>0.028155</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>22045</td>\n",
       "      <td>71284</td>\n",
       "      <td>3.233568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CN=graph.windows.net</td>\n",
       "      <td>CN=DigiCert SHA2 Secure Server CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.921680e+11</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.019783</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>754</td>\n",
       "      <td>1580</td>\n",
       "      <td>2.095491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.921680e+11</td>\n",
       "      <td>8080.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>172</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.127907</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.921680e+11</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.012315</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>1051</td>\n",
       "      <td>1568</td>\n",
       "      <td>1.491912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DestIP   Dport  Protocol  number_of_flows  average_of_duration  \\\n",
       "0  1.921680e+11   443.0       1.0               25             0.683142   \n",
       "1  4.012602e+10   443.0       1.0                4             0.539588   \n",
       "2  1.921680e+11    80.0       1.0                5             0.019783   \n",
       "3  1.921680e+11  8080.0       1.0              172             0.000033   \n",
       "4  1.921680e+11    53.0       2.0               25             0.012315   \n",
       "\n",
       "   standard_deviation_duration  percent_of_standard_deviation_duration  \\\n",
       "0                     0.962513                                0.320000   \n",
       "1                     0.028155                                0.250000   \n",
       "2                     0.001679                                0.400000   \n",
       "3                     0.000006                                0.127907   \n",
       "4                     0.002622                                0.120000   \n",
       "\n",
       "   total_size_of_flows_orig  total_size_of_flows_resp  ratio_of_sizes  ...  \\\n",
       "0                      7106                     35509        4.997045  ...   \n",
       "1                     22045                     71284        3.233568  ...   \n",
       "2                       754                      1580        2.095491  ...   \n",
       "3                         0                         0       -1.000000  ...   \n",
       "4                      1051                      1568        1.491912  ...   \n",
       "\n",
       "   dns_success_vowelchangeratio  dns_noerror  dns_nxdomain  dns_othererrors  \\\n",
       "0                           0.0          0.0           0.0              0.0   \n",
       "1                           0.0          0.0           0.0              0.0   \n",
       "2                           0.0          0.0           0.0              0.0   \n",
       "3                           0.0          0.0           0.0              0.0   \n",
       "4                           0.0         25.0           0.0              0.0   \n",
       "\n",
       "   dns_status_ratio          cert_subject                        cert_issuer  \\\n",
       "0               0.0                     -                                  -   \n",
       "1               0.0  CN=graph.windows.net  CN=DigiCert SHA2 Secure Server CA   \n",
       "2               0.0                   NaN                                NaN   \n",
       "3               0.0                   NaN                                NaN   \n",
       "4               0.0                   NaN                                NaN   \n",
       "\n",
       "   Src_P  Dest_IP  Dest_P  \n",
       "0    NaN      NaN     NaN  \n",
       "1    NaN      NaN     NaN  \n",
       "2    NaN      NaN     NaN  \n",
       "3    NaN      NaN     NaN  \n",
       "4    NaN      NaN     NaN  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['full_label', 'label', 'method', 'goal', 'family_gene', 'keylog', 'bkdoor',\n",
    "                     'infosteal', 'rootkits', 'method_encoded', 'goal_encoded',\n",
    "                     'family_encoded', 'infosteal_encoded', \"hash\", \"fileno\"],axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43be0192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DestIP</th>\n",
       "      <th>Dport</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>number_of_flows</th>\n",
       "      <th>average_of_duration</th>\n",
       "      <th>standard_deviation_duration</th>\n",
       "      <th>percent_of_standard_deviation_duration</th>\n",
       "      <th>total_size_of_flows_orig</th>\n",
       "      <th>total_size_of_flows_resp</th>\n",
       "      <th>ratio_of_sizes</th>\n",
       "      <th>...</th>\n",
       "      <th>dns_success_specialcharratio</th>\n",
       "      <th>dns_success_caseratio</th>\n",
       "      <th>dns_success_vowelchangeratio</th>\n",
       "      <th>dns_noerror</th>\n",
       "      <th>dns_nxdomain</th>\n",
       "      <th>dns_othererrors</th>\n",
       "      <th>dns_status_ratio</th>\n",
       "      <th>Src_P</th>\n",
       "      <th>Dest_IP</th>\n",
       "      <th>Dest_P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.921680e+11</td>\n",
       "      <td>443.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.683142</td>\n",
       "      <td>0.962513</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>7106</td>\n",
       "      <td>35509</td>\n",
       "      <td>4.997045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.012602e+10</td>\n",
       "      <td>443.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.539588</td>\n",
       "      <td>0.028155</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>22045</td>\n",
       "      <td>71284</td>\n",
       "      <td>3.233568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.921680e+11</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.019783</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>754</td>\n",
       "      <td>1580</td>\n",
       "      <td>2.095491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.921680e+11</td>\n",
       "      <td>8080.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>172</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.127907</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.921680e+11</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.012315</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>1051</td>\n",
       "      <td>1568</td>\n",
       "      <td>1.491912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DestIP   Dport  Protocol  number_of_flows  average_of_duration  \\\n",
       "0  1.921680e+11   443.0       1.0               25             0.683142   \n",
       "1  4.012602e+10   443.0       1.0                4             0.539588   \n",
       "2  1.921680e+11    80.0       1.0                5             0.019783   \n",
       "3  1.921680e+11  8080.0       1.0              172             0.000033   \n",
       "4  1.921680e+11    53.0       2.0               25             0.012315   \n",
       "\n",
       "   standard_deviation_duration  percent_of_standard_deviation_duration  \\\n",
       "0                     0.962513                                0.320000   \n",
       "1                     0.028155                                0.250000   \n",
       "2                     0.001679                                0.400000   \n",
       "3                     0.000006                                0.127907   \n",
       "4                     0.002622                                0.120000   \n",
       "\n",
       "   total_size_of_flows_orig  total_size_of_flows_resp  ratio_of_sizes  ...  \\\n",
       "0                      7106                     35509        4.997045  ...   \n",
       "1                     22045                     71284        3.233568  ...   \n",
       "2                       754                      1580        2.095491  ...   \n",
       "3                         0                         0       -1.000000  ...   \n",
       "4                      1051                      1568        1.491912  ...   \n",
       "\n",
       "   dns_success_specialcharratio  dns_success_caseratio  \\\n",
       "0                           0.0                    0.0   \n",
       "1                           0.0                    0.0   \n",
       "2                           0.0                    0.0   \n",
       "3                           0.0                    0.0   \n",
       "4                           0.0                    0.0   \n",
       "\n",
       "   dns_success_vowelchangeratio  dns_noerror  dns_nxdomain  dns_othererrors  \\\n",
       "0                           0.0          0.0           0.0              0.0   \n",
       "1                           0.0          0.0           0.0              0.0   \n",
       "2                           0.0          0.0           0.0              0.0   \n",
       "3                           0.0          0.0           0.0              0.0   \n",
       "4                           0.0         25.0           0.0              0.0   \n",
       "\n",
       "   dns_status_ratio  Src_P  Dest_IP  Dest_P  \n",
       "0               0.0    NaN      NaN     NaN  \n",
       "1               0.0    NaN      NaN     NaN  \n",
       "2               0.0    NaN      NaN     NaN  \n",
       "3               0.0    NaN      NaN     NaN  \n",
       "4               0.0    NaN      NaN     NaN  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop([\"family_label\", 'url', 'url_query_names', 'url_query_values', 'path', 'filename', 'hostname', 'sni', 'cert_subject', 'cert_issuer', '#Src_IP'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6561f4",
   "metadata": {},
   "source": [
    "Preprocessing Strategy \n",
    "\n",
    "1. List all the columns which contains a null value \n",
    "2. If the column is having numerical values, fill it with the mean of all the values in that column \n",
    "3. If the column is having objects then drop such records all together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98592351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dns_nxdomain_vowelchangeratio',\n",
       " 'dns_success_digitratio',\n",
       " 'dns_success_alpharatio',\n",
       " 'dns_success_specialcharratio',\n",
       " 'dns_success_caseratio',\n",
       " 'dns_nxdomain',\n",
       " 'dns_noerror',\n",
       " 'dns_status_ratio',\n",
       " 'dns_othererrors',\n",
       " 'dns_nxdomain_caseratio',\n",
       " 'dns_success_vowelchangeratio',\n",
       " 'dns_nxdomain_specialcharratio',\n",
       " 'DestIP',\n",
       " 'dns_nxdomain_digitratio',\n",
       " 'sni_vowelchangeratio',\n",
       " 'sni_caseratio',\n",
       " 'sni_specialcharratio',\n",
       " 'sni_alpharatio',\n",
       " 'sni_digitratio',\n",
       " 'sportcounts',\n",
       " 'service',\n",
       " 'Protocol',\n",
       " 'Dport',\n",
       " 'dns_nxdomain_alpharatio',\n",
       " 'Dest_IP',\n",
       " 'Src_P',\n",
       " 'Dest_P']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_list = df.isna().sum()\n",
    "null_list = null_list.sort_values()\n",
    "null_columns = []\n",
    "for i in range(null_list.size):\n",
    "    if null_list[i]!=0:\n",
    "        null_columns.append(null_list.index[i])\n",
    "null_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e4824ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list_1 = ['dns_nxdomain_vowelchangeratio',\n",
    " 'dns_success_digitratio',\n",
    " 'dns_success_alpharatio',\n",
    " 'dns_success_specialcharratio',\n",
    " 'dns_success_caseratio',\n",
    " 'dns_nxdomain',\n",
    " 'dns_noerror',\n",
    " 'dns_status_ratio',\n",
    " 'dns_othererrors',\n",
    " 'dns_nxdomain_caseratio',\n",
    " 'dns_success_vowelchangeratio',\n",
    " 'dns_nxdomain_specialcharratio',\n",
    " 'dns_nxdomain_digitratio',\n",
    " 'sni_vowelchangeratio',\n",
    " 'sni_caseratio',\n",
    " 'sni_specialcharratio',\n",
    " 'sni_alpharatio',\n",
    " 'sni_digitratio',\n",
    " 'sportcounts','dns_nxdomain_alpharatio',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a7ac12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0410695576040144\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.7018792191205985\n",
      "0.0\n",
      "1.832147418354315\n",
      "0.0\n",
      "0.0\n",
      "0.016259395896288834\n",
      "0.017986888449964204\n",
      "0.04889333619291095\n",
      "0.0\n",
      "0.013015530484760477\n",
      "0.08005693009050409\n",
      "6.747739226025187e-05\n",
      "25.777595329319468\n",
      "0.05734284172563148\n"
     ]
    }
   ],
   "source": [
    "for i in col_list_1:\n",
    "    mean_value = df[i].mean()\n",
    "    print(mean_value)\n",
    "    df[i].fillna(value=mean_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c13a02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DestIP', 'Protocol', 'Dport', 'service', 'Dest_IP', 'Src_P', 'Dest_P']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_list = df.isna().sum()\n",
    "null_list = null_list.sort_values()\n",
    "null_columns = []\n",
    "for i in range(null_list.size):\n",
    "    if null_list[i]!=0:\n",
    "        null_columns.append(null_list.index[i])\n",
    "null_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1170804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DestIP                            0\n",
      "Dport                             0\n",
      "Protocol                        192\n",
      "number_of_flows                   0\n",
      "average_of_duration               0\n",
      "                               ... \n",
      "dns_success_vowelchangeratio      0\n",
      "dns_noerror                       0\n",
      "dns_nxdomain                      0\n",
      "dns_othererrors                   0\n",
      "dns_status_ratio                  0\n",
      "Length: 76, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DestIP</th>\n",
       "      <th>Dport</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>number_of_flows</th>\n",
       "      <th>average_of_duration</th>\n",
       "      <th>standard_deviation_duration</th>\n",
       "      <th>percent_of_standard_deviation_duration</th>\n",
       "      <th>total_size_of_flows_orig</th>\n",
       "      <th>total_size_of_flows_resp</th>\n",
       "      <th>ratio_of_sizes</th>\n",
       "      <th>...</th>\n",
       "      <th>dns_nxdomain_vowelchangeratio</th>\n",
       "      <th>dns_success_digitratio</th>\n",
       "      <th>dns_success_alpharatio</th>\n",
       "      <th>dns_success_specialcharratio</th>\n",
       "      <th>dns_success_caseratio</th>\n",
       "      <th>dns_success_vowelchangeratio</th>\n",
       "      <th>dns_noerror</th>\n",
       "      <th>dns_nxdomain</th>\n",
       "      <th>dns_othererrors</th>\n",
       "      <th>dns_status_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.921680e+11</td>\n",
       "      <td>443.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.683142</td>\n",
       "      <td>0.962513</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>7106</td>\n",
       "      <td>35509</td>\n",
       "      <td>4.997045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.012602e+10</td>\n",
       "      <td>443.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.539588</td>\n",
       "      <td>0.028155</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>22045</td>\n",
       "      <td>71284</td>\n",
       "      <td>3.233568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.921680e+11</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.019783</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>754</td>\n",
       "      <td>1580</td>\n",
       "      <td>2.095491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.921680e+11</td>\n",
       "      <td>8080.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>172</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.127907</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.921680e+11</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25</td>\n",
       "      <td>0.012315</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>1051</td>\n",
       "      <td>1568</td>\n",
       "      <td>1.491912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.511084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         DestIP   Dport  Protocol  number_of_flows  average_of_duration  \\\n",
       "0  1.921680e+11   443.0       1.0               25             0.683142   \n",
       "1  4.012602e+10   443.0       1.0                4             0.539588   \n",
       "2  1.921680e+11    80.0       1.0                5             0.019783   \n",
       "3  1.921680e+11  8080.0       1.0              172             0.000033   \n",
       "4  1.921680e+11    53.0       2.0               25             0.012315   \n",
       "\n",
       "   standard_deviation_duration  percent_of_standard_deviation_duration  \\\n",
       "0                     0.962513                                0.320000   \n",
       "1                     0.028155                                0.250000   \n",
       "2                     0.001679                                0.400000   \n",
       "3                     0.000006                                0.127907   \n",
       "4                     0.002622                                0.120000   \n",
       "\n",
       "   total_size_of_flows_orig  total_size_of_flows_resp  ratio_of_sizes  ...  \\\n",
       "0                      7106                     35509        4.997045  ...   \n",
       "1                     22045                     71284        3.233568  ...   \n",
       "2                       754                      1580        2.095491  ...   \n",
       "3                         0                         0       -1.000000  ...   \n",
       "4                      1051                      1568        1.491912  ...   \n",
       "\n",
       "   dns_nxdomain_vowelchangeratio  dns_success_digitratio  \\\n",
       "0                       0.000000                     0.0   \n",
       "1                       0.000000                     0.0   \n",
       "2                       0.000000                     0.0   \n",
       "3                       0.000000                     0.0   \n",
       "4                       0.511084                     0.0   \n",
       "\n",
       "   dns_success_alpharatio  dns_success_specialcharratio  \\\n",
       "0                     0.0                           0.0   \n",
       "1                     0.0                           0.0   \n",
       "2                     0.0                           0.0   \n",
       "3                     0.0                           0.0   \n",
       "4                     0.0                           0.0   \n",
       "\n",
       "   dns_success_caseratio  dns_success_vowelchangeratio  dns_noerror  \\\n",
       "0                    0.0                           0.0          0.0   \n",
       "1                    0.0                           0.0          0.0   \n",
       "2                    0.0                           0.0          0.0   \n",
       "3                    0.0                           0.0          0.0   \n",
       "4                    0.0                           0.0         25.0   \n",
       "\n",
       "   dns_nxdomain  dns_othererrors  dns_status_ratio  \n",
       "0           0.0              0.0               0.0  \n",
       "1           0.0              0.0               0.0  \n",
       "2           0.0              0.0               0.0  \n",
       "3           0.0              0.0               0.0  \n",
       "4           0.0              0.0               0.0  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.DestIP.fillna(df.Src_P, inplace=True)\n",
    "df.Dport.fillna(df.Dest_IP, inplace=True)\n",
    "df.sportcounts.fillna(df.Dest_P, inplace=True)\n",
    "df.drop(['Src_P','Dest_IP','Dest_P'],axis=1,inplace=True)\n",
    "print(df.isna().sum())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b17c7817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['service', 'Protocol']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_list = df.isna().sum()\n",
    "null_list = null_list.sort_values()\n",
    "null_columns = []\n",
    "for i in range(null_list.size):\n",
    "    if null_list[i]!=0:\n",
    "        null_columns.append(null_list.index[i])\n",
    "null_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32bface5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0454857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y=df['binarylabel']\n",
    "X=df.drop(['binarylabel'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414edb9b",
   "metadata": {},
   "source": [
    "Scaling all the numerical values in the dataframe between 0 and 1. This step helps the loss function to converge faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe5dd28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8348a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8769, 75)\n",
      "(8769,)\n",
      "(2193, 75)\n",
      "(2193,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84090509",
   "metadata": {},
   "source": [
    "### Model fitting\n",
    "\n",
    "The model chosen here is a shallow neural network with just 3 layers and ReLU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9798582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81096b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 75)]              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 40)                3040      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 20)                820       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,881\n",
      "Trainable params: 3,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(75,))\n",
    "\n",
    "x = tf.keras.layers.Dense(40,activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dense(20,activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs,outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8ba4d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8834814d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ok_sikha/anaconda3/envs/tf_gpu_segnet/lib/python3.9/site-packages/keras/backend.py:5673: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 3s 12ms/step - loss: 0.6551 - accuracy: 0.6182 - val_loss: 0.6225 - val_accuracy: 0.6807\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.6040 - accuracy: 0.6801 - val_loss: 0.5740 - val_accuracy: 0.7275\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.5678 - accuracy: 0.7120 - val_loss: 0.5460 - val_accuracy: 0.7457\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.5463 - accuracy: 0.7202 - val_loss: 0.5293 - val_accuracy: 0.7417\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.5297 - accuracy: 0.7327 - val_loss: 0.5140 - val_accuracy: 0.7452\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.5193 - accuracy: 0.7428 - val_loss: 0.5083 - val_accuracy: 0.7463\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.5084 - accuracy: 0.7411 - val_loss: 0.4960 - val_accuracy: 0.7514\n",
      "Epoch 8/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.5006 - accuracy: 0.7517 - val_loss: 0.4815 - val_accuracy: 0.7691\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4956 - accuracy: 0.7540 - val_loss: 0.4785 - val_accuracy: 0.7605\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4875 - accuracy: 0.7562 - val_loss: 0.4849 - val_accuracy: 0.7463\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4834 - accuracy: 0.7530 - val_loss: 0.4683 - val_accuracy: 0.7719\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4735 - accuracy: 0.7631 - val_loss: 0.4646 - val_accuracy: 0.7685\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4725 - accuracy: 0.7585 - val_loss: 0.4599 - val_accuracy: 0.7685\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4675 - accuracy: 0.7692 - val_loss: 0.4589 - val_accuracy: 0.7777\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4646 - accuracy: 0.7639 - val_loss: 0.4559 - val_accuracy: 0.7731\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4606 - accuracy: 0.7696 - val_loss: 0.4564 - val_accuracy: 0.7725\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4580 - accuracy: 0.7689 - val_loss: 0.4552 - val_accuracy: 0.7839\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4561 - accuracy: 0.7662 - val_loss: 0.4444 - val_accuracy: 0.7731\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4504 - accuracy: 0.7695 - val_loss: 0.4459 - val_accuracy: 0.7754\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4488 - accuracy: 0.7733 - val_loss: 0.4518 - val_accuracy: 0.7657\n",
      "Epoch 21/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4465 - accuracy: 0.7711 - val_loss: 0.4444 - val_accuracy: 0.7771\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4438 - accuracy: 0.7743 - val_loss: 0.4387 - val_accuracy: 0.7834\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4412 - accuracy: 0.7738 - val_loss: 0.4481 - val_accuracy: 0.7702\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4409 - accuracy: 0.7731 - val_loss: 0.4432 - val_accuracy: 0.7719\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4355 - accuracy: 0.7773 - val_loss: 0.4474 - val_accuracy: 0.7657\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4383 - accuracy: 0.7716 - val_loss: 0.4504 - val_accuracy: 0.7662\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4352 - accuracy: 0.7756 - val_loss: 0.4339 - val_accuracy: 0.7839\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4351 - accuracy: 0.7779 - val_loss: 0.4362 - val_accuracy: 0.7782\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4318 - accuracy: 0.7792 - val_loss: 0.4289 - val_accuracy: 0.7816\n",
      "Epoch 30/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4325 - accuracy: 0.7778 - val_loss: 0.4346 - val_accuracy: 0.7771\n",
      "Epoch 31/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4340 - accuracy: 0.7822 - val_loss: 0.4441 - val_accuracy: 0.7725\n",
      "Epoch 32/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4281 - accuracy: 0.7810 - val_loss: 0.4268 - val_accuracy: 0.7902\n",
      "Epoch 33/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4262 - accuracy: 0.7772 - val_loss: 0.4282 - val_accuracy: 0.7919\n",
      "Epoch 34/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4298 - accuracy: 0.7753 - val_loss: 0.4339 - val_accuracy: 0.7851\n",
      "Epoch 35/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4282 - accuracy: 0.7833 - val_loss: 0.4319 - val_accuracy: 0.7765\n",
      "Epoch 36/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4259 - accuracy: 0.7812 - val_loss: 0.4301 - val_accuracy: 0.7731\n",
      "Epoch 37/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4250 - accuracy: 0.7839 - val_loss: 0.4359 - val_accuracy: 0.7777\n",
      "Epoch 38/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4257 - accuracy: 0.7808 - val_loss: 0.4367 - val_accuracy: 0.7816\n",
      "Epoch 39/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4261 - accuracy: 0.7850 - val_loss: 0.4303 - val_accuracy: 0.7828\n",
      "Epoch 40/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4249 - accuracy: 0.7798 - val_loss: 0.4250 - val_accuracy: 0.7908\n",
      "Epoch 41/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4242 - accuracy: 0.7835 - val_loss: 0.4291 - val_accuracy: 0.7788\n",
      "Epoch 42/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4248 - accuracy: 0.7808 - val_loss: 0.4282 - val_accuracy: 0.7816\n",
      "Epoch 43/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4219 - accuracy: 0.7832 - val_loss: 0.4329 - val_accuracy: 0.7771\n",
      "Epoch 44/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4220 - accuracy: 0.7847 - val_loss: 0.4333 - val_accuracy: 0.7845\n",
      "Epoch 45/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4214 - accuracy: 0.7850 - val_loss: 0.4424 - val_accuracy: 0.7731\n",
      "Epoch 46/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4204 - accuracy: 0.7816 - val_loss: 0.4252 - val_accuracy: 0.7908\n",
      "Epoch 47/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4206 - accuracy: 0.7816 - val_loss: 0.4199 - val_accuracy: 0.7987\n",
      "Epoch 48/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4200 - accuracy: 0.7840 - val_loss: 0.4249 - val_accuracy: 0.7891\n",
      "Epoch 49/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4198 - accuracy: 0.7839 - val_loss: 0.4240 - val_accuracy: 0.7862\n",
      "Epoch 50/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4187 - accuracy: 0.7869 - val_loss: 0.4214 - val_accuracy: 0.7919\n",
      "Epoch 51/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4181 - accuracy: 0.7847 - val_loss: 0.4191 - val_accuracy: 0.7965\n",
      "Epoch 52/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4185 - accuracy: 0.7833 - val_loss: 0.4291 - val_accuracy: 0.7674\n",
      "Epoch 53/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4163 - accuracy: 0.7886 - val_loss: 0.4270 - val_accuracy: 0.7794\n",
      "Epoch 54/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4185 - accuracy: 0.7835 - val_loss: 0.4309 - val_accuracy: 0.7805\n",
      "Epoch 55/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4159 - accuracy: 0.7857 - val_loss: 0.4234 - val_accuracy: 0.7908\n",
      "Epoch 56/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4184 - accuracy: 0.7855 - val_loss: 0.4261 - val_accuracy: 0.7794\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4159 - accuracy: 0.7872 - val_loss: 0.4206 - val_accuracy: 0.7930\n",
      "Epoch 58/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4171 - accuracy: 0.7866 - val_loss: 0.4255 - val_accuracy: 0.7799\n",
      "Epoch 59/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4137 - accuracy: 0.7877 - val_loss: 0.4230 - val_accuracy: 0.7936\n",
      "Epoch 60/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4158 - accuracy: 0.7867 - val_loss: 0.4188 - val_accuracy: 0.7948\n",
      "Epoch 61/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4155 - accuracy: 0.7877 - val_loss: 0.4237 - val_accuracy: 0.7851\n",
      "Epoch 62/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4140 - accuracy: 0.7860 - val_loss: 0.4155 - val_accuracy: 0.7856\n",
      "Epoch 63/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4142 - accuracy: 0.7876 - val_loss: 0.4255 - val_accuracy: 0.7805\n",
      "Epoch 64/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4131 - accuracy: 0.7886 - val_loss: 0.4248 - val_accuracy: 0.7856\n",
      "Epoch 65/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4138 - accuracy: 0.7857 - val_loss: 0.4184 - val_accuracy: 0.7982\n",
      "Epoch 66/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4139 - accuracy: 0.7857 - val_loss: 0.4150 - val_accuracy: 0.7953\n",
      "Epoch 67/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4114 - accuracy: 0.7889 - val_loss: 0.4182 - val_accuracy: 0.7816\n",
      "Epoch 68/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4095 - accuracy: 0.7899 - val_loss: 0.4196 - val_accuracy: 0.7976\n",
      "Epoch 69/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4134 - accuracy: 0.7886 - val_loss: 0.4219 - val_accuracy: 0.7925\n",
      "Epoch 70/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4148 - accuracy: 0.7904 - val_loss: 0.4200 - val_accuracy: 0.7822\n",
      "Epoch 71/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4133 - accuracy: 0.7892 - val_loss: 0.4158 - val_accuracy: 0.7805\n",
      "Epoch 72/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4111 - accuracy: 0.7883 - val_loss: 0.4119 - val_accuracy: 0.7976\n",
      "Epoch 73/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4093 - accuracy: 0.7877 - val_loss: 0.4232 - val_accuracy: 0.7913\n",
      "Epoch 74/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4104 - accuracy: 0.7876 - val_loss: 0.4102 - val_accuracy: 0.8073\n",
      "Epoch 75/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4113 - accuracy: 0.7924 - val_loss: 0.4226 - val_accuracy: 0.7811\n",
      "Epoch 76/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4110 - accuracy: 0.7895 - val_loss: 0.4146 - val_accuracy: 0.7999\n",
      "Epoch 77/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4094 - accuracy: 0.7942 - val_loss: 0.4164 - val_accuracy: 0.7930\n",
      "Epoch 78/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4091 - accuracy: 0.7920 - val_loss: 0.4166 - val_accuracy: 0.7942\n",
      "Epoch 79/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4101 - accuracy: 0.7873 - val_loss: 0.4195 - val_accuracy: 0.7902\n",
      "Epoch 80/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4085 - accuracy: 0.7917 - val_loss: 0.4152 - val_accuracy: 0.7936\n",
      "Epoch 81/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4094 - accuracy: 0.7913 - val_loss: 0.4230 - val_accuracy: 0.7805\n",
      "Epoch 82/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4100 - accuracy: 0.7863 - val_loss: 0.4145 - val_accuracy: 0.7942\n",
      "Epoch 83/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4083 - accuracy: 0.7873 - val_loss: 0.4158 - val_accuracy: 0.7908\n",
      "Epoch 84/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4112 - accuracy: 0.7873 - val_loss: 0.4147 - val_accuracy: 0.7936\n",
      "Epoch 85/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4101 - accuracy: 0.7877 - val_loss: 0.4142 - val_accuracy: 0.7942\n",
      "Epoch 86/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4060 - accuracy: 0.7902 - val_loss: 0.4141 - val_accuracy: 0.7982\n",
      "Epoch 87/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4067 - accuracy: 0.7907 - val_loss: 0.4151 - val_accuracy: 0.8022\n",
      "Epoch 88/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4058 - accuracy: 0.7924 - val_loss: 0.4188 - val_accuracy: 0.7925\n",
      "Epoch 89/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4078 - accuracy: 0.7879 - val_loss: 0.4135 - val_accuracy: 0.7908\n",
      "Epoch 90/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4069 - accuracy: 0.7886 - val_loss: 0.4236 - val_accuracy: 0.7805\n",
      "Epoch 91/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4066 - accuracy: 0.7924 - val_loss: 0.4159 - val_accuracy: 0.7993\n",
      "Epoch 92/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4073 - accuracy: 0.7910 - val_loss: 0.4143 - val_accuracy: 0.7925\n",
      "Epoch 93/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4080 - accuracy: 0.7883 - val_loss: 0.4160 - val_accuracy: 0.7891\n",
      "Epoch 94/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4064 - accuracy: 0.7932 - val_loss: 0.4107 - val_accuracy: 0.8010\n",
      "Epoch 95/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4073 - accuracy: 0.7953 - val_loss: 0.4109 - val_accuracy: 0.8044\n",
      "Epoch 96/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4047 - accuracy: 0.7946 - val_loss: 0.4101 - val_accuracy: 0.7970\n",
      "Epoch 97/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4069 - accuracy: 0.7904 - val_loss: 0.4142 - val_accuracy: 0.7913\n",
      "Epoch 98/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4056 - accuracy: 0.7916 - val_loss: 0.4172 - val_accuracy: 0.7822\n",
      "Epoch 99/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4034 - accuracy: 0.7897 - val_loss: 0.4105 - val_accuracy: 0.7942\n",
      "Epoch 100/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4051 - accuracy: 0.7903 - val_loss: 0.4143 - val_accuracy: 0.7822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aadd6a6db80>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b5d101c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275/275 [==============================] - 1s 4ms/step\n",
      "69/69 [==============================] - 0s 4ms/step\n",
      "[[False]\n",
      " [False]\n",
      " [ True]\n",
      " ...\n",
      " [ True]\n",
      " [ True]\n",
      " [ True]]\n",
      "Train accuracy: 0.7829855171627323\n",
      "Test accuracy: 0.7578659370725034\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "mlp_y_pred_train=model.predict(x_train)\n",
    "mlp_y_pred_test=model.predict(x_test)\n",
    "mlp_y_pred_test=mlp_y_pred_test>0.5\n",
    "print(mlp_y_pred_test)\n",
    "mlp_y_pred_train=mlp_y_pred_train>0.5\n",
    "print('Train accuracy:',accuracy_score(y_train,mlp_y_pred_train))\n",
    "print('Test accuracy:',accuracy_score(y_test,mlp_y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e25f7eb",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47452283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 75)]              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               9728      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 4)                 36        \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 2)                 10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103,334\n",
      "Trainable params: 103,334\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(75,))\n",
    "\n",
    "x = tf.keras.layers.Dense(128,activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(64,activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(32,activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(16,activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(8,activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(4,activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(2,activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs,outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11784f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "042db6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.6482 - accuracy: 0.6047 - val_loss: 0.5794 - val_accuracy: 0.7075\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.5900 - accuracy: 0.6476 - val_loss: 0.5069 - val_accuracy: 0.7372\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.5448 - accuracy: 0.6848 - val_loss: 0.5070 - val_accuracy: 0.7132\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 2s 10ms/step - loss: 0.5423 - accuracy: 0.6890 - val_loss: 0.4807 - val_accuracy: 0.7560\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.5373 - accuracy: 0.6865 - val_loss: 0.4747 - val_accuracy: 0.7469\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.5234 - accuracy: 0.7008 - val_loss: 0.4722 - val_accuracy: 0.7640\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.5298 - accuracy: 0.6902 - val_loss: 0.4817 - val_accuracy: 0.7429\n",
      "Epoch 8/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.5216 - accuracy: 0.6959 - val_loss: 0.4678 - val_accuracy: 0.7560\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.5205 - accuracy: 0.7120 - val_loss: 0.4684 - val_accuracy: 0.7623\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4947 - accuracy: 0.7485 - val_loss: 0.4693 - val_accuracy: 0.7548\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4788 - accuracy: 0.7468 - val_loss: 0.4408 - val_accuracy: 0.7725\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4666 - accuracy: 0.7514 - val_loss: 0.4454 - val_accuracy: 0.7583\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4642 - accuracy: 0.7588 - val_loss: 0.4481 - val_accuracy: 0.7617\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4796 - accuracy: 0.7488 - val_loss: 0.4368 - val_accuracy: 0.7782\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4661 - accuracy: 0.7569 - val_loss: 0.4408 - val_accuracy: 0.7628\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4538 - accuracy: 0.7618 - val_loss: 0.4368 - val_accuracy: 0.7828\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4479 - accuracy: 0.7642 - val_loss: 0.4357 - val_accuracy: 0.7742\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4434 - accuracy: 0.7615 - val_loss: 0.4351 - val_accuracy: 0.7662\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4537 - accuracy: 0.7609 - val_loss: 0.4305 - val_accuracy: 0.7754\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4425 - accuracy: 0.7588 - val_loss: 0.4160 - val_accuracy: 0.7805\n",
      "Epoch 21/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4399 - accuracy: 0.7631 - val_loss: 0.4300 - val_accuracy: 0.7759\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4443 - accuracy: 0.7638 - val_loss: 0.4386 - val_accuracy: 0.7725\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4405 - accuracy: 0.7676 - val_loss: 0.4248 - val_accuracy: 0.7799\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4465 - accuracy: 0.7646 - val_loss: 0.4259 - val_accuracy: 0.7799\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4361 - accuracy: 0.7669 - val_loss: 0.4248 - val_accuracy: 0.7799\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4416 - accuracy: 0.7659 - val_loss: 0.4193 - val_accuracy: 0.7925\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4395 - accuracy: 0.7684 - val_loss: 0.4241 - val_accuracy: 0.7719\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4291 - accuracy: 0.7708 - val_loss: 0.4302 - val_accuracy: 0.7777\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4394 - accuracy: 0.7632 - val_loss: 0.4217 - val_accuracy: 0.7754\n",
      "Epoch 30/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4360 - accuracy: 0.7692 - val_loss: 0.4350 - val_accuracy: 0.7731\n",
      "Epoch 31/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4352 - accuracy: 0.7659 - val_loss: 0.4325 - val_accuracy: 0.7702\n",
      "Epoch 32/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4326 - accuracy: 0.7679 - val_loss: 0.4206 - val_accuracy: 0.7816\n",
      "Epoch 33/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4348 - accuracy: 0.7644 - val_loss: 0.4144 - val_accuracy: 0.7856\n",
      "Epoch 34/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4312 - accuracy: 0.7684 - val_loss: 0.4219 - val_accuracy: 0.7896\n",
      "Epoch 35/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4339 - accuracy: 0.7636 - val_loss: 0.4331 - val_accuracy: 0.7714\n",
      "Epoch 36/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4310 - accuracy: 0.7686 - val_loss: 0.4170 - val_accuracy: 0.7891\n",
      "Epoch 37/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4260 - accuracy: 0.7695 - val_loss: 0.4309 - val_accuracy: 0.7754\n",
      "Epoch 38/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4426 - accuracy: 0.7662 - val_loss: 0.4281 - val_accuracy: 0.7702\n",
      "Epoch 39/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4336 - accuracy: 0.7685 - val_loss: 0.4126 - val_accuracy: 0.7891\n",
      "Epoch 40/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4278 - accuracy: 0.7748 - val_loss: 0.4151 - val_accuracy: 0.7879\n",
      "Epoch 41/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4297 - accuracy: 0.7679 - val_loss: 0.4223 - val_accuracy: 0.7737\n",
      "Epoch 42/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4326 - accuracy: 0.7652 - val_loss: 0.4286 - val_accuracy: 0.7725\n",
      "Epoch 43/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4267 - accuracy: 0.7745 - val_loss: 0.4099 - val_accuracy: 0.7925\n",
      "Epoch 44/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4298 - accuracy: 0.7664 - val_loss: 0.4195 - val_accuracy: 0.7788\n",
      "Epoch 45/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4274 - accuracy: 0.7711 - val_loss: 0.4145 - val_accuracy: 0.7891\n",
      "Epoch 46/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4257 - accuracy: 0.7723 - val_loss: 0.4144 - val_accuracy: 0.7828\n",
      "Epoch 47/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4244 - accuracy: 0.7742 - val_loss: 0.4112 - val_accuracy: 0.7896\n",
      "Epoch 48/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4188 - accuracy: 0.7759 - val_loss: 0.4276 - val_accuracy: 0.7925\n",
      "Epoch 49/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4309 - accuracy: 0.7705 - val_loss: 0.4098 - val_accuracy: 0.7970\n",
      "Epoch 50/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4290 - accuracy: 0.7689 - val_loss: 0.4177 - val_accuracy: 0.7925\n",
      "Epoch 51/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4205 - accuracy: 0.7753 - val_loss: 0.4192 - val_accuracy: 0.7885\n",
      "Epoch 52/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4153 - accuracy: 0.7782 - val_loss: 0.4160 - val_accuracy: 0.7782\n",
      "Epoch 53/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4166 - accuracy: 0.7789 - val_loss: 0.4178 - val_accuracy: 0.7856\n",
      "Epoch 54/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4174 - accuracy: 0.7749 - val_loss: 0.4104 - val_accuracy: 0.7902\n",
      "Epoch 55/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4309 - accuracy: 0.7632 - val_loss: 0.4224 - val_accuracy: 0.7805\n",
      "Epoch 56/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4273 - accuracy: 0.7692 - val_loss: 0.4253 - val_accuracy: 0.7771\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4280 - accuracy: 0.7678 - val_loss: 0.4361 - val_accuracy: 0.7657\n",
      "Epoch 58/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4225 - accuracy: 0.7742 - val_loss: 0.4198 - val_accuracy: 0.7885\n",
      "Epoch 59/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4165 - accuracy: 0.7783 - val_loss: 0.4374 - val_accuracy: 0.7868\n",
      "Epoch 60/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4290 - accuracy: 0.7691 - val_loss: 0.4454 - val_accuracy: 0.7702\n",
      "Epoch 61/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4273 - accuracy: 0.7732 - val_loss: 0.4198 - val_accuracy: 0.7959\n",
      "Epoch 62/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4176 - accuracy: 0.7713 - val_loss: 0.4176 - val_accuracy: 0.7902\n",
      "Epoch 63/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4159 - accuracy: 0.7788 - val_loss: 0.4222 - val_accuracy: 0.7959\n",
      "Epoch 64/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4258 - accuracy: 0.7749 - val_loss: 0.4267 - val_accuracy: 0.7919\n",
      "Epoch 65/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4195 - accuracy: 0.7765 - val_loss: 0.4159 - val_accuracy: 0.7976\n",
      "Epoch 66/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4166 - accuracy: 0.7796 - val_loss: 0.4218 - val_accuracy: 0.7845\n",
      "Epoch 67/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4136 - accuracy: 0.7816 - val_loss: 0.4262 - val_accuracy: 0.7719\n",
      "Epoch 68/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4229 - accuracy: 0.7718 - val_loss: 0.4363 - val_accuracy: 0.7788\n",
      "Epoch 69/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4139 - accuracy: 0.7799 - val_loss: 0.4150 - val_accuracy: 0.7919\n",
      "Epoch 70/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4135 - accuracy: 0.7805 - val_loss: 0.4264 - val_accuracy: 0.7885\n",
      "Epoch 71/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4189 - accuracy: 0.7743 - val_loss: 0.4421 - val_accuracy: 0.7754\n",
      "Epoch 72/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4358 - accuracy: 0.7678 - val_loss: 0.4222 - val_accuracy: 0.7754\n",
      "Epoch 73/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4264 - accuracy: 0.7648 - val_loss: 0.4119 - val_accuracy: 0.7788\n",
      "Epoch 74/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4139 - accuracy: 0.7745 - val_loss: 0.4161 - val_accuracy: 0.7913\n",
      "Epoch 75/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4138 - accuracy: 0.7779 - val_loss: 0.4129 - val_accuracy: 0.7902\n",
      "Epoch 76/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4170 - accuracy: 0.7752 - val_loss: 0.4273 - val_accuracy: 0.7765\n",
      "Epoch 77/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4135 - accuracy: 0.7761 - val_loss: 0.4156 - val_accuracy: 0.7873\n",
      "Epoch 78/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4160 - accuracy: 0.7802 - val_loss: 0.4210 - val_accuracy: 0.7868\n",
      "Epoch 79/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4133 - accuracy: 0.7778 - val_loss: 0.4295 - val_accuracy: 0.7885\n",
      "Epoch 80/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4205 - accuracy: 0.7789 - val_loss: 0.4407 - val_accuracy: 0.7685\n",
      "Epoch 81/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4237 - accuracy: 0.7665 - val_loss: 0.4248 - val_accuracy: 0.7754\n",
      "Epoch 82/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4338 - accuracy: 0.7716 - val_loss: 0.4153 - val_accuracy: 0.7754\n",
      "Epoch 83/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4342 - accuracy: 0.7716 - val_loss: 0.4192 - val_accuracy: 0.8010\n",
      "Epoch 84/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4131 - accuracy: 0.7798 - val_loss: 0.4119 - val_accuracy: 0.7936\n",
      "Epoch 85/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4152 - accuracy: 0.7780 - val_loss: 0.4221 - val_accuracy: 0.7856\n",
      "Epoch 86/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4201 - accuracy: 0.7753 - val_loss: 0.4141 - val_accuracy: 0.7885\n",
      "Epoch 87/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4077 - accuracy: 0.7819 - val_loss: 0.4135 - val_accuracy: 0.7970\n",
      "Epoch 88/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4168 - accuracy: 0.7759 - val_loss: 0.4103 - val_accuracy: 0.7925\n",
      "Epoch 89/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4099 - accuracy: 0.7823 - val_loss: 0.4136 - val_accuracy: 0.7919\n",
      "Epoch 90/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4116 - accuracy: 0.7788 - val_loss: 0.4179 - val_accuracy: 0.7919\n",
      "Epoch 91/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4163 - accuracy: 0.7770 - val_loss: 0.4199 - val_accuracy: 0.7908\n",
      "Epoch 92/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4113 - accuracy: 0.7798 - val_loss: 0.4081 - val_accuracy: 0.7930\n",
      "Epoch 93/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4087 - accuracy: 0.7809 - val_loss: 0.4108 - val_accuracy: 0.7959\n",
      "Epoch 94/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4032 - accuracy: 0.7835 - val_loss: 0.4065 - val_accuracy: 0.7942\n",
      "Epoch 95/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4049 - accuracy: 0.7853 - val_loss: 0.4155 - val_accuracy: 0.7965\n",
      "Epoch 96/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4084 - accuracy: 0.7815 - val_loss: 0.4187 - val_accuracy: 0.7930\n",
      "Epoch 97/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4080 - accuracy: 0.7820 - val_loss: 0.4232 - val_accuracy: 0.7987\n",
      "Epoch 98/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4102 - accuracy: 0.7746 - val_loss: 0.4139 - val_accuracy: 0.7976\n",
      "Epoch 99/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4031 - accuracy: 0.7819 - val_loss: 0.4156 - val_accuracy: 0.7965\n",
      "Epoch 100/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4050 - accuracy: 0.7846 - val_loss: 0.4324 - val_accuracy: 0.7805\n",
      "69/69 - 1s - loss: 0.4474 - accuracy: 0.7620 - 522ms/epoch - 8ms/step\n",
      "Test loss:  0.4473526179790497\n",
      "Test accuracy:  0.7619699239730835\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=100, validation_split=0.2)\n",
    "test_score = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss: \", test_score[0])\n",
    "print(\"Test accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f9a2f7",
   "metadata": {},
   "source": [
    "### Improving the neural network's accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d927be",
   "metadata": {},
   "source": [
    "### Leaky_Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "555ba51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 75)]              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 40)                3040      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 20)                820       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,881\n",
      "Trainable params: 3,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(75,))\n",
    "\n",
    "x = tf.keras.layers.Dense(40,activation='leaky_relu')(inputs)\n",
    "x = tf.keras.layers.Dense(20,activation='leaky_relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs,outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "def93103",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eaa64c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ok_sikha/anaconda3/envs/tf_gpu_segnet/lib/python3.9/site-packages/keras/backend.py:5673: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 3s 12ms/step - loss: 0.6658 - accuracy: 0.5896 - val_loss: 0.6346 - val_accuracy: 0.6648\n",
      "Epoch 2/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.6193 - accuracy: 0.6740 - val_loss: 0.5956 - val_accuracy: 0.7132\n",
      "Epoch 3/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.5928 - accuracy: 0.7024 - val_loss: 0.5763 - val_accuracy: 0.7201\n",
      "Epoch 4/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.5772 - accuracy: 0.7177 - val_loss: 0.5609 - val_accuracy: 0.7355\n",
      "Epoch 5/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.5630 - accuracy: 0.7239 - val_loss: 0.5523 - val_accuracy: 0.7395\n",
      "Epoch 6/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.5497 - accuracy: 0.7287 - val_loss: 0.5386 - val_accuracy: 0.7172\n",
      "Epoch 7/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.5370 - accuracy: 0.7346 - val_loss: 0.5343 - val_accuracy: 0.7400\n",
      "Epoch 8/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.5259 - accuracy: 0.7373 - val_loss: 0.5102 - val_accuracy: 0.7383\n",
      "Epoch 9/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.5160 - accuracy: 0.7398 - val_loss: 0.5010 - val_accuracy: 0.7457\n",
      "Epoch 10/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.5065 - accuracy: 0.7435 - val_loss: 0.5005 - val_accuracy: 0.7583\n",
      "Epoch 11/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.5000 - accuracy: 0.7468 - val_loss: 0.4885 - val_accuracy: 0.7537\n",
      "Epoch 12/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4909 - accuracy: 0.7545 - val_loss: 0.4822 - val_accuracy: 0.7554\n",
      "Epoch 13/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4864 - accuracy: 0.7518 - val_loss: 0.4759 - val_accuracy: 0.7554\n",
      "Epoch 14/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4832 - accuracy: 0.7520 - val_loss: 0.4693 - val_accuracy: 0.7651\n",
      "Epoch 15/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4780 - accuracy: 0.7584 - val_loss: 0.4779 - val_accuracy: 0.7611\n",
      "Epoch 16/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4714 - accuracy: 0.7585 - val_loss: 0.4746 - val_accuracy: 0.7566\n",
      "Epoch 17/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4692 - accuracy: 0.7628 - val_loss: 0.4638 - val_accuracy: 0.7674\n",
      "Epoch 18/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4670 - accuracy: 0.7652 - val_loss: 0.4610 - val_accuracy: 0.7634\n",
      "Epoch 19/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4632 - accuracy: 0.7654 - val_loss: 0.4584 - val_accuracy: 0.7645\n",
      "Epoch 20/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4592 - accuracy: 0.7649 - val_loss: 0.4582 - val_accuracy: 0.7560\n",
      "Epoch 21/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4558 - accuracy: 0.7675 - val_loss: 0.4650 - val_accuracy: 0.7754\n",
      "Epoch 22/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4568 - accuracy: 0.7652 - val_loss: 0.4565 - val_accuracy: 0.7571\n",
      "Epoch 23/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4551 - accuracy: 0.7652 - val_loss: 0.4761 - val_accuracy: 0.7583\n",
      "Epoch 24/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4496 - accuracy: 0.7684 - val_loss: 0.4471 - val_accuracy: 0.7748\n",
      "Epoch 25/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4499 - accuracy: 0.7699 - val_loss: 0.4505 - val_accuracy: 0.7788\n",
      "Epoch 26/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4472 - accuracy: 0.7712 - val_loss: 0.4439 - val_accuracy: 0.7708\n",
      "Epoch 27/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4442 - accuracy: 0.7701 - val_loss: 0.4496 - val_accuracy: 0.7737\n",
      "Epoch 28/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4505 - accuracy: 0.7709 - val_loss: 0.4474 - val_accuracy: 0.7702\n",
      "Epoch 29/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4476 - accuracy: 0.7729 - val_loss: 0.4423 - val_accuracy: 0.7714\n",
      "Epoch 30/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4481 - accuracy: 0.7701 - val_loss: 0.4409 - val_accuracy: 0.7725\n",
      "Epoch 31/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4399 - accuracy: 0.7725 - val_loss: 0.4400 - val_accuracy: 0.7708\n",
      "Epoch 32/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4404 - accuracy: 0.7736 - val_loss: 0.4486 - val_accuracy: 0.7777\n",
      "Epoch 33/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4385 - accuracy: 0.7749 - val_loss: 0.4424 - val_accuracy: 0.7759\n",
      "Epoch 34/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4422 - accuracy: 0.7718 - val_loss: 0.4386 - val_accuracy: 0.7839\n",
      "Epoch 35/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4380 - accuracy: 0.7732 - val_loss: 0.4392 - val_accuracy: 0.7737\n",
      "Epoch 36/100\n",
      "220/220 [==============================] - 2s 11ms/step - loss: 0.4376 - accuracy: 0.7778 - val_loss: 0.4384 - val_accuracy: 0.7748\n",
      "Epoch 37/100\n",
      "220/220 [==============================] - 2s 10ms/step - loss: 0.4344 - accuracy: 0.7765 - val_loss: 0.4336 - val_accuracy: 0.7765\n",
      "Epoch 38/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4343 - accuracy: 0.7822 - val_loss: 0.4361 - val_accuracy: 0.7851\n",
      "Epoch 39/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4324 - accuracy: 0.7825 - val_loss: 0.4366 - val_accuracy: 0.7873\n",
      "Epoch 40/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4335 - accuracy: 0.7780 - val_loss: 0.4377 - val_accuracy: 0.7759\n",
      "Epoch 41/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4356 - accuracy: 0.7772 - val_loss: 0.4357 - val_accuracy: 0.7834\n",
      "Epoch 42/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4337 - accuracy: 0.7799 - val_loss: 0.4341 - val_accuracy: 0.7719\n",
      "Epoch 43/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4326 - accuracy: 0.7749 - val_loss: 0.4317 - val_accuracy: 0.7811\n",
      "Epoch 44/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4301 - accuracy: 0.7770 - val_loss: 0.4433 - val_accuracy: 0.7674\n",
      "Epoch 45/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4285 - accuracy: 0.7786 - val_loss: 0.4382 - val_accuracy: 0.7708\n",
      "Epoch 46/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4319 - accuracy: 0.7795 - val_loss: 0.4477 - val_accuracy: 0.7731\n",
      "Epoch 47/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4299 - accuracy: 0.7772 - val_loss: 0.4312 - val_accuracy: 0.7719\n",
      "Epoch 48/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4318 - accuracy: 0.7753 - val_loss: 0.4480 - val_accuracy: 0.7702\n",
      "Epoch 49/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4294 - accuracy: 0.7806 - val_loss: 0.4312 - val_accuracy: 0.7930\n",
      "Epoch 50/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4260 - accuracy: 0.7822 - val_loss: 0.4297 - val_accuracy: 0.7788\n",
      "Epoch 51/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4241 - accuracy: 0.7820 - val_loss: 0.4294 - val_accuracy: 0.7737\n",
      "Epoch 52/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4262 - accuracy: 0.7798 - val_loss: 0.4288 - val_accuracy: 0.7782\n",
      "Epoch 53/100\n",
      "220/220 [==============================] - 3s 11ms/step - loss: 0.4293 - accuracy: 0.7745 - val_loss: 0.4411 - val_accuracy: 0.7708\n",
      "Epoch 54/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4255 - accuracy: 0.7766 - val_loss: 0.4478 - val_accuracy: 0.7731\n",
      "Epoch 55/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4284 - accuracy: 0.7823 - val_loss: 0.4383 - val_accuracy: 0.7719\n",
      "Epoch 56/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4243 - accuracy: 0.7785 - val_loss: 0.4485 - val_accuracy: 0.7634\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4247 - accuracy: 0.7819 - val_loss: 0.4297 - val_accuracy: 0.7737\n",
      "Epoch 58/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4242 - accuracy: 0.7782 - val_loss: 0.4305 - val_accuracy: 0.7702\n",
      "Epoch 59/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4260 - accuracy: 0.7749 - val_loss: 0.4297 - val_accuracy: 0.7868\n",
      "Epoch 60/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4243 - accuracy: 0.7808 - val_loss: 0.4254 - val_accuracy: 0.7788\n",
      "Epoch 61/100\n",
      "220/220 [==============================] - 2s 10ms/step - loss: 0.4256 - accuracy: 0.7815 - val_loss: 0.4289 - val_accuracy: 0.7873\n",
      "Epoch 62/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4233 - accuracy: 0.7803 - val_loss: 0.4269 - val_accuracy: 0.7834\n",
      "Epoch 63/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4254 - accuracy: 0.7788 - val_loss: 0.4243 - val_accuracy: 0.7834\n",
      "Epoch 64/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4212 - accuracy: 0.7895 - val_loss: 0.4308 - val_accuracy: 0.7748\n",
      "Epoch 65/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4226 - accuracy: 0.7819 - val_loss: 0.4345 - val_accuracy: 0.7902\n",
      "Epoch 66/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4249 - accuracy: 0.7795 - val_loss: 0.4386 - val_accuracy: 0.7811\n",
      "Epoch 67/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4195 - accuracy: 0.7818 - val_loss: 0.4368 - val_accuracy: 0.7685\n",
      "Epoch 68/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4249 - accuracy: 0.7810 - val_loss: 0.4303 - val_accuracy: 0.7908\n",
      "Epoch 69/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4243 - accuracy: 0.7835 - val_loss: 0.4257 - val_accuracy: 0.7794\n",
      "Epoch 70/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4218 - accuracy: 0.7833 - val_loss: 0.4317 - val_accuracy: 0.7759\n",
      "Epoch 71/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4219 - accuracy: 0.7846 - val_loss: 0.4259 - val_accuracy: 0.7879\n",
      "Epoch 72/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4217 - accuracy: 0.7833 - val_loss: 0.4288 - val_accuracy: 0.7999\n",
      "Epoch 73/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4211 - accuracy: 0.7866 - val_loss: 0.4457 - val_accuracy: 0.7856\n",
      "Epoch 74/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4200 - accuracy: 0.7832 - val_loss: 0.4226 - val_accuracy: 0.7782\n",
      "Epoch 75/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4195 - accuracy: 0.7873 - val_loss: 0.4263 - val_accuracy: 0.7816\n",
      "Epoch 76/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4199 - accuracy: 0.7836 - val_loss: 0.4233 - val_accuracy: 0.7942\n",
      "Epoch 77/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4197 - accuracy: 0.7812 - val_loss: 0.4331 - val_accuracy: 0.7731\n",
      "Epoch 78/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4210 - accuracy: 0.7823 - val_loss: 0.4476 - val_accuracy: 0.7537\n",
      "Epoch 79/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4198 - accuracy: 0.7826 - val_loss: 0.4313 - val_accuracy: 0.7839\n",
      "Epoch 80/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4198 - accuracy: 0.7862 - val_loss: 0.4219 - val_accuracy: 0.7925\n",
      "Epoch 81/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4189 - accuracy: 0.7850 - val_loss: 0.4272 - val_accuracy: 0.7930\n",
      "Epoch 82/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4224 - accuracy: 0.7818 - val_loss: 0.4289 - val_accuracy: 0.7771\n",
      "Epoch 83/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4200 - accuracy: 0.7800 - val_loss: 0.4381 - val_accuracy: 0.7697\n",
      "Epoch 84/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4191 - accuracy: 0.7866 - val_loss: 0.4298 - val_accuracy: 0.7788\n",
      "Epoch 85/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4226 - accuracy: 0.7837 - val_loss: 0.4208 - val_accuracy: 0.7925\n",
      "Epoch 86/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4173 - accuracy: 0.7857 - val_loss: 0.4309 - val_accuracy: 0.7794\n",
      "Epoch 87/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4188 - accuracy: 0.7823 - val_loss: 0.4266 - val_accuracy: 0.7908\n",
      "Epoch 88/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4162 - accuracy: 0.7879 - val_loss: 0.4302 - val_accuracy: 0.7799\n",
      "Epoch 89/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4156 - accuracy: 0.7857 - val_loss: 0.4222 - val_accuracy: 0.7896\n",
      "Epoch 90/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4216 - accuracy: 0.7820 - val_loss: 0.4488 - val_accuracy: 0.7702\n",
      "Epoch 91/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4171 - accuracy: 0.7845 - val_loss: 0.4259 - val_accuracy: 0.7930\n",
      "Epoch 92/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4147 - accuracy: 0.7862 - val_loss: 0.4290 - val_accuracy: 0.7896\n",
      "Epoch 93/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4162 - accuracy: 0.7876 - val_loss: 0.4322 - val_accuracy: 0.7976\n",
      "Epoch 94/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4176 - accuracy: 0.7866 - val_loss: 0.4285 - val_accuracy: 0.7834\n",
      "Epoch 95/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4158 - accuracy: 0.7812 - val_loss: 0.4288 - val_accuracy: 0.7856\n",
      "Epoch 96/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4180 - accuracy: 0.7879 - val_loss: 0.4277 - val_accuracy: 0.7868\n",
      "Epoch 97/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4131 - accuracy: 0.7875 - val_loss: 0.4324 - val_accuracy: 0.7965\n",
      "Epoch 98/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4139 - accuracy: 0.7876 - val_loss: 0.4248 - val_accuracy: 0.7885\n",
      "Epoch 99/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4154 - accuracy: 0.7828 - val_loss: 0.4259 - val_accuracy: 0.7885\n",
      "Epoch 100/100\n",
      "220/220 [==============================] - 3s 12ms/step - loss: 0.4145 - accuracy: 0.7859 - val_loss: 0.4298 - val_accuracy: 0.7873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2aadd7e617f0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f19b05d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69/69 - 0s - loss: 0.4660 - accuracy: 0.7711 - 498ms/epoch - 7ms/step\n",
      "Test loss:  0.46597737073898315\n",
      "Test accuracy:  0.7710898518562317\n"
     ]
    }
   ],
   "source": [
    "test_score = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss: \", test_score[0])\n",
    "print(\"Test accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8f0f2d",
   "metadata": {},
   "source": [
    "Model 1 => ~75% accuracy \n",
    "\n",
    "Model 2 => ~76% accuracy \n",
    "\n",
    "Model 1 with Leaky ReLU activation => ~77%\n",
    "\n",
    "This clearly highlights the fact that a shallow network is able to capture as much details and going for a deeper network is not giving any huge performance boost. This can be attributed to the high dimensionality of the dataset (75 columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c500976c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
