{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10511a0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 17:41:59.701041: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-12 17:42:00.425963: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-07-12 17:42:09.172196: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/cudnn-8.4/8.4/lib64:/cm/local/apps/cuda/libs/current/lib64:/cm/shared/apps/cuda11.2/toolkit/11.2.0/targets/x86_64-linux/lib:/cm/local/apps/gcc/7.2.0/lib:/cm/local/apps/gcc/7.2.0/lib64:/home/ok_sikha/anaconda3/envs/tf_gpu_segnet/lib/\n",
      "2023-07-12 17:42:09.172469: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /cm/shared/apps/cudnn-8.4/8.4/lib64:/cm/local/apps/cuda/libs/current/lib64:/cm/shared/apps/cuda11.2/toolkit/11.2.0/targets/x86_64-linux/lib:/cm/local/apps/gcc/7.2.0/lib:/cm/local/apps/gcc/7.2.0/lib64:/home/ok_sikha/anaconda3/envs/tf_gpu_segnet/lib/\n",
      "2023-07-12 17:42:09.172500: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b254f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cols_dtypes(df):\n",
    "    print(\"Columns and dtypes:\")\n",
    "    for column, dtype in df.dtypes.iteritems():\n",
    "        print(f\"{column}: {dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1165d3c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process Profiling-&gt;Thread Exit</th>\n",
       "      <th>Process Profiling-&gt;Thread Create</th>\n",
       "      <th>Thread Exit-&gt;Process Profiling</th>\n",
       "      <th>Thread Exit-&gt;Thread Exit</th>\n",
       "      <th>Thread Exit-&gt;Thread Create</th>\n",
       "      <th>Thread Exit-&gt;ReadFile</th>\n",
       "      <th>Thread Exit-&gt;RegQueryKey</th>\n",
       "      <th>Thread Exit-&gt;RegOpenKey</th>\n",
       "      <th>Thread Exit-&gt;RegQueryValue</th>\n",
       "      <th>Thread Exit-&gt;CreateFileMapping</th>\n",
       "      <th>...</th>\n",
       "      <th>QueryDeviceRelations-&gt;ReadFile</th>\n",
       "      <th>QueryDeviceRelations-&gt;RegQueryKey</th>\n",
       "      <th>QueryDeviceRelations-&gt;RegOpenKey</th>\n",
       "      <th>QueryDeviceRelations-&gt;RegQueryValue</th>\n",
       "      <th>QueryDeviceRelations-&gt;CreateFile</th>\n",
       "      <th>QueryDeviceRelations-&gt;QueryBasicInformationFile</th>\n",
       "      <th>TCP Accept-&gt;TCP TCPCopy</th>\n",
       "      <th>CreatePipe-&gt;CreateFile</th>\n",
       "      <th>RegSaveKey-&gt;WriteFile</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4774</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4775</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4776</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4777</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4778</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4779 rows Ã— 1738 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Process Profiling->Thread Exit  Process Profiling->Thread Create  \\\n",
       "0                                  1                                 0   \n",
       "1                                  1                                 0   \n",
       "2                                  0                                 1   \n",
       "3                                  0                                 0   \n",
       "4                                  1                                 0   \n",
       "...                              ...                               ...   \n",
       "4774                               0                                 0   \n",
       "4775                               1                                 0   \n",
       "4776                               1                                 0   \n",
       "4777                               1                                 0   \n",
       "4778                               1                                 0   \n",
       "\n",
       "      Thread Exit->Process Profiling  Thread Exit->Thread Exit  \\\n",
       "0                                  0                         0   \n",
       "1                                  0                         0   \n",
       "2                                  0                         0   \n",
       "3                                  0                         0   \n",
       "4                                  0                         0   \n",
       "...                              ...                       ...   \n",
       "4774                               0                         0   \n",
       "4775                               0                         0   \n",
       "4776                               0                         0   \n",
       "4777                               0                         0   \n",
       "4778                               0                         0   \n",
       "\n",
       "      Thread Exit->Thread Create  Thread Exit->ReadFile  \\\n",
       "0                            1.0                    0.0   \n",
       "1                            1.0                    0.0   \n",
       "2                            0.0                    0.0   \n",
       "3                            0.0                    0.0   \n",
       "4                            1.0                    0.0   \n",
       "...                          ...                    ...   \n",
       "4774                         0.0                    0.0   \n",
       "4775                         1.0                    0.0   \n",
       "4776                         1.0                    0.0   \n",
       "4777                         1.0                    0.0   \n",
       "4778                         1.0                    0.0   \n",
       "\n",
       "      Thread Exit->RegQueryKey  Thread Exit->RegOpenKey  \\\n",
       "0                          0.0                      0.0   \n",
       "1                          0.0                      0.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          0.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "4774                       0.0                      0.0   \n",
       "4775                       0.0                      0.0   \n",
       "4776                       0.0                      0.0   \n",
       "4777                       0.0                      0.0   \n",
       "4778                       0.0                      0.0   \n",
       "\n",
       "      Thread Exit->RegQueryValue  Thread Exit->CreateFileMapping  ...  \\\n",
       "0                            0.0                             0.0  ...   \n",
       "1                            0.0                             0.0  ...   \n",
       "2                            0.0                             0.0  ...   \n",
       "3                            0.0                             0.0  ...   \n",
       "4                            0.0                             0.0  ...   \n",
       "...                          ...                             ...  ...   \n",
       "4774                         0.0                             0.0  ...   \n",
       "4775                         0.0                             0.0  ...   \n",
       "4776                         0.0                             0.0  ...   \n",
       "4777                         0.0                             0.0  ...   \n",
       "4778                         0.0                             0.0  ...   \n",
       "\n",
       "      QueryDeviceRelations->ReadFile  QueryDeviceRelations->RegQueryKey  \\\n",
       "0                                0.0                                0.0   \n",
       "1                                0.0                                0.0   \n",
       "2                                0.0                                0.0   \n",
       "3                                0.0                                0.0   \n",
       "4                                0.0                                0.0   \n",
       "...                              ...                                ...   \n",
       "4774                             0.0                                0.0   \n",
       "4775                             0.0                                0.0   \n",
       "4776                             0.0                                0.0   \n",
       "4777                             0.0                                0.0   \n",
       "4778                             0.0                                0.0   \n",
       "\n",
       "      QueryDeviceRelations->RegOpenKey  QueryDeviceRelations->RegQueryValue  \\\n",
       "0                                  0.0                                  0.0   \n",
       "1                                  0.0                                  0.0   \n",
       "2                                  0.0                                  0.0   \n",
       "3                                  0.0                                  0.0   \n",
       "4                                  0.0                                  0.0   \n",
       "...                                ...                                  ...   \n",
       "4774                               0.0                                  0.0   \n",
       "4775                               0.0                                  0.0   \n",
       "4776                               0.0                                  0.0   \n",
       "4777                               0.0                                  0.0   \n",
       "4778                               0.0                                  0.0   \n",
       "\n",
       "      QueryDeviceRelations->CreateFile  \\\n",
       "0                                  0.0   \n",
       "1                                  0.0   \n",
       "2                                  0.0   \n",
       "3                                  0.0   \n",
       "4                                  0.0   \n",
       "...                                ...   \n",
       "4774                               0.0   \n",
       "4775                               0.0   \n",
       "4776                               0.0   \n",
       "4777                               0.0   \n",
       "4778                               0.0   \n",
       "\n",
       "      QueryDeviceRelations->QueryBasicInformationFile  \\\n",
       "0                                                 0.0   \n",
       "1                                                 0.0   \n",
       "2                                                 0.0   \n",
       "3                                                 0.0   \n",
       "4                                                 0.0   \n",
       "...                                               ...   \n",
       "4774                                              0.0   \n",
       "4775                                              0.0   \n",
       "4776                                              0.0   \n",
       "4777                                              0.0   \n",
       "4778                                              0.0   \n",
       "\n",
       "      TCP Accept->TCP TCPCopy  CreatePipe->CreateFile  RegSaveKey->WriteFile  \\\n",
       "0                           0                       0                      0   \n",
       "1                           0                       0                      0   \n",
       "2                           0                       0                      0   \n",
       "3                           0                       0                      0   \n",
       "4                           0                       0                      0   \n",
       "...                       ...                     ...                    ...   \n",
       "4774                        0                       0                      0   \n",
       "4775                        0                       0                      0   \n",
       "4776                        0                       0                      0   \n",
       "4777                        0                       0                      0   \n",
       "4778                        0                       0                      0   \n",
       "\n",
       "      Labels  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "4774       7  \n",
       "4775       7  \n",
       "4776       7  \n",
       "4777       7  \n",
       "4778       7  \n",
       "\n",
       "[4779 rows x 1738 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_master = pd.read_csv('markov_dataset_all.csv')\n",
    "df_master = df_master.drop(['Unnamed: 0'], axis=1)\n",
    "df_master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6a156f",
   "metadata": {},
   "source": [
    "### Fixing class imbalances using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db42bf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dce70e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=393 (8.223%)\n",
      "Class=8, n=148 (3.097%)\n",
      "Class=1, n=484 (10.128%)\n",
      "Class=2, n=867 (18.142%)\n",
      "Class=3, n=720 (15.066%)\n",
      "Class=4, n=116 (2.427%)\n",
      "Class=5, n=691 (14.459%)\n",
      "Class=6, n=968 (20.255%)\n",
      "Class=7, n=392 (8.203%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = df_master.iloc[:, :-1], df_master.iloc[:, -1]\n",
    "# label encode the target variable\n",
    "y = preprocessing.LabelEncoder().fit_transform(y)\n",
    "# summarize distribution\n",
    "counter = Counter(y)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y) * 100\n",
    "    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# plot the distribution\n",
    "pyplot.bar(counter.keys(), counter.values())\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b857bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=968 (11.111%)\n",
      "Class=8, n=968 (11.111%)\n",
      "Class=1, n=968 (11.111%)\n",
      "Class=2, n=968 (11.111%)\n",
      "Class=3, n=968 (11.111%)\n",
      "Class=4, n=968 (11.111%)\n",
      "Class=5, n=968 (11.111%)\n",
      "Class=6, n=968 (11.111%)\n",
      "Class=7, n=968 (11.111%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(X, y)\n",
    "# summarize distribution\n",
    "counter = Counter(y)\n",
    "for k,v in counter.items():\n",
    "    per = v / len(y) * 100\n",
    "    print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# plot the distribution\n",
    "pyplot.bar(counter.keys(), counter.values())\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8beac261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_265475/1300657185.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_master['Labels'] = y\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process Profiling-&gt;Thread Exit</th>\n",
       "      <th>Process Profiling-&gt;Thread Create</th>\n",
       "      <th>Thread Exit-&gt;Process Profiling</th>\n",
       "      <th>Thread Exit-&gt;Thread Exit</th>\n",
       "      <th>Thread Exit-&gt;Thread Create</th>\n",
       "      <th>Thread Exit-&gt;ReadFile</th>\n",
       "      <th>Thread Exit-&gt;RegQueryKey</th>\n",
       "      <th>Thread Exit-&gt;RegOpenKey</th>\n",
       "      <th>Thread Exit-&gt;RegQueryValue</th>\n",
       "      <th>Thread Exit-&gt;CreateFileMapping</th>\n",
       "      <th>...</th>\n",
       "      <th>QueryDeviceRelations-&gt;ReadFile</th>\n",
       "      <th>QueryDeviceRelations-&gt;RegQueryKey</th>\n",
       "      <th>QueryDeviceRelations-&gt;RegOpenKey</th>\n",
       "      <th>QueryDeviceRelations-&gt;RegQueryValue</th>\n",
       "      <th>QueryDeviceRelations-&gt;CreateFile</th>\n",
       "      <th>QueryDeviceRelations-&gt;QueryBasicInformationFile</th>\n",
       "      <th>TCP Accept-&gt;TCP TCPCopy</th>\n",
       "      <th>CreatePipe-&gt;CreateFile</th>\n",
       "      <th>RegSaveKey-&gt;WriteFile</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8707</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8708</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8709</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8710</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8711</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8712 rows Ã— 1738 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Process Profiling->Thread Exit  Process Profiling->Thread Create  \\\n",
       "0                                  1                                 0   \n",
       "1                                  1                                 0   \n",
       "2                                  0                                 1   \n",
       "3                                  0                                 0   \n",
       "4                                  1                                 0   \n",
       "...                              ...                               ...   \n",
       "8707                               0                                 0   \n",
       "8708                               0                                 0   \n",
       "8709                               0                                 0   \n",
       "8710                               0                                 0   \n",
       "8711                               0                                 0   \n",
       "\n",
       "      Thread Exit->Process Profiling  Thread Exit->Thread Exit  \\\n",
       "0                                  0                         0   \n",
       "1                                  0                         0   \n",
       "2                                  0                         0   \n",
       "3                                  0                         0   \n",
       "4                                  0                         0   \n",
       "...                              ...                       ...   \n",
       "8707                               0                         0   \n",
       "8708                               0                         0   \n",
       "8709                               0                         0   \n",
       "8710                               0                         0   \n",
       "8711                               0                         0   \n",
       "\n",
       "      Thread Exit->Thread Create  Thread Exit->ReadFile  \\\n",
       "0                            1.0                    0.0   \n",
       "1                            1.0                    0.0   \n",
       "2                            0.0                    0.0   \n",
       "3                            0.0                    0.0   \n",
       "4                            1.0                    0.0   \n",
       "...                          ...                    ...   \n",
       "8707                         0.0                    0.0   \n",
       "8708                         0.0                    0.0   \n",
       "8709                         0.0                    0.0   \n",
       "8710                         0.0                    0.0   \n",
       "8711                         0.0                    0.0   \n",
       "\n",
       "      Thread Exit->RegQueryKey  Thread Exit->RegOpenKey  \\\n",
       "0                          0.0                      0.0   \n",
       "1                          0.0                      0.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          0.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "8707                       0.0                      0.0   \n",
       "8708                       0.0                      0.0   \n",
       "8709                       0.0                      0.0   \n",
       "8710                       0.0                      0.0   \n",
       "8711                       0.0                      0.0   \n",
       "\n",
       "      Thread Exit->RegQueryValue  Thread Exit->CreateFileMapping  ...  \\\n",
       "0                            0.0                             0.0  ...   \n",
       "1                            0.0                             0.0  ...   \n",
       "2                            0.0                             0.0  ...   \n",
       "3                            0.0                             0.0  ...   \n",
       "4                            0.0                             0.0  ...   \n",
       "...                          ...                             ...  ...   \n",
       "8707                         0.0                             0.0  ...   \n",
       "8708                         0.0                             0.0  ...   \n",
       "8709                         0.0                             0.0  ...   \n",
       "8710                         0.0                             0.0  ...   \n",
       "8711                         0.0                             0.0  ...   \n",
       "\n",
       "      QueryDeviceRelations->ReadFile  QueryDeviceRelations->RegQueryKey  \\\n",
       "0                                0.0                                0.0   \n",
       "1                                0.0                                0.0   \n",
       "2                                0.0                                0.0   \n",
       "3                                0.0                                0.0   \n",
       "4                                0.0                                0.0   \n",
       "...                              ...                                ...   \n",
       "8707                             0.0                                0.0   \n",
       "8708                             0.0                                0.0   \n",
       "8709                             0.0                                0.0   \n",
       "8710                             0.0                                0.0   \n",
       "8711                             0.0                                0.0   \n",
       "\n",
       "      QueryDeviceRelations->RegOpenKey  QueryDeviceRelations->RegQueryValue  \\\n",
       "0                                  0.0                                  0.0   \n",
       "1                                  0.0                                  0.0   \n",
       "2                                  0.0                                  0.0   \n",
       "3                                  0.0                                  0.0   \n",
       "4                                  0.0                                  0.0   \n",
       "...                                ...                                  ...   \n",
       "8707                               0.0                                  0.0   \n",
       "8708                               0.0                                  0.0   \n",
       "8709                               0.0                                  0.0   \n",
       "8710                               0.0                                  0.0   \n",
       "8711                               0.0                                  0.0   \n",
       "\n",
       "      QueryDeviceRelations->CreateFile  \\\n",
       "0                                  0.0   \n",
       "1                                  0.0   \n",
       "2                                  0.0   \n",
       "3                                  0.0   \n",
       "4                                  0.0   \n",
       "...                                ...   \n",
       "8707                               0.0   \n",
       "8708                               0.0   \n",
       "8709                               0.0   \n",
       "8710                               0.0   \n",
       "8711                               0.0   \n",
       "\n",
       "      QueryDeviceRelations->QueryBasicInformationFile  \\\n",
       "0                                                 0.0   \n",
       "1                                                 0.0   \n",
       "2                                                 0.0   \n",
       "3                                                 0.0   \n",
       "4                                                 0.0   \n",
       "...                                               ...   \n",
       "8707                                              0.0   \n",
       "8708                                              0.0   \n",
       "8709                                              0.0   \n",
       "8710                                              0.0   \n",
       "8711                                              0.0   \n",
       "\n",
       "      TCP Accept->TCP TCPCopy  CreatePipe->CreateFile  RegSaveKey->WriteFile  \\\n",
       "0                           0                       0                      0   \n",
       "1                           0                       0                      0   \n",
       "2                           0                       0                      0   \n",
       "3                           0                       0                      0   \n",
       "4                           0                       0                      0   \n",
       "...                       ...                     ...                    ...   \n",
       "8707                        0                       0                      0   \n",
       "8708                        0                       0                      0   \n",
       "8709                        0                       0                      0   \n",
       "8710                        0                       0                      0   \n",
       "8711                        0                       0                      0   \n",
       "\n",
       "      Labels  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "8707       8  \n",
       "8708       8  \n",
       "8709       8  \n",
       "8710       8  \n",
       "8711       8  \n",
       "\n",
       "[8712 rows x 1738 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_master = pd.DataFrame(X)\n",
    "df_master['Labels'] = y\n",
    "df_master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13224fa5",
   "metadata": {},
   "source": [
    "## Generic detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1fb1fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_master.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e33777ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(X).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80a03e6d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "8707    8\n",
       "8708    8\n",
       "8709    8\n",
       "8710    8\n",
       "8711    8\n",
       "Name: Labels, Length: 8712, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_master['Labels']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34f0aebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 8, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d27d32a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "8707    1\n",
       "8708    1\n",
       "8709    1\n",
       "8710    1\n",
       "8711    1\n",
       "Name: Labels, Length: 8712, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_gen = (y != 0).astype(int)\n",
    "y_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78c26eb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of ones:  88.88888888888889\n",
      "Percentage of zeros:  11.11111111111111\n"
     ]
    }
   ],
   "source": [
    "count_ones = np.count_nonzero(y_gen == 1)\n",
    "count_zeros = np.count_nonzero(y_gen == 0)\n",
    "\n",
    "# Calculate the percentages\n",
    "percentage_ones = count_ones / np.size(y_gen) * 100\n",
    "percentage_zeros = count_zeros / np.size(y_gen) * 100\n",
    "\n",
    "# Display the percentages\n",
    "print(\"Percentage of ones: \", percentage_ones)\n",
    "print(\"Percentage of zeros: \", percentage_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a62769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing the class imbalance\n",
    "oversample = SMOTE()\n",
    "X, y_gen = oversample.fit_resample(X, y_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91cb42f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of ones:  50.0\n",
      "Percentage of zeros:  50.0\n"
     ]
    }
   ],
   "source": [
    "count_ones = np.count_nonzero(y_gen == 1)\n",
    "count_zeros = np.count_nonzero(y_gen == 0)\n",
    "\n",
    "# Calculate the percentages\n",
    "percentage_ones = count_ones / np.size(y_gen) * 100\n",
    "percentage_zeros = count_zeros / np.size(y_gen) * 100\n",
    "\n",
    "# Display the percentages\n",
    "print(\"Percentage of ones: \", percentage_ones)\n",
    "print(\"Percentage of zeros: \", percentage_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14bd21f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12390, 1737)\n",
      "(12390,)\n",
      "(3098, 1737)\n",
      "(3098,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = tts(X,y_gen,test_size=0.2) \n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aec3c0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 17:42:30.242520: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 1737)]            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 40)                69520     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                820       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,361\n",
      "Trainable params: 70,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-12 17:42:31.561821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8330 MB memory:  -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:3b:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(1737,))\n",
    "\n",
    "x = tf.keras.layers.Dense(40,activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dense(20,activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model_gen = tf.keras.Model(inputs=inputs,outputs=output)\n",
    "model_gen.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "935585ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gen.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab846461",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ok_sikha/anaconda3/envs/tf_gpu_segnet/lib/python3.9/site-packages/keras/backend.py:5673: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310/310 [==============================] - 4s 6ms/step - loss: 0.4868 - accuracy: 0.7649 - val_loss: 0.4004 - val_accuracy: 0.8111\n",
      "Epoch 2/100\n",
      "310/310 [==============================] - 2s 7ms/step - loss: 0.3766 - accuracy: 0.8137 - val_loss: 0.3639 - val_accuracy: 0.8220\n",
      "Epoch 3/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3537 - accuracy: 0.8206 - val_loss: 0.3533 - val_accuracy: 0.8261\n",
      "Epoch 4/100\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3429 - accuracy: 0.8258 - val_loss: 0.3487 - val_accuracy: 0.8289\n",
      "Epoch 5/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3366 - accuracy: 0.8264 - val_loss: 0.3457 - val_accuracy: 0.8309\n",
      "Epoch 6/100\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3293 - accuracy: 0.8300 - val_loss: 0.3442 - val_accuracy: 0.8309\n",
      "Epoch 7/100\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3258 - accuracy: 0.8312 - val_loss: 0.3479 - val_accuracy: 0.8313\n",
      "Epoch 8/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3246 - accuracy: 0.8305 - val_loss: 0.3459 - val_accuracy: 0.8317\n",
      "Epoch 9/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3233 - accuracy: 0.8310 - val_loss: 0.3450 - val_accuracy: 0.8325\n",
      "Epoch 10/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3202 - accuracy: 0.8317 - val_loss: 0.3511 - val_accuracy: 0.8325\n",
      "Epoch 11/100\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3212 - accuracy: 0.8319 - val_loss: 0.3473 - val_accuracy: 0.8305\n",
      "Epoch 12/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3199 - accuracy: 0.8324 - val_loss: 0.3460 - val_accuracy: 0.8321\n",
      "Epoch 13/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3210 - accuracy: 0.8318 - val_loss: 0.3520 - val_accuracy: 0.8309\n",
      "Epoch 14/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3203 - accuracy: 0.8336 - val_loss: 0.3508 - val_accuracy: 0.7906\n",
      "Epoch 15/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3185 - accuracy: 0.8314 - val_loss: 0.3458 - val_accuracy: 0.8329\n",
      "Epoch 16/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3183 - accuracy: 0.8320 - val_loss: 0.3540 - val_accuracy: 0.8329\n",
      "Epoch 17/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3194 - accuracy: 0.8319 - val_loss: 0.3658 - val_accuracy: 0.8293\n",
      "Epoch 18/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3185 - accuracy: 0.8319 - val_loss: 0.3823 - val_accuracy: 0.8249\n",
      "Epoch 19/100\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3200 - accuracy: 0.8320 - val_loss: 0.3461 - val_accuracy: 0.8325\n",
      "Epoch 20/100\n",
      "310/310 [==============================] - 1s 5ms/step - loss: 0.3181 - accuracy: 0.8322 - val_loss: 0.3451 - val_accuracy: 0.8329\n",
      "Epoch 21/100\n",
      "310/310 [==============================] - 1s 5ms/step - loss: 0.3185 - accuracy: 0.8325 - val_loss: 0.3592 - val_accuracy: 0.8325\n",
      "Epoch 22/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3162 - accuracy: 0.8334 - val_loss: 0.3551 - val_accuracy: 0.8325\n",
      "Epoch 23/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3171 - accuracy: 0.8334 - val_loss: 0.3518 - val_accuracy: 0.8325\n",
      "Epoch 24/100\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3171 - accuracy: 0.8329 - val_loss: 0.3600 - val_accuracy: 0.8301\n",
      "Epoch 25/100\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3171 - accuracy: 0.8335 - val_loss: 0.3572 - val_accuracy: 0.8321\n",
      "Epoch 26/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3173 - accuracy: 0.8319 - val_loss: 0.3586 - val_accuracy: 0.8313\n",
      "Epoch 27/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3165 - accuracy: 0.8339 - val_loss: 0.3602 - val_accuracy: 0.8317\n",
      "Epoch 28/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3172 - accuracy: 0.8306 - val_loss: 0.3672 - val_accuracy: 0.8297\n",
      "Epoch 29/100\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3156 - accuracy: 0.8329 - val_loss: 0.3583 - val_accuracy: 0.8325\n",
      "Epoch 30/100\n",
      "310/310 [==============================] - 2s 6ms/step - loss: 0.3161 - accuracy: 0.8329 - val_loss: 0.3627 - val_accuracy: 0.8317\n",
      "Epoch 31/100\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3165 - accuracy: 0.8326 - val_loss: 0.3698 - val_accuracy: 0.8301\n",
      "Epoch 32/100\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3164 - accuracy: 0.8316 - val_loss: 0.3681 - val_accuracy: 0.8317\n",
      "Epoch 33/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3153 - accuracy: 0.8315 - val_loss: 0.3552 - val_accuracy: 0.8325\n",
      "Epoch 34/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3160 - accuracy: 0.8333 - val_loss: 0.3743 - val_accuracy: 0.8313\n",
      "Epoch 35/100\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3176 - accuracy: 0.8315 - val_loss: 0.3483 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "310/310 [==============================] - 1s 5ms/step - loss: 0.3164 - accuracy: 0.8330 - val_loss: 0.3606 - val_accuracy: 0.8301\n",
      "Epoch 37/100\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3159 - accuracy: 0.8315 - val_loss: 0.3504 - val_accuracy: 0.8341\n",
      "Epoch 38/100\n",
      "310/310 [==============================] - 1s 5ms/step - loss: 0.3152 - accuracy: 0.8323 - val_loss: 0.3707 - val_accuracy: 0.8289\n",
      "Epoch 39/100\n",
      "310/310 [==============================] - 1s 5ms/step - loss: 0.3169 - accuracy: 0.8330 - val_loss: 0.3488 - val_accuracy: 0.8333\n",
      "Epoch 40/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3163 - accuracy: 0.8333 - val_loss: 0.3702 - val_accuracy: 0.8289\n",
      "Epoch 41/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3153 - accuracy: 0.8330 - val_loss: 0.3693 - val_accuracy: 0.8293\n",
      "Epoch 42/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3154 - accuracy: 0.8324 - val_loss: 0.3605 - val_accuracy: 0.8321\n",
      "Epoch 43/100\n",
      "310/310 [==============================] - 2s 6ms/step - loss: 0.3154 - accuracy: 0.8324 - val_loss: 0.3786 - val_accuracy: 0.8293\n",
      "Epoch 44/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3155 - accuracy: 0.8336 - val_loss: 0.3714 - val_accuracy: 0.8321\n",
      "Epoch 45/100\n",
      "310/310 [==============================] - 1s 5ms/step - loss: 0.3151 - accuracy: 0.8327 - val_loss: 0.3808 - val_accuracy: 0.8285\n",
      "Epoch 46/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3160 - accuracy: 0.8335 - val_loss: 0.3811 - val_accuracy: 0.8305\n",
      "Epoch 47/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3171 - accuracy: 0.8331 - val_loss: 0.3593 - val_accuracy: 0.8333\n",
      "Epoch 48/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3153 - accuracy: 0.8316 - val_loss: 0.3641 - val_accuracy: 0.8329\n",
      "Epoch 49/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3138 - accuracy: 0.8329 - val_loss: 0.3775 - val_accuracy: 0.8301\n",
      "Epoch 50/100\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3159 - accuracy: 0.8319 - val_loss: 0.3774 - val_accuracy: 0.8293\n",
      "Epoch 51/100\n",
      "310/310 [==============================] - 2s 6ms/step - loss: 0.3159 - accuracy: 0.8312 - val_loss: 0.3864 - val_accuracy: 0.8305\n",
      "Epoch 52/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3159 - accuracy: 0.8324 - val_loss: 0.3806 - val_accuracy: 0.8309\n",
      "Epoch 53/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3131 - accuracy: 0.8322 - val_loss: 0.3754 - val_accuracy: 0.8313\n",
      "Epoch 54/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3150 - accuracy: 0.8336 - val_loss: 0.3887 - val_accuracy: 0.8277\n",
      "Epoch 55/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3141 - accuracy: 0.8329 - val_loss: 0.3808 - val_accuracy: 0.8305\n",
      "Epoch 56/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3152 - accuracy: 0.8323 - val_loss: 0.3801 - val_accuracy: 0.8313\n",
      "Epoch 57/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3149 - accuracy: 0.8332 - val_loss: 0.3731 - val_accuracy: 0.8317\n",
      "Epoch 58/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3148 - accuracy: 0.8337 - val_loss: 0.3686 - val_accuracy: 0.8313\n",
      "Epoch 59/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3149 - accuracy: 0.8319 - val_loss: 0.3728 - val_accuracy: 0.8317\n",
      "Epoch 60/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3182 - accuracy: 0.8301 - val_loss: 0.3584 - val_accuracy: 0.8329\n",
      "Epoch 61/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3150 - accuracy: 0.8328 - val_loss: 0.3716 - val_accuracy: 0.8309\n",
      "Epoch 62/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3150 - accuracy: 0.8328 - val_loss: 0.3728 - val_accuracy: 0.8309\n",
      "Epoch 63/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3150 - accuracy: 0.8308 - val_loss: 0.3697 - val_accuracy: 0.8313\n",
      "Epoch 64/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3137 - accuracy: 0.8313 - val_loss: 0.3867 - val_accuracy: 0.8281\n",
      "Epoch 65/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3157 - accuracy: 0.8309 - val_loss: 0.3769 - val_accuracy: 0.8321\n",
      "Epoch 66/100\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3140 - accuracy: 0.8321 - val_loss: 0.3820 - val_accuracy: 0.8309\n",
      "Epoch 67/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3150 - accuracy: 0.8325 - val_loss: 0.3647 - val_accuracy: 0.8329\n",
      "Epoch 68/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3154 - accuracy: 0.8319 - val_loss: 0.4024 - val_accuracy: 0.8293\n",
      "Epoch 69/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3144 - accuracy: 0.8341 - val_loss: 0.3804 - val_accuracy: 0.8309\n",
      "Epoch 70/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3142 - accuracy: 0.8305 - val_loss: 0.3802 - val_accuracy: 0.8313\n",
      "Epoch 71/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3149 - accuracy: 0.8328 - val_loss: 0.3880 - val_accuracy: 0.8293\n",
      "Epoch 72/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3142 - accuracy: 0.8315 - val_loss: 0.3745 - val_accuracy: 0.8317\n",
      "Epoch 73/100\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3137 - accuracy: 0.8325 - val_loss: 0.3721 - val_accuracy: 0.8321\n",
      "Epoch 74/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3147 - accuracy: 0.8321 - val_loss: 0.3826 - val_accuracy: 0.8305\n",
      "Epoch 75/100\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3142 - accuracy: 0.8324 - val_loss: 0.3814 - val_accuracy: 0.8313\n",
      "Epoch 76/100\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3133 - accuracy: 0.8320 - val_loss: 0.3954 - val_accuracy: 0.8289\n",
      "Epoch 77/100\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3159 - accuracy: 0.8329 - val_loss: 0.3647 - val_accuracy: 0.8317\n",
      "Epoch 78/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3142 - accuracy: 0.8328 - val_loss: 0.3790 - val_accuracy: 0.8297\n",
      "Epoch 79/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3147 - accuracy: 0.8310 - val_loss: 0.3862 - val_accuracy: 0.8293\n",
      "Epoch 80/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3154 - accuracy: 0.8306 - val_loss: 0.3717 - val_accuracy: 0.8301\n",
      "Epoch 81/100\n",
      "310/310 [==============================] - 1s 5ms/step - loss: 0.3134 - accuracy: 0.8330 - val_loss: 0.3881 - val_accuracy: 0.8285\n",
      "Epoch 82/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3137 - accuracy: 0.8325 - val_loss: 0.3678 - val_accuracy: 0.8321\n",
      "Epoch 83/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3146 - accuracy: 0.8311 - val_loss: 0.3800 - val_accuracy: 0.8321\n",
      "Epoch 84/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3145 - accuracy: 0.8328 - val_loss: 0.3785 - val_accuracy: 0.8321\n",
      "Epoch 85/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3146 - accuracy: 0.8329 - val_loss: 0.3944 - val_accuracy: 0.8281\n",
      "Epoch 86/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3143 - accuracy: 0.8316 - val_loss: 0.3870 - val_accuracy: 0.8301\n",
      "Epoch 87/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3140 - accuracy: 0.8342 - val_loss: 0.3536 - val_accuracy: 0.8337\n",
      "Epoch 88/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3149 - accuracy: 0.8323 - val_loss: 0.3910 - val_accuracy: 0.8297\n",
      "Epoch 89/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3149 - accuracy: 0.8302 - val_loss: 0.3879 - val_accuracy: 0.8293\n",
      "Epoch 90/100\n",
      "310/310 [==============================] - 2s 6ms/step - loss: 0.3144 - accuracy: 0.8328 - val_loss: 0.3802 - val_accuracy: 0.8313\n",
      "Epoch 91/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3142 - accuracy: 0.8336 - val_loss: 0.3992 - val_accuracy: 0.8289\n",
      "Epoch 92/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3143 - accuracy: 0.8309 - val_loss: 0.3993 - val_accuracy: 0.8297\n",
      "Epoch 93/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3126 - accuracy: 0.8328 - val_loss: 0.3920 - val_accuracy: 0.8309\n",
      "Epoch 94/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3143 - accuracy: 0.8343 - val_loss: 0.4000 - val_accuracy: 0.8301\n",
      "Epoch 95/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3143 - accuracy: 0.8316 - val_loss: 0.4009 - val_accuracy: 0.8301\n",
      "Epoch 96/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3142 - accuracy: 0.8307 - val_loss: 0.4030 - val_accuracy: 0.8285\n",
      "Epoch 97/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3143 - accuracy: 0.8330 - val_loss: 0.4156 - val_accuracy: 0.8265\n",
      "Epoch 98/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3139 - accuracy: 0.8300 - val_loss: 0.3957 - val_accuracy: 0.8305\n",
      "Epoch 99/100\n",
      "310/310 [==============================] - 2s 5ms/step - loss: 0.3126 - accuracy: 0.8330 - val_loss: 0.4097 - val_accuracy: 0.8289\n",
      "Epoch 100/100\n",
      "310/310 [==============================] - 1s 4ms/step - loss: 0.3160 - accuracy: 0.8324 - val_loss: 0.3692 - val_accuracy: 0.8301\n",
      "97/97 - 0s - loss: 0.3503 - accuracy: 0.8247 - 226ms/epoch - 2ms/step\n",
      "Test loss:  0.35030415654182434\n",
      "Test accuracy:  0.8247256278991699\n"
     ]
    }
   ],
   "source": [
    "model_gen.fit(x_train, y_train, batch_size=32, epochs=100, validation_split=0.2)\n",
    "test_score = model_gen.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss: \", test_score[0])\n",
    "print(\"Test accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde7b245",
   "metadata": {},
   "source": [
    "\"normal\": 0, \"banker\": 1, \"spyware\": 2, \"backdoor\": 3, \"ransomware\": 4, \"pua\": 5, \"downloader\": 6, \"deceptor\": 7, \"cryptominer\":8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5271fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys = list(hash_lookup.keys())\n",
    "# keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "933fb488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7174b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hash_vals = [i+'.csv' for i in keys]\n",
    "# ct = 0\n",
    "# full_labels = []\n",
    "# for i in hash_vals:\n",
    "#     full_labels.append(df_master.query('hash == @i').goal_encoded.unique()[0])\n",
    "#     ct+=1\n",
    "#     if ct%100 == 0:\n",
    "#         print(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71271587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_labels = np.array(full_labels)\n",
    "# np.unique(full_labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16803e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Target'] = full_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed220957",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process Profiling-&gt;Thread Exit</th>\n",
       "      <th>Process Profiling-&gt;Thread Create</th>\n",
       "      <th>Thread Exit-&gt;Process Profiling</th>\n",
       "      <th>Thread Exit-&gt;Thread Exit</th>\n",
       "      <th>Thread Exit-&gt;Thread Create</th>\n",
       "      <th>Thread Exit-&gt;ReadFile</th>\n",
       "      <th>Thread Exit-&gt;RegQueryKey</th>\n",
       "      <th>Thread Exit-&gt;RegOpenKey</th>\n",
       "      <th>Thread Exit-&gt;RegQueryValue</th>\n",
       "      <th>Thread Exit-&gt;CreateFileMapping</th>\n",
       "      <th>...</th>\n",
       "      <th>QueryDeviceRelations-&gt;ReadFile</th>\n",
       "      <th>QueryDeviceRelations-&gt;RegQueryKey</th>\n",
       "      <th>QueryDeviceRelations-&gt;RegOpenKey</th>\n",
       "      <th>QueryDeviceRelations-&gt;RegQueryValue</th>\n",
       "      <th>QueryDeviceRelations-&gt;CreateFile</th>\n",
       "      <th>QueryDeviceRelations-&gt;QueryBasicInformationFile</th>\n",
       "      <th>TCP Accept-&gt;TCP TCPCopy</th>\n",
       "      <th>CreatePipe-&gt;CreateFile</th>\n",
       "      <th>RegSaveKey-&gt;WriteFile</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8707</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8708</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8709</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8710</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8711</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8712 rows Ã— 1738 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Process Profiling->Thread Exit  Process Profiling->Thread Create  \\\n",
       "0                                  1                                 0   \n",
       "1                                  1                                 0   \n",
       "2                                  0                                 1   \n",
       "3                                  0                                 0   \n",
       "4                                  1                                 0   \n",
       "...                              ...                               ...   \n",
       "8707                               0                                 0   \n",
       "8708                               0                                 0   \n",
       "8709                               0                                 0   \n",
       "8710                               0                                 0   \n",
       "8711                               0                                 0   \n",
       "\n",
       "      Thread Exit->Process Profiling  Thread Exit->Thread Exit  \\\n",
       "0                                  0                         0   \n",
       "1                                  0                         0   \n",
       "2                                  0                         0   \n",
       "3                                  0                         0   \n",
       "4                                  0                         0   \n",
       "...                              ...                       ...   \n",
       "8707                               0                         0   \n",
       "8708                               0                         0   \n",
       "8709                               0                         0   \n",
       "8710                               0                         0   \n",
       "8711                               0                         0   \n",
       "\n",
       "      Thread Exit->Thread Create  Thread Exit->ReadFile  \\\n",
       "0                            1.0                    0.0   \n",
       "1                            1.0                    0.0   \n",
       "2                            0.0                    0.0   \n",
       "3                            0.0                    0.0   \n",
       "4                            1.0                    0.0   \n",
       "...                          ...                    ...   \n",
       "8707                         0.0                    0.0   \n",
       "8708                         0.0                    0.0   \n",
       "8709                         0.0                    0.0   \n",
       "8710                         0.0                    0.0   \n",
       "8711                         0.0                    0.0   \n",
       "\n",
       "      Thread Exit->RegQueryKey  Thread Exit->RegOpenKey  \\\n",
       "0                          0.0                      0.0   \n",
       "1                          0.0                      0.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          0.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "8707                       0.0                      0.0   \n",
       "8708                       0.0                      0.0   \n",
       "8709                       0.0                      0.0   \n",
       "8710                       0.0                      0.0   \n",
       "8711                       0.0                      0.0   \n",
       "\n",
       "      Thread Exit->RegQueryValue  Thread Exit->CreateFileMapping  ...  \\\n",
       "0                            0.0                             0.0  ...   \n",
       "1                            0.0                             0.0  ...   \n",
       "2                            0.0                             0.0  ...   \n",
       "3                            0.0                             0.0  ...   \n",
       "4                            0.0                             0.0  ...   \n",
       "...                          ...                             ...  ...   \n",
       "8707                         0.0                             0.0  ...   \n",
       "8708                         0.0                             0.0  ...   \n",
       "8709                         0.0                             0.0  ...   \n",
       "8710                         0.0                             0.0  ...   \n",
       "8711                         0.0                             0.0  ...   \n",
       "\n",
       "      QueryDeviceRelations->ReadFile  QueryDeviceRelations->RegQueryKey  \\\n",
       "0                                0.0                                0.0   \n",
       "1                                0.0                                0.0   \n",
       "2                                0.0                                0.0   \n",
       "3                                0.0                                0.0   \n",
       "4                                0.0                                0.0   \n",
       "...                              ...                                ...   \n",
       "8707                             0.0                                0.0   \n",
       "8708                             0.0                                0.0   \n",
       "8709                             0.0                                0.0   \n",
       "8710                             0.0                                0.0   \n",
       "8711                             0.0                                0.0   \n",
       "\n",
       "      QueryDeviceRelations->RegOpenKey  QueryDeviceRelations->RegQueryValue  \\\n",
       "0                                  0.0                                  0.0   \n",
       "1                                  0.0                                  0.0   \n",
       "2                                  0.0                                  0.0   \n",
       "3                                  0.0                                  0.0   \n",
       "4                                  0.0                                  0.0   \n",
       "...                                ...                                  ...   \n",
       "8707                               0.0                                  0.0   \n",
       "8708                               0.0                                  0.0   \n",
       "8709                               0.0                                  0.0   \n",
       "8710                               0.0                                  0.0   \n",
       "8711                               0.0                                  0.0   \n",
       "\n",
       "      QueryDeviceRelations->CreateFile  \\\n",
       "0                                  0.0   \n",
       "1                                  0.0   \n",
       "2                                  0.0   \n",
       "3                                  0.0   \n",
       "4                                  0.0   \n",
       "...                                ...   \n",
       "8707                               0.0   \n",
       "8708                               0.0   \n",
       "8709                               0.0   \n",
       "8710                               0.0   \n",
       "8711                               0.0   \n",
       "\n",
       "      QueryDeviceRelations->QueryBasicInformationFile  \\\n",
       "0                                                 0.0   \n",
       "1                                                 0.0   \n",
       "2                                                 0.0   \n",
       "3                                                 0.0   \n",
       "4                                                 0.0   \n",
       "...                                               ...   \n",
       "8707                                              0.0   \n",
       "8708                                              0.0   \n",
       "8709                                              0.0   \n",
       "8710                                              0.0   \n",
       "8711                                              0.0   \n",
       "\n",
       "      TCP Accept->TCP TCPCopy  CreatePipe->CreateFile  RegSaveKey->WriteFile  \\\n",
       "0                           0                       0                      0   \n",
       "1                           0                       0                      0   \n",
       "2                           0                       0                      0   \n",
       "3                           0                       0                      0   \n",
       "4                           0                       0                      0   \n",
       "...                       ...                     ...                    ...   \n",
       "8707                        0                       0                      0   \n",
       "8708                        0                       0                      0   \n",
       "8709                        0                       0                      0   \n",
       "8710                        0                       0                      0   \n",
       "8711                        0                       0                      0   \n",
       "\n",
       "      Labels  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "8707       8  \n",
       "8708       8  \n",
       "8709       8  \n",
       "8710       8  \n",
       "8711       8  \n",
       "\n",
       "[8712 rows x 1738 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8195df",
   "metadata": {},
   "source": [
    "## Specialized detector for Banker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b81b592",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process Profiling-&gt;Thread Exit</th>\n",
       "      <th>Process Profiling-&gt;Thread Create</th>\n",
       "      <th>Thread Exit-&gt;Process Profiling</th>\n",
       "      <th>Thread Exit-&gt;Thread Exit</th>\n",
       "      <th>Thread Exit-&gt;Thread Create</th>\n",
       "      <th>Thread Exit-&gt;ReadFile</th>\n",
       "      <th>Thread Exit-&gt;RegQueryKey</th>\n",
       "      <th>Thread Exit-&gt;RegOpenKey</th>\n",
       "      <th>Thread Exit-&gt;RegQueryValue</th>\n",
       "      <th>Thread Exit-&gt;CreateFileMapping</th>\n",
       "      <th>...</th>\n",
       "      <th>QueryDeviceRelations-&gt;ReadFile</th>\n",
       "      <th>QueryDeviceRelations-&gt;RegQueryKey</th>\n",
       "      <th>QueryDeviceRelations-&gt;RegOpenKey</th>\n",
       "      <th>QueryDeviceRelations-&gt;RegQueryValue</th>\n",
       "      <th>QueryDeviceRelations-&gt;CreateFile</th>\n",
       "      <th>QueryDeviceRelations-&gt;QueryBasicInformationFile</th>\n",
       "      <th>TCP Accept-&gt;TCP TCPCopy</th>\n",
       "      <th>CreatePipe-&gt;CreateFile</th>\n",
       "      <th>RegSaveKey-&gt;WriteFile</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5834</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5835</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5836</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5837</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.170266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.170266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1936 rows Ã— 1738 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Process Profiling->Thread Exit  Process Profiling->Thread Create  \\\n",
       "0                                  1                                 0   \n",
       "1                                  1                                 0   \n",
       "2                                  0                                 1   \n",
       "3                                  0                                 0   \n",
       "4                                  1                                 0   \n",
       "...                              ...                               ...   \n",
       "5833                               0                                 1   \n",
       "5834                               0                                 1   \n",
       "5835                               0                                 0   \n",
       "5836                               0                                 1   \n",
       "5837                               0                                 0   \n",
       "\n",
       "      Thread Exit->Process Profiling  Thread Exit->Thread Exit  \\\n",
       "0                                  0                         0   \n",
       "1                                  0                         0   \n",
       "2                                  0                         0   \n",
       "3                                  0                         0   \n",
       "4                                  0                         0   \n",
       "...                              ...                       ...   \n",
       "5833                               0                         0   \n",
       "5834                               0                         0   \n",
       "5835                               0                         0   \n",
       "5836                               0                         0   \n",
       "5837                               0                         0   \n",
       "\n",
       "      Thread Exit->Thread Create  Thread Exit->ReadFile  \\\n",
       "0                            1.0                    0.0   \n",
       "1                            1.0                    0.0   \n",
       "2                            0.0                    0.0   \n",
       "3                            0.0                    0.0   \n",
       "4                            1.0                    0.0   \n",
       "...                          ...                    ...   \n",
       "5833                         0.0                    0.0   \n",
       "5834                         0.0                    0.0   \n",
       "5835                         0.0                    0.0   \n",
       "5836                         0.0                    0.0   \n",
       "5837                         0.0                    0.0   \n",
       "\n",
       "      Thread Exit->RegQueryKey  Thread Exit->RegOpenKey  \\\n",
       "0                     0.000000                      0.0   \n",
       "1                     0.000000                      0.0   \n",
       "2                     0.000000                      0.0   \n",
       "3                     0.000000                      0.0   \n",
       "4                     0.000000                      0.0   \n",
       "...                        ...                      ...   \n",
       "5833                  0.000000                      0.0   \n",
       "5834                  0.000000                      0.0   \n",
       "5835                  0.000000                      0.0   \n",
       "5836                  0.000000                      0.0   \n",
       "5837                  0.170266                      0.0   \n",
       "\n",
       "      Thread Exit->RegQueryValue  Thread Exit->CreateFileMapping  ...  \\\n",
       "0                       0.000000                             0.0  ...   \n",
       "1                       0.000000                             0.0  ...   \n",
       "2                       0.000000                             0.0  ...   \n",
       "3                       0.000000                             0.0  ...   \n",
       "4                       0.000000                             0.0  ...   \n",
       "...                          ...                             ...  ...   \n",
       "5833                    0.000000                             0.0  ...   \n",
       "5834                    0.000000                             0.0  ...   \n",
       "5835                    0.000000                             0.0  ...   \n",
       "5836                    0.000000                             0.0  ...   \n",
       "5837                    0.170266                             0.0  ...   \n",
       "\n",
       "      QueryDeviceRelations->ReadFile  QueryDeviceRelations->RegQueryKey  \\\n",
       "0                                0.0                                0.0   \n",
       "1                                0.0                                0.0   \n",
       "2                                0.0                                0.0   \n",
       "3                                0.0                                0.0   \n",
       "4                                0.0                                0.0   \n",
       "...                              ...                                ...   \n",
       "5833                             0.0                                0.0   \n",
       "5834                             0.0                                0.0   \n",
       "5835                             0.0                                0.0   \n",
       "5836                             0.0                                0.0   \n",
       "5837                             0.0                                0.0   \n",
       "\n",
       "      QueryDeviceRelations->RegOpenKey  QueryDeviceRelations->RegQueryValue  \\\n",
       "0                                  0.0                                  0.0   \n",
       "1                                  0.0                                  0.0   \n",
       "2                                  0.0                                  0.0   \n",
       "3                                  0.0                                  0.0   \n",
       "4                                  0.0                                  0.0   \n",
       "...                                ...                                  ...   \n",
       "5833                               0.0                                  0.0   \n",
       "5834                               0.0                                  0.0   \n",
       "5835                               0.0                                  0.0   \n",
       "5836                               0.0                                  0.0   \n",
       "5837                               0.0                                  0.0   \n",
       "\n",
       "      QueryDeviceRelations->CreateFile  \\\n",
       "0                                  0.0   \n",
       "1                                  0.0   \n",
       "2                                  0.0   \n",
       "3                                  0.0   \n",
       "4                                  0.0   \n",
       "...                                ...   \n",
       "5833                               0.0   \n",
       "5834                               0.0   \n",
       "5835                               0.0   \n",
       "5836                               0.0   \n",
       "5837                               0.0   \n",
       "\n",
       "      QueryDeviceRelations->QueryBasicInformationFile  \\\n",
       "0                                                 0.0   \n",
       "1                                                 0.0   \n",
       "2                                                 0.0   \n",
       "3                                                 0.0   \n",
       "4                                                 0.0   \n",
       "...                                               ...   \n",
       "5833                                              0.0   \n",
       "5834                                              0.0   \n",
       "5835                                              0.0   \n",
       "5836                                              0.0   \n",
       "5837                                              0.0   \n",
       "\n",
       "      TCP Accept->TCP TCPCopy  CreatePipe->CreateFile  RegSaveKey->WriteFile  \\\n",
       "0                           0                       0                      0   \n",
       "1                           0                       0                      0   \n",
       "2                           0                       0                      0   \n",
       "3                           0                       0                      0   \n",
       "4                           0                       0                      0   \n",
       "...                       ...                     ...                    ...   \n",
       "5833                        0                       0                      0   \n",
       "5834                        0                       0                      0   \n",
       "5835                        0                       0                      0   \n",
       "5836                        0                       0                      0   \n",
       "5837                        0                       0                      0   \n",
       "\n",
       "      Labels  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "5833       1  \n",
       "5834       1  \n",
       "5835       1  \n",
       "5836       1  \n",
       "5837       1  \n",
       "\n",
       "[1936 rows x 1738 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_banker = df_master[(df_master.Labels == 0) | (df_master.Labels == 1)] \n",
    "df_banker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "697da04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    968\n",
       "1    968\n",
       "Name: Labels, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_banker['Labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ad350d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_banker.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d08a3e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_banker['Labels']\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ebd5c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1548, 1737)\n",
      "(1548,)\n",
      "(388, 1737)\n",
      "(388,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = tts(X,y,test_size=0.2) \n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c9694f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1737)]            0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 40)                69520     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 20)                820       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,361\n",
      "Trainable params: 70,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(1737,))\n",
    "\n",
    "x = tf.keras.layers.Dense(40,activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dense(20,activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model_banker = tf.keras.Model(inputs=inputs,outputs=output)\n",
    "model_banker.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf559d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_banker.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0d1c0b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ok_sikha/anaconda3/envs/tf_gpu_segnet/lib/python3.9/site-packages/keras/backend.py:5673: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 10ms/step - loss: 0.6214 - accuracy: 0.6898 - val_loss: 0.5362 - val_accuracy: 0.8000\n",
      "Epoch 2/100\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.4894 - accuracy: 0.8015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ok_sikha/anaconda3/envs/tf_gpu_segnet/lib/python3.9/site-packages/keras/backend.py:5673: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.8053 - val_loss: 0.3786 - val_accuracy: 0.8258\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.3425 - accuracy: 0.8069 - val_loss: 0.3339 - val_accuracy: 0.8032\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3111 - accuracy: 0.8312 - val_loss: 0.3232 - val_accuracy: 0.8000\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.2825 - accuracy: 0.8425 - val_loss: 0.3157 - val_accuracy: 0.8258\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.2755 - accuracy: 0.8393 - val_loss: 0.3161 - val_accuracy: 0.7968\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.2747 - accuracy: 0.8215 - val_loss: 0.3156 - val_accuracy: 0.7968\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.2684 - accuracy: 0.8384 - val_loss: 0.3195 - val_accuracy: 0.8000\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.2636 - accuracy: 0.8401 - val_loss: 0.3124 - val_accuracy: 0.8258\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2598 - accuracy: 0.8352 - val_loss: 0.3191 - val_accuracy: 0.8000\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2601 - accuracy: 0.8328 - val_loss: 0.3162 - val_accuracy: 0.8065\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2552 - accuracy: 0.8449 - val_loss: 0.3110 - val_accuracy: 0.8290\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2550 - accuracy: 0.8384 - val_loss: 0.3120 - val_accuracy: 0.8290\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.2498 - accuracy: 0.8465 - val_loss: 0.3210 - val_accuracy: 0.8097\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.2508 - accuracy: 0.8425 - val_loss: 0.3203 - val_accuracy: 0.8065\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2505 - accuracy: 0.8344 - val_loss: 0.3176 - val_accuracy: 0.8065\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2499 - accuracy: 0.8360 - val_loss: 0.3202 - val_accuracy: 0.8065\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2497 - accuracy: 0.8401 - val_loss: 0.3263 - val_accuracy: 0.8097\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2496 - accuracy: 0.8368 - val_loss: 0.3180 - val_accuracy: 0.8065\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2447 - accuracy: 0.8384 - val_loss: 0.3212 - val_accuracy: 0.8065\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2521 - accuracy: 0.8352 - val_loss: 0.3299 - val_accuracy: 0.8097\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2517 - accuracy: 0.8376 - val_loss: 0.3153 - val_accuracy: 0.8097\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2469 - accuracy: 0.8271 - val_loss: 0.3172 - val_accuracy: 0.8323\n",
      "Epoch 24/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2478 - accuracy: 0.8409 - val_loss: 0.3206 - val_accuracy: 0.8097\n",
      "Epoch 25/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2452 - accuracy: 0.8312 - val_loss: 0.3219 - val_accuracy: 0.8323\n",
      "Epoch 26/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2459 - accuracy: 0.8473 - val_loss: 0.3239 - val_accuracy: 0.8290\n",
      "Epoch 27/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2455 - accuracy: 0.8368 - val_loss: 0.3261 - val_accuracy: 0.8065\n",
      "Epoch 28/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2472 - accuracy: 0.8401 - val_loss: 0.3276 - val_accuracy: 0.8097\n",
      "Epoch 29/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2429 - accuracy: 0.8433 - val_loss: 0.3262 - val_accuracy: 0.8323\n",
      "Epoch 30/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2417 - accuracy: 0.8514 - val_loss: 0.3309 - val_accuracy: 0.8097\n",
      "Epoch 31/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2421 - accuracy: 0.8473 - val_loss: 0.3347 - val_accuracy: 0.8097\n",
      "Epoch 32/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2456 - accuracy: 0.8336 - val_loss: 0.3339 - val_accuracy: 0.8097\n",
      "Epoch 33/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2451 - accuracy: 0.8344 - val_loss: 0.3322 - val_accuracy: 0.8065\n",
      "Epoch 34/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2468 - accuracy: 0.8409 - val_loss: 0.3310 - val_accuracy: 0.8323\n",
      "Epoch 35/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2431 - accuracy: 0.8401 - val_loss: 0.3357 - val_accuracy: 0.8097\n",
      "Epoch 36/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2496 - accuracy: 0.8441 - val_loss: 0.3360 - val_accuracy: 0.8323\n",
      "Epoch 37/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2432 - accuracy: 0.8425 - val_loss: 0.3388 - val_accuracy: 0.8097\n",
      "Epoch 38/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2440 - accuracy: 0.8425 - val_loss: 0.3375 - val_accuracy: 0.8065\n",
      "Epoch 39/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2428 - accuracy: 0.8457 - val_loss: 0.3420 - val_accuracy: 0.8097\n",
      "Epoch 40/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2425 - accuracy: 0.8368 - val_loss: 0.3412 - val_accuracy: 0.8290\n",
      "Epoch 41/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2413 - accuracy: 0.8425 - val_loss: 0.3439 - val_accuracy: 0.8097\n",
      "Epoch 42/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2464 - accuracy: 0.8441 - val_loss: 0.3444 - val_accuracy: 0.8323\n",
      "Epoch 43/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.2412 - accuracy: 0.8409 - val_loss: 0.3438 - val_accuracy: 0.8323\n",
      "Epoch 44/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2414 - accuracy: 0.8554 - val_loss: 0.3502 - val_accuracy: 0.8129\n",
      "Epoch 45/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2413 - accuracy: 0.8506 - val_loss: 0.3462 - val_accuracy: 0.8065\n",
      "Epoch 46/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2417 - accuracy: 0.8417 - val_loss: 0.3475 - val_accuracy: 0.8065\n",
      "Epoch 47/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2424 - accuracy: 0.8393 - val_loss: 0.3525 - val_accuracy: 0.8097\n",
      "Epoch 48/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2440 - accuracy: 0.8320 - val_loss: 0.3485 - val_accuracy: 0.8290\n",
      "Epoch 49/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2420 - accuracy: 0.8425 - val_loss: 0.3533 - val_accuracy: 0.8065\n",
      "Epoch 50/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2406 - accuracy: 0.8393 - val_loss: 0.3517 - val_accuracy: 0.8065\n",
      "Epoch 51/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2390 - accuracy: 0.8352 - val_loss: 0.3544 - val_accuracy: 0.8065\n",
      "Epoch 52/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2428 - accuracy: 0.8376 - val_loss: 0.3564 - val_accuracy: 0.8290\n",
      "Epoch 53/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2420 - accuracy: 0.8336 - val_loss: 0.3555 - val_accuracy: 0.8065\n",
      "Epoch 54/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2420 - accuracy: 0.8457 - val_loss: 0.3553 - val_accuracy: 0.8065\n",
      "Epoch 55/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2395 - accuracy: 0.8522 - val_loss: 0.3578 - val_accuracy: 0.8065\n",
      "Epoch 56/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2403 - accuracy: 0.8498 - val_loss: 0.3578 - val_accuracy: 0.8065\n",
      "Epoch 57/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2392 - accuracy: 0.8481 - val_loss: 0.3596 - val_accuracy: 0.8065\n",
      "Epoch 58/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2415 - accuracy: 0.8433 - val_loss: 0.3606 - val_accuracy: 0.8065\n",
      "Epoch 59/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2393 - accuracy: 0.8522 - val_loss: 0.3612 - val_accuracy: 0.8065\n",
      "Epoch 60/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2385 - accuracy: 0.8409 - val_loss: 0.3625 - val_accuracy: 0.8065\n",
      "Epoch 61/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.2402 - accuracy: 0.8441 - val_loss: 0.3671 - val_accuracy: 0.8065\n",
      "Epoch 62/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2383 - accuracy: 0.8465 - val_loss: 0.3680 - val_accuracy: 0.8065\n",
      "Epoch 63/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2394 - accuracy: 0.8473 - val_loss: 0.3671 - val_accuracy: 0.8065\n",
      "Epoch 64/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2392 - accuracy: 0.8489 - val_loss: 0.3680 - val_accuracy: 0.8065\n",
      "Epoch 65/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2409 - accuracy: 0.8449 - val_loss: 0.3676 - val_accuracy: 0.8065\n",
      "Epoch 66/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2389 - accuracy: 0.8473 - val_loss: 0.3711 - val_accuracy: 0.8065\n",
      "Epoch 67/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2405 - accuracy: 0.8465 - val_loss: 0.3716 - val_accuracy: 0.8065\n",
      "Epoch 68/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2387 - accuracy: 0.8530 - val_loss: 0.3749 - val_accuracy: 0.8065\n",
      "Epoch 69/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2404 - accuracy: 0.8449 - val_loss: 0.3741 - val_accuracy: 0.8065\n",
      "Epoch 70/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2379 - accuracy: 0.8595 - val_loss: 0.3763 - val_accuracy: 0.8065\n",
      "Epoch 71/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2399 - accuracy: 0.8546 - val_loss: 0.3825 - val_accuracy: 0.8097\n",
      "Epoch 72/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2419 - accuracy: 0.8457 - val_loss: 0.3778 - val_accuracy: 0.8065\n",
      "Epoch 73/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2386 - accuracy: 0.8441 - val_loss: 0.3807 - val_accuracy: 0.8065\n",
      "Epoch 74/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2394 - accuracy: 0.8473 - val_loss: 0.3832 - val_accuracy: 0.8065\n",
      "Epoch 75/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2402 - accuracy: 0.8417 - val_loss: 0.3810 - val_accuracy: 0.8065\n",
      "Epoch 76/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2379 - accuracy: 0.8409 - val_loss: 0.3812 - val_accuracy: 0.8065\n",
      "Epoch 77/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2394 - accuracy: 0.8522 - val_loss: 0.3818 - val_accuracy: 0.8065\n",
      "Epoch 78/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2390 - accuracy: 0.8498 - val_loss: 0.3862 - val_accuracy: 0.8065\n",
      "Epoch 79/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2376 - accuracy: 0.8538 - val_loss: 0.3865 - val_accuracy: 0.8065\n",
      "Epoch 80/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2358 - accuracy: 0.8473 - val_loss: 0.3867 - val_accuracy: 0.8065\n",
      "Epoch 81/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2380 - accuracy: 0.8465 - val_loss: 0.3884 - val_accuracy: 0.8065\n",
      "Epoch 82/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2380 - accuracy: 0.8433 - val_loss: 0.3920 - val_accuracy: 0.8065\n",
      "Epoch 83/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2393 - accuracy: 0.8401 - val_loss: 0.3922 - val_accuracy: 0.8065\n",
      "Epoch 84/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2394 - accuracy: 0.8498 - val_loss: 0.3945 - val_accuracy: 0.8065\n",
      "Epoch 85/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2383 - accuracy: 0.8481 - val_loss: 0.3941 - val_accuracy: 0.8065\n",
      "Epoch 86/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2388 - accuracy: 0.8506 - val_loss: 0.3957 - val_accuracy: 0.8065\n",
      "Epoch 87/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2385 - accuracy: 0.8449 - val_loss: 0.3966 - val_accuracy: 0.8065\n",
      "Epoch 88/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2388 - accuracy: 0.8441 - val_loss: 0.3998 - val_accuracy: 0.8065\n",
      "Epoch 89/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2371 - accuracy: 0.8393 - val_loss: 0.3975 - val_accuracy: 0.8065\n",
      "Epoch 90/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2399 - accuracy: 0.8506 - val_loss: 0.3977 - val_accuracy: 0.8065\n",
      "Epoch 91/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.2411 - accuracy: 0.8409 - val_loss: 0.3974 - val_accuracy: 0.8290\n",
      "Epoch 92/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2375 - accuracy: 0.8393 - val_loss: 0.4027 - val_accuracy: 0.8065\n",
      "Epoch 93/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.2379 - accuracy: 0.8489 - val_loss: 0.4051 - val_accuracy: 0.8065\n",
      "Epoch 94/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2378 - accuracy: 0.8433 - val_loss: 0.4078 - val_accuracy: 0.8065\n",
      "Epoch 95/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2384 - accuracy: 0.8489 - val_loss: 0.4080 - val_accuracy: 0.8065\n",
      "Epoch 96/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2383 - accuracy: 0.8481 - val_loss: 0.4089 - val_accuracy: 0.8065\n",
      "Epoch 97/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2379 - accuracy: 0.8498 - val_loss: 0.4144 - val_accuracy: 0.8065\n",
      "Epoch 98/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2362 - accuracy: 0.8489 - val_loss: 0.4201 - val_accuracy: 0.8032\n",
      "Epoch 99/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2383 - accuracy: 0.8433 - val_loss: 0.4186 - val_accuracy: 0.8065\n",
      "Epoch 100/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2383 - accuracy: 0.8481 - val_loss: 0.4198 - val_accuracy: 0.8065\n",
      "13/13 - 0s - loss: 0.2590 - accuracy: 0.8325 - 91ms/epoch - 7ms/step\n",
      "Test loss:  0.2590281069278717\n",
      "Test accuracy:  0.8324742317199707\n"
     ]
    }
   ],
   "source": [
    "model_banker.fit(x_train, y_train, batch_size=32, epochs=100, validation_split=0.2)\n",
    "test_score = model_banker.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss: \", test_score[0])\n",
    "print(\"Test accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fae0c6d",
   "metadata": {},
   "source": [
    "## Specialized spyware detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f521977b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_265475/3989978893.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_spyware['Labels'] = df_spyware['Labels'].replace(2, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    968\n",
       "1    968\n",
       "Name: Labels, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spyware = df_master[(df_master.Labels == 0) | (df_master.Labels == 2)] \n",
    "df_spyware['Labels'] = df_spyware['Labels'].replace(2, 1)\n",
    "df_spyware.Labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07e83210",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_spyware.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0974716c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_spyware['Labels']\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fed43bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1548, 1737)\n",
      "(1548,)\n",
      "(388, 1737)\n",
      "(388,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = tts(X,y,test_size=0.2) \n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3808d6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1737)]            0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 40)                69520     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 20)                820       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,361\n",
      "Trainable params: 70,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(1737,))\n",
    "\n",
    "x = tf.keras.layers.Dense(40,activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dense(20,activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model_spyware = tf.keras.Model(inputs=inputs,outputs=output)\n",
    "model_spyware.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e922e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_spyware.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec56bee7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ok_sikha/anaconda3/envs/tf_gpu_segnet/lib/python3.9/site-packages/keras/backend.py:5673: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 10ms/step - loss: 0.6431 - accuracy: 0.7609 - val_loss: 0.5715 - val_accuracy: 0.8484\n",
      "Epoch 2/100\n",
      "18/39 [============>.................] - ETA: 0s - loss: 0.5555 - accuracy: 0.8160"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ok_sikha/anaconda3/envs/tf_gpu_segnet/lib/python3.9/site-packages/keras/backend.py:5673: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 6ms/step - loss: 0.5165 - accuracy: 0.8279 - val_loss: 0.4387 - val_accuracy: 0.8548\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.4156 - accuracy: 0.8473 - val_loss: 0.3547 - val_accuracy: 0.8774\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3622 - accuracy: 0.8635 - val_loss: 0.3276 - val_accuracy: 0.8806\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.3369 - accuracy: 0.8724 - val_loss: 0.3189 - val_accuracy: 0.8871\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3111 - accuracy: 0.8788 - val_loss: 0.3176 - val_accuracy: 0.8871\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3022 - accuracy: 0.8821 - val_loss: 0.3150 - val_accuracy: 0.8839\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.2963 - accuracy: 0.8788 - val_loss: 0.3169 - val_accuracy: 0.8839\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2875 - accuracy: 0.8869 - val_loss: 0.3152 - val_accuracy: 0.8903\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2830 - accuracy: 0.8877 - val_loss: 0.3183 - val_accuracy: 0.8839\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2828 - accuracy: 0.8845 - val_loss: 0.3284 - val_accuracy: 0.8839\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2779 - accuracy: 0.8877 - val_loss: 0.3131 - val_accuracy: 0.8871\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2808 - accuracy: 0.8829 - val_loss: 0.3223 - val_accuracy: 0.8871\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2764 - accuracy: 0.8869 - val_loss: 0.3227 - val_accuracy: 0.8903\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2745 - accuracy: 0.8885 - val_loss: 0.3206 - val_accuracy: 0.8871\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2723 - accuracy: 0.8885 - val_loss: 0.3241 - val_accuracy: 0.8871\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.2712 - accuracy: 0.8910 - val_loss: 0.3170 - val_accuracy: 0.8903\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.2722 - accuracy: 0.8901 - val_loss: 0.3204 - val_accuracy: 0.8903\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2761 - accuracy: 0.8885 - val_loss: 0.3325 - val_accuracy: 0.8839\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2717 - accuracy: 0.8893 - val_loss: 0.3198 - val_accuracy: 0.8903\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2665 - accuracy: 0.8910 - val_loss: 0.3388 - val_accuracy: 0.8839\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2674 - accuracy: 0.8926 - val_loss: 0.3250 - val_accuracy: 0.8903\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.2614 - accuracy: 0.8926 - val_loss: 0.3317 - val_accuracy: 0.8903\n",
      "Epoch 24/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2639 - accuracy: 0.8934 - val_loss: 0.3355 - val_accuracy: 0.8903\n",
      "Epoch 25/100\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.2659 - accuracy: 0.8901 - val_loss: 0.3418 - val_accuracy: 0.8903\n",
      "Epoch 26/100\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.2613 - accuracy: 0.8942 - val_loss: 0.3367 - val_accuracy: 0.8935\n",
      "Epoch 27/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.2594 - accuracy: 0.8901 - val_loss: 0.3323 - val_accuracy: 0.8903\n",
      "Epoch 28/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2615 - accuracy: 0.8910 - val_loss: 0.3387 - val_accuracy: 0.8903\n",
      "Epoch 29/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.2609 - accuracy: 0.8918 - val_loss: 0.3429 - val_accuracy: 0.8871\n",
      "Epoch 30/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2588 - accuracy: 0.8918 - val_loss: 0.3459 - val_accuracy: 0.8839\n",
      "Epoch 31/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2645 - accuracy: 0.8901 - val_loss: 0.3422 - val_accuracy: 0.8903\n",
      "Epoch 32/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2573 - accuracy: 0.8934 - val_loss: 0.3467 - val_accuracy: 0.8871\n",
      "Epoch 33/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2611 - accuracy: 0.8901 - val_loss: 0.3576 - val_accuracy: 0.8839\n",
      "Epoch 34/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2663 - accuracy: 0.8918 - val_loss: 0.3441 - val_accuracy: 0.8871\n",
      "Epoch 35/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.2626 - accuracy: 0.8910 - val_loss: 0.3550 - val_accuracy: 0.8871\n",
      "Epoch 36/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2600 - accuracy: 0.8910 - val_loss: 0.3506 - val_accuracy: 0.8871\n",
      "Epoch 37/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2608 - accuracy: 0.8893 - val_loss: 0.3522 - val_accuracy: 0.8903\n",
      "Epoch 38/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.2612 - accuracy: 0.8901 - val_loss: 0.3483 - val_accuracy: 0.8935\n",
      "Epoch 39/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.2592 - accuracy: 0.8893 - val_loss: 0.3487 - val_accuracy: 0.8935\n",
      "Epoch 40/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2616 - accuracy: 0.8901 - val_loss: 0.3480 - val_accuracy: 0.8935\n",
      "Epoch 41/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2570 - accuracy: 0.8926 - val_loss: 0.3498 - val_accuracy: 0.8935\n",
      "Epoch 42/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2541 - accuracy: 0.8942 - val_loss: 0.3462 - val_accuracy: 0.8935\n",
      "Epoch 43/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2590 - accuracy: 0.8910 - val_loss: 0.3567 - val_accuracy: 0.8903\n",
      "Epoch 44/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2593 - accuracy: 0.8910 - val_loss: 0.3532 - val_accuracy: 0.8935\n",
      "Epoch 45/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2556 - accuracy: 0.8910 - val_loss: 0.3545 - val_accuracy: 0.8935\n",
      "Epoch 46/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2591 - accuracy: 0.8926 - val_loss: 0.3549 - val_accuracy: 0.8935\n",
      "Epoch 47/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2585 - accuracy: 0.8901 - val_loss: 0.3485 - val_accuracy: 0.8903\n",
      "Epoch 48/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.2595 - accuracy: 0.8910 - val_loss: 0.3553 - val_accuracy: 0.8935\n",
      "Epoch 49/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2618 - accuracy: 0.8926 - val_loss: 0.3557 - val_accuracy: 0.8935\n",
      "Epoch 50/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2599 - accuracy: 0.8893 - val_loss: 0.3613 - val_accuracy: 0.8903\n",
      "Epoch 51/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.2547 - accuracy: 0.8918 - val_loss: 0.3567 - val_accuracy: 0.8935\n",
      "Epoch 52/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2590 - accuracy: 0.8918 - val_loss: 0.3543 - val_accuracy: 0.8935\n",
      "Epoch 53/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2541 - accuracy: 0.8918 - val_loss: 0.3637 - val_accuracy: 0.8903\n",
      "Epoch 54/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2578 - accuracy: 0.8926 - val_loss: 0.3598 - val_accuracy: 0.8935\n",
      "Epoch 55/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2560 - accuracy: 0.8926 - val_loss: 0.3684 - val_accuracy: 0.8903\n",
      "Epoch 56/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.2579 - accuracy: 0.8934 - val_loss: 0.3642 - val_accuracy: 0.8935\n",
      "Epoch 57/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2577 - accuracy: 0.8918 - val_loss: 0.3604 - val_accuracy: 0.8935\n",
      "Epoch 58/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.2557 - accuracy: 0.8926 - val_loss: 0.3633 - val_accuracy: 0.8935\n",
      "Epoch 59/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.2573 - accuracy: 0.8942 - val_loss: 0.3603 - val_accuracy: 0.8935\n",
      "Epoch 60/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2571 - accuracy: 0.8926 - val_loss: 0.3645 - val_accuracy: 0.8935\n",
      "Epoch 61/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2515 - accuracy: 0.8934 - val_loss: 0.3599 - val_accuracy: 0.8935\n",
      "Epoch 62/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2610 - accuracy: 0.8918 - val_loss: 0.3655 - val_accuracy: 0.8935\n",
      "Epoch 63/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2599 - accuracy: 0.8942 - val_loss: 0.3643 - val_accuracy: 0.8935\n",
      "Epoch 64/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.2575 - accuracy: 0.8934 - val_loss: 0.3668 - val_accuracy: 0.8935\n",
      "Epoch 65/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2613 - accuracy: 0.8926 - val_loss: 0.3662 - val_accuracy: 0.8935\n",
      "Epoch 66/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2533 - accuracy: 0.8934 - val_loss: 0.3658 - val_accuracy: 0.8935\n",
      "Epoch 67/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.2551 - accuracy: 0.8926 - val_loss: 0.3654 - val_accuracy: 0.8935\n",
      "Epoch 68/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2573 - accuracy: 0.8950 - val_loss: 0.3659 - val_accuracy: 0.8935\n",
      "Epoch 69/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2522 - accuracy: 0.8934 - val_loss: 0.3679 - val_accuracy: 0.8935\n",
      "Epoch 70/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.2597 - accuracy: 0.8950 - val_loss: 0.3661 - val_accuracy: 0.8935\n",
      "Epoch 71/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2622 - accuracy: 0.8926 - val_loss: 0.3643 - val_accuracy: 0.8903\n",
      "Epoch 72/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2530 - accuracy: 0.8942 - val_loss: 0.3788 - val_accuracy: 0.8903\n",
      "Epoch 73/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2546 - accuracy: 0.8934 - val_loss: 0.3634 - val_accuracy: 0.8903\n",
      "Epoch 74/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2515 - accuracy: 0.8942 - val_loss: 0.3788 - val_accuracy: 0.8903\n",
      "Epoch 75/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2552 - accuracy: 0.8926 - val_loss: 0.3650 - val_accuracy: 0.8903\n",
      "Epoch 76/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2617 - accuracy: 0.8926 - val_loss: 0.3674 - val_accuracy: 0.8903\n",
      "Epoch 77/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2544 - accuracy: 0.8934 - val_loss: 0.3678 - val_accuracy: 0.8903\n",
      "Epoch 78/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2582 - accuracy: 0.8942 - val_loss: 0.3936 - val_accuracy: 0.8871\n",
      "Epoch 79/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2562 - accuracy: 0.8926 - val_loss: 0.3756 - val_accuracy: 0.8903\n",
      "Epoch 80/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2585 - accuracy: 0.8918 - val_loss: 0.3707 - val_accuracy: 0.8903\n",
      "Epoch 81/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2580 - accuracy: 0.8926 - val_loss: 0.4051 - val_accuracy: 0.8871\n",
      "Epoch 82/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2612 - accuracy: 0.8910 - val_loss: 0.3719 - val_accuracy: 0.8903\n",
      "Epoch 83/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2617 - accuracy: 0.8901 - val_loss: 0.3786 - val_accuracy: 0.8935\n",
      "Epoch 84/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2577 - accuracy: 0.8926 - val_loss: 0.3760 - val_accuracy: 0.8903\n",
      "Epoch 85/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2586 - accuracy: 0.8942 - val_loss: 0.3782 - val_accuracy: 0.8903\n",
      "Epoch 86/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2559 - accuracy: 0.8942 - val_loss: 0.3758 - val_accuracy: 0.8903\n",
      "Epoch 87/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2534 - accuracy: 0.8934 - val_loss: 0.3763 - val_accuracy: 0.8903\n",
      "Epoch 88/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2553 - accuracy: 0.8934 - val_loss: 0.3768 - val_accuracy: 0.8903\n",
      "Epoch 89/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2532 - accuracy: 0.8918 - val_loss: 0.3810 - val_accuracy: 0.8903\n",
      "Epoch 90/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2548 - accuracy: 0.8926 - val_loss: 0.3804 - val_accuracy: 0.8903\n",
      "Epoch 91/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2568 - accuracy: 0.8942 - val_loss: 0.3807 - val_accuracy: 0.8903\n",
      "Epoch 92/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.2544 - accuracy: 0.8934 - val_loss: 0.3812 - val_accuracy: 0.8903\n",
      "Epoch 93/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.2540 - accuracy: 0.8918 - val_loss: 0.3806 - val_accuracy: 0.8903\n",
      "Epoch 94/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2538 - accuracy: 0.8934 - val_loss: 0.3822 - val_accuracy: 0.8903\n",
      "Epoch 95/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2571 - accuracy: 0.8926 - val_loss: 0.3842 - val_accuracy: 0.8903\n",
      "Epoch 96/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2540 - accuracy: 0.8918 - val_loss: 0.3829 - val_accuracy: 0.8903\n",
      "Epoch 97/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2562 - accuracy: 0.8934 - val_loss: 0.3881 - val_accuracy: 0.8935\n",
      "Epoch 98/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2541 - accuracy: 0.8934 - val_loss: 0.3828 - val_accuracy: 0.8935\n",
      "Epoch 99/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2526 - accuracy: 0.8934 - val_loss: 0.3853 - val_accuracy: 0.8903\n",
      "Epoch 100/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2549 - accuracy: 0.8926 - val_loss: 0.3850 - val_accuracy: 0.8903\n",
      "13/13 - 0s - loss: 0.3889 - accuracy: 0.8608 - 70ms/epoch - 5ms/step\n",
      "Test loss:  0.38887566328048706\n",
      "Test accuracy:  0.8608247637748718\n"
     ]
    }
   ],
   "source": [
    "model_spyware.fit(x_train, y_train, batch_size=32, epochs=100, validation_split=0.2)\n",
    "test_score = model_spyware.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss: \", test_score[0])\n",
    "print(\"Test accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec496430",
   "metadata": {},
   "source": [
    "## Specialized backdoor detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50460ea4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_265475/2013118094.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_backdoor['Labels'] = df_backdoor['Labels'].replace(3, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    968\n",
       "1    968\n",
       "Name: Labels, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_backdoor = df_master[(df_master.Labels == 0) | (df_master.Labels == 3)] \n",
    "df_backdoor['Labels'] = df_backdoor['Labels'].replace(3, 1)\n",
    "df_backdoor.Labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e7f81368",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_backdoor.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6dc7bd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_backdoor['Labels']\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "43b82440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1548, 1737)\n",
      "(1548,)\n",
      "(388, 1737)\n",
      "(388,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = tts(X,y,test_size=0.2) \n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e4fbd493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1737)]            0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 40)                69520     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 20)                820       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,361\n",
      "Trainable params: 70,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(1737,))\n",
    "\n",
    "x = tf.keras.layers.Dense(40,activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dense(20,activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model_backdoor = tf.keras.Model(inputs=inputs,outputs=output)\n",
    "model_backdoor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c71916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_backdoor.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b621532",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ok_sikha/anaconda3/envs/tf_gpu_segnet/lib/python3.9/site-packages/keras/backend.py:5673: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 9ms/step - loss: 0.6536 - accuracy: 0.6446 - val_loss: 0.6089 - val_accuracy: 0.7968\n",
      "Epoch 2/100\n",
      "10/39 [======>.......................] - ETA: 0s - loss: 0.5598 - accuracy: 0.7906"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ok_sikha/anaconda3/envs/tf_gpu_segnet/lib/python3.9/site-packages/keras/backend.py:5673: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 7ms/step - loss: 0.5226 - accuracy: 0.7779 - val_loss: 0.5004 - val_accuracy: 0.7968\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.8174 - val_loss: 0.4495 - val_accuracy: 0.8161\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.3758 - accuracy: 0.8288 - val_loss: 0.4328 - val_accuracy: 0.8258\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3466 - accuracy: 0.8441 - val_loss: 0.4281 - val_accuracy: 0.8258\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3338 - accuracy: 0.8425 - val_loss: 0.4289 - val_accuracy: 0.8323\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3285 - accuracy: 0.8498 - val_loss: 0.4329 - val_accuracy: 0.8290\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3210 - accuracy: 0.8498 - val_loss: 0.4424 - val_accuracy: 0.8355\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.3140 - accuracy: 0.8578 - val_loss: 0.4429 - val_accuracy: 0.8355\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3126 - accuracy: 0.8538 - val_loss: 0.4471 - val_accuracy: 0.8323\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3096 - accuracy: 0.8514 - val_loss: 0.4500 - val_accuracy: 0.8355\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3086 - accuracy: 0.8554 - val_loss: 0.4558 - val_accuracy: 0.8355\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3001 - accuracy: 0.8595 - val_loss: 0.4628 - val_accuracy: 0.8355\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3028 - accuracy: 0.8554 - val_loss: 0.4751 - val_accuracy: 0.8323\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3090 - accuracy: 0.8578 - val_loss: 0.4763 - val_accuracy: 0.8323\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2965 - accuracy: 0.8611 - val_loss: 0.4729 - val_accuracy: 0.8387\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2997 - accuracy: 0.8586 - val_loss: 0.4754 - val_accuracy: 0.8419\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.3012 - accuracy: 0.8570 - val_loss: 0.4820 - val_accuracy: 0.8419\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.2993 - accuracy: 0.8603 - val_loss: 0.4885 - val_accuracy: 0.8419\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.2918 - accuracy: 0.8619 - val_loss: 0.4931 - val_accuracy: 0.8387\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2974 - accuracy: 0.8586 - val_loss: 0.5023 - val_accuracy: 0.8355\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.2948 - accuracy: 0.8595 - val_loss: 0.4958 - val_accuracy: 0.8452\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.2951 - accuracy: 0.8595 - val_loss: 0.5024 - val_accuracy: 0.8419\n",
      "Epoch 24/100\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.2952 - accuracy: 0.8578 - val_loss: 0.5010 - val_accuracy: 0.8387\n",
      "Epoch 25/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2960 - accuracy: 0.8595 - val_loss: 0.5069 - val_accuracy: 0.8452\n",
      "Epoch 26/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2928 - accuracy: 0.8611 - val_loss: 0.5114 - val_accuracy: 0.8419\n",
      "Epoch 27/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2958 - accuracy: 0.8603 - val_loss: 0.5149 - val_accuracy: 0.8387\n",
      "Epoch 28/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2936 - accuracy: 0.8603 - val_loss: 0.5143 - val_accuracy: 0.8452\n",
      "Epoch 29/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2883 - accuracy: 0.8619 - val_loss: 0.5176 - val_accuracy: 0.8452\n",
      "Epoch 30/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2923 - accuracy: 0.8611 - val_loss: 0.5238 - val_accuracy: 0.8452\n",
      "Epoch 31/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2916 - accuracy: 0.8611 - val_loss: 0.5260 - val_accuracy: 0.8452\n",
      "Epoch 32/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2875 - accuracy: 0.8611 - val_loss: 0.5290 - val_accuracy: 0.8452\n",
      "Epoch 33/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2929 - accuracy: 0.8595 - val_loss: 0.5308 - val_accuracy: 0.8452\n",
      "Epoch 34/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2878 - accuracy: 0.8627 - val_loss: 0.5433 - val_accuracy: 0.8452\n",
      "Epoch 35/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2888 - accuracy: 0.8635 - val_loss: 0.5420 - val_accuracy: 0.8387\n",
      "Epoch 36/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2885 - accuracy: 0.8627 - val_loss: 0.5464 - val_accuracy: 0.8452\n",
      "Epoch 37/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2874 - accuracy: 0.8611 - val_loss: 0.5576 - val_accuracy: 0.8355\n",
      "Epoch 38/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2926 - accuracy: 0.8603 - val_loss: 0.5463 - val_accuracy: 0.8452\n",
      "Epoch 39/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.2886 - accuracy: 0.8603 - val_loss: 0.5502 - val_accuracy: 0.8452\n",
      "Epoch 40/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2892 - accuracy: 0.8603 - val_loss: 0.5500 - val_accuracy: 0.8452\n",
      "Epoch 41/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2862 - accuracy: 0.8603 - val_loss: 0.5543 - val_accuracy: 0.8452\n",
      "Epoch 42/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2865 - accuracy: 0.8627 - val_loss: 0.5593 - val_accuracy: 0.8387\n",
      "Epoch 43/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2891 - accuracy: 0.8595 - val_loss: 0.5624 - val_accuracy: 0.8452\n",
      "Epoch 44/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2855 - accuracy: 0.8603 - val_loss: 0.5593 - val_accuracy: 0.8452\n",
      "Epoch 45/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2882 - accuracy: 0.8611 - val_loss: 0.5659 - val_accuracy: 0.8452\n",
      "Epoch 46/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2857 - accuracy: 0.8611 - val_loss: 0.5727 - val_accuracy: 0.8419\n",
      "Epoch 47/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2860 - accuracy: 0.8611 - val_loss: 0.5711 - val_accuracy: 0.8452\n",
      "Epoch 48/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2841 - accuracy: 0.8611 - val_loss: 0.5741 - val_accuracy: 0.8452\n",
      "Epoch 49/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.2861 - accuracy: 0.8619 - val_loss: 0.5761 - val_accuracy: 0.8452\n",
      "Epoch 50/100\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.2853 - accuracy: 0.8611 - val_loss: 0.5756 - val_accuracy: 0.8452\n",
      "Epoch 51/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.2874 - accuracy: 0.8603 - val_loss: 0.5764 - val_accuracy: 0.8452\n",
      "Epoch 52/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.2874 - accuracy: 0.8619 - val_loss: 0.5862 - val_accuracy: 0.8387\n",
      "Epoch 53/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.2887 - accuracy: 0.8611 - val_loss: 0.5876 - val_accuracy: 0.8419\n",
      "Epoch 54/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.2877 - accuracy: 0.8603 - val_loss: 0.5843 - val_accuracy: 0.8452\n",
      "Epoch 55/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2869 - accuracy: 0.8627 - val_loss: 0.5881 - val_accuracy: 0.8452\n",
      "Epoch 56/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2857 - accuracy: 0.8611 - val_loss: 0.5879 - val_accuracy: 0.8452\n",
      "Epoch 57/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2841 - accuracy: 0.8611 - val_loss: 0.5879 - val_accuracy: 0.8452\n",
      "Epoch 58/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2841 - accuracy: 0.8619 - val_loss: 0.6011 - val_accuracy: 0.8452\n",
      "Epoch 59/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.2856 - accuracy: 0.8603 - val_loss: 0.5907 - val_accuracy: 0.8452\n",
      "Epoch 60/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2817 - accuracy: 0.8611 - val_loss: 0.6002 - val_accuracy: 0.8419\n",
      "Epoch 61/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2866 - accuracy: 0.8603 - val_loss: 0.6061 - val_accuracy: 0.8419\n",
      "Epoch 62/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2818 - accuracy: 0.8595 - val_loss: 0.6042 - val_accuracy: 0.8452\n",
      "Epoch 63/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.2848 - accuracy: 0.8619 - val_loss: 0.6082 - val_accuracy: 0.8452\n",
      "Epoch 64/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2846 - accuracy: 0.8619 - val_loss: 0.6151 - val_accuracy: 0.8419\n",
      "Epoch 65/100\n",
      "39/39 [==============================] - 1s 21ms/step - loss: 0.2844 - accuracy: 0.8619 - val_loss: 0.6097 - val_accuracy: 0.8452\n",
      "Epoch 66/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2871 - accuracy: 0.8611 - val_loss: 0.6155 - val_accuracy: 0.8419\n",
      "Epoch 67/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2868 - accuracy: 0.8603 - val_loss: 0.6095 - val_accuracy: 0.8452\n",
      "Epoch 68/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2835 - accuracy: 0.8627 - val_loss: 0.6152 - val_accuracy: 0.8484\n",
      "Epoch 69/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2818 - accuracy: 0.8611 - val_loss: 0.6255 - val_accuracy: 0.8452\n",
      "Epoch 70/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2821 - accuracy: 0.8611 - val_loss: 0.6229 - val_accuracy: 0.8452\n",
      "Epoch 71/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2854 - accuracy: 0.8611 - val_loss: 0.6219 - val_accuracy: 0.8419\n",
      "Epoch 72/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2837 - accuracy: 0.8627 - val_loss: 0.6218 - val_accuracy: 0.8452\n",
      "Epoch 73/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2827 - accuracy: 0.8619 - val_loss: 0.6272 - val_accuracy: 0.8419\n",
      "Epoch 74/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.2843 - accuracy: 0.8611 - val_loss: 0.6270 - val_accuracy: 0.8419\n",
      "Epoch 75/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2841 - accuracy: 0.8611 - val_loss: 0.6266 - val_accuracy: 0.8452\n",
      "Epoch 76/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2804 - accuracy: 0.8627 - val_loss: 0.6301 - val_accuracy: 0.8452\n",
      "Epoch 77/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2889 - accuracy: 0.8611 - val_loss: 0.6286 - val_accuracy: 0.8387\n",
      "Epoch 78/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2832 - accuracy: 0.8611 - val_loss: 0.6322 - val_accuracy: 0.8452\n",
      "Epoch 79/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2844 - accuracy: 0.8627 - val_loss: 0.6349 - val_accuracy: 0.8452\n",
      "Epoch 80/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2860 - accuracy: 0.8627 - val_loss: 0.6420 - val_accuracy: 0.8452\n",
      "Epoch 81/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2822 - accuracy: 0.8611 - val_loss: 0.6418 - val_accuracy: 0.8419\n",
      "Epoch 82/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2846 - accuracy: 0.8611 - val_loss: 0.6412 - val_accuracy: 0.8452\n",
      "Epoch 83/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2832 - accuracy: 0.8619 - val_loss: 0.6394 - val_accuracy: 0.8484\n",
      "Epoch 84/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2838 - accuracy: 0.8619 - val_loss: 0.6516 - val_accuracy: 0.8419\n",
      "Epoch 85/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2863 - accuracy: 0.8627 - val_loss: 0.6441 - val_accuracy: 0.8484\n",
      "Epoch 86/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2805 - accuracy: 0.8619 - val_loss: 0.6427 - val_accuracy: 0.8484\n",
      "Epoch 87/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.2838 - accuracy: 0.8595 - val_loss: 0.6518 - val_accuracy: 0.8452\n",
      "Epoch 88/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2834 - accuracy: 0.8627 - val_loss: 0.6544 - val_accuracy: 0.8419\n",
      "Epoch 89/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2856 - accuracy: 0.8635 - val_loss: 0.6563 - val_accuracy: 0.8387\n",
      "Epoch 90/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2796 - accuracy: 0.8611 - val_loss: 0.6437 - val_accuracy: 0.8452\n",
      "Epoch 91/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2852 - accuracy: 0.8627 - val_loss: 0.6608 - val_accuracy: 0.8419\n",
      "Epoch 92/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2844 - accuracy: 0.8627 - val_loss: 0.6525 - val_accuracy: 0.8484\n",
      "Epoch 93/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2842 - accuracy: 0.8627 - val_loss: 0.6578 - val_accuracy: 0.8484\n",
      "Epoch 94/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2797 - accuracy: 0.8635 - val_loss: 0.6653 - val_accuracy: 0.8452\n",
      "Epoch 95/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2828 - accuracy: 0.8627 - val_loss: 0.6703 - val_accuracy: 0.8419\n",
      "Epoch 96/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2788 - accuracy: 0.8627 - val_loss: 0.6611 - val_accuracy: 0.8484\n",
      "Epoch 97/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2807 - accuracy: 0.8627 - val_loss: 0.6647 - val_accuracy: 0.8484\n",
      "Epoch 98/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2849 - accuracy: 0.8635 - val_loss: 0.6687 - val_accuracy: 0.8452\n",
      "Epoch 99/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2809 - accuracy: 0.8627 - val_loss: 0.6690 - val_accuracy: 0.8484\n",
      "Epoch 100/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2824 - accuracy: 0.8619 - val_loss: 0.6674 - val_accuracy: 0.8484\n",
      "13/13 - 0s - loss: 0.5647 - accuracy: 0.8144 - 54ms/epoch - 4ms/step\n",
      "Test loss:  0.564724862575531\n",
      "Test accuracy:  0.8144329786300659\n"
     ]
    }
   ],
   "source": [
    "model_backdoor.fit(x_train, y_train, batch_size=32, epochs=100, validation_split=0.2)\n",
    "test_score = model_backdoor.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss: \", test_score[0])\n",
    "print(\"Test accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9c3983",
   "metadata": {},
   "source": [
    "## Specialized ransomware detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "80f6778a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_265475/3915678970.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ransomware['Labels'] = df_ransomware['Labels'].replace(4, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    968\n",
       "1    968\n",
       "Name: Labels, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ransomware = df_master[(df_master.Labels == 0) | (df_master.Labels == 4)] \n",
    "df_ransomware['Labels'] = df_ransomware['Labels'].replace(4, 1)\n",
    "df_ransomware.Labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5d2f1477",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_ransomware.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d45f79a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_ransomware['Labels']\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3e5a6c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1548, 1737)\n",
      "(1548,)\n",
      "(388, 1737)\n",
      "(388,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = tts(X,y,test_size=0.2) \n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "719154a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 1737)]            0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 40)                69520     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 20)                820       \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,361\n",
      "Trainable params: 70,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(1737,))\n",
    "\n",
    "x = tf.keras.layers.Dense(40,activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dense(20,activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model_ransomware = tf.keras.Model(inputs=inputs,outputs=output)\n",
    "model_ransomware.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "438959f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ransomware.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cd95e83c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ok_sikha/anaconda3/envs/tf_gpu_segnet/lib/python3.9/site-packages/keras/backend.py:5673: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 10ms/step - loss: 0.6206 - accuracy: 0.7165 - val_loss: 0.5511 - val_accuracy: 0.7710\n",
      "Epoch 2/100\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.6110 - accuracy: 0.6562"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ok_sikha/anaconda3/envs/tf_gpu_segnet/lib/python3.9/site-packages/keras/backend.py:5673: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.7779 - val_loss: 0.4462 - val_accuracy: 0.7839\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.4029 - accuracy: 0.7956 - val_loss: 0.4073 - val_accuracy: 0.7871\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3700 - accuracy: 0.8078 - val_loss: 0.3865 - val_accuracy: 0.7935\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3563 - accuracy: 0.8110 - val_loss: 0.3807 - val_accuracy: 0.7935\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3480 - accuracy: 0.8021 - val_loss: 0.3778 - val_accuracy: 0.7968\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3425 - accuracy: 0.8134 - val_loss: 0.3805 - val_accuracy: 0.7968\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3384 - accuracy: 0.8150 - val_loss: 0.3776 - val_accuracy: 0.7968\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3350 - accuracy: 0.8142 - val_loss: 0.3771 - val_accuracy: 0.7968\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3340 - accuracy: 0.8134 - val_loss: 0.3734 - val_accuracy: 0.7968\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8086 - val_loss: 0.3756 - val_accuracy: 0.7968\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3292 - accuracy: 0.8142 - val_loss: 0.3770 - val_accuracy: 0.7968\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3287 - accuracy: 0.8126 - val_loss: 0.3770 - val_accuracy: 0.7968\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3284 - accuracy: 0.8134 - val_loss: 0.3786 - val_accuracy: 0.7968\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3277 - accuracy: 0.8158 - val_loss: 0.3805 - val_accuracy: 0.7968\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3241 - accuracy: 0.8158 - val_loss: 0.3816 - val_accuracy: 0.7968\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3268 - accuracy: 0.8134 - val_loss: 0.3836 - val_accuracy: 0.7968\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3238 - accuracy: 0.8134 - val_loss: 0.3834 - val_accuracy: 0.7968\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3244 - accuracy: 0.8150 - val_loss: 0.3807 - val_accuracy: 0.7968\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3242 - accuracy: 0.8150 - val_loss: 0.3836 - val_accuracy: 0.7968\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3229 - accuracy: 0.8150 - val_loss: 0.3854 - val_accuracy: 0.7968\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3212 - accuracy: 0.8150 - val_loss: 0.3906 - val_accuracy: 0.7935\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3223 - accuracy: 0.8134 - val_loss: 0.3863 - val_accuracy: 0.8000\n",
      "Epoch 24/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3242 - accuracy: 0.8150 - val_loss: 0.3886 - val_accuracy: 0.7968\n",
      "Epoch 25/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3215 - accuracy: 0.8158 - val_loss: 0.3876 - val_accuracy: 0.8000\n",
      "Epoch 26/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3231 - accuracy: 0.8158 - val_loss: 0.3846 - val_accuracy: 0.8000\n",
      "Epoch 27/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3209 - accuracy: 0.8158 - val_loss: 0.3869 - val_accuracy: 0.8000\n",
      "Epoch 28/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3201 - accuracy: 0.8158 - val_loss: 0.3891 - val_accuracy: 0.7968\n",
      "Epoch 29/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3192 - accuracy: 0.8158 - val_loss: 0.3909 - val_accuracy: 0.8000\n",
      "Epoch 30/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.3223 - accuracy: 0.8158 - val_loss: 0.3934 - val_accuracy: 0.7935\n",
      "Epoch 31/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3207 - accuracy: 0.8158 - val_loss: 0.3928 - val_accuracy: 0.7935\n",
      "Epoch 32/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3203 - accuracy: 0.8158 - val_loss: 0.3937 - val_accuracy: 0.7968\n",
      "Epoch 33/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3204 - accuracy: 0.8150 - val_loss: 0.3926 - val_accuracy: 0.7968\n",
      "Epoch 34/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3192 - accuracy: 0.8158 - val_loss: 0.3943 - val_accuracy: 0.7935\n",
      "Epoch 35/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3189 - accuracy: 0.8158 - val_loss: 0.3938 - val_accuracy: 0.8000\n",
      "Epoch 36/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3199 - accuracy: 0.8158 - val_loss: 0.3739 - val_accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3226 - accuracy: 0.8150 - val_loss: 0.4023 - val_accuracy: 0.7935\n",
      "Epoch 38/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3209 - accuracy: 0.8158 - val_loss: 0.3762 - val_accuracy: 0.8000\n",
      "Epoch 39/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3206 - accuracy: 0.8158 - val_loss: 0.3798 - val_accuracy: 0.7968\n",
      "Epoch 40/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3185 - accuracy: 0.8158 - val_loss: 0.3806 - val_accuracy: 0.8000\n",
      "Epoch 41/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3183 - accuracy: 0.8158 - val_loss: 0.3874 - val_accuracy: 0.7968\n",
      "Epoch 42/100\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.3198 - accuracy: 0.8158 - val_loss: 0.3882 - val_accuracy: 0.7968\n",
      "Epoch 43/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.3194 - accuracy: 0.8158 - val_loss: 0.3914 - val_accuracy: 0.7968\n",
      "Epoch 44/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3179 - accuracy: 0.8158 - val_loss: 0.3887 - val_accuracy: 0.7968\n",
      "Epoch 45/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3205 - accuracy: 0.8158 - val_loss: 0.3892 - val_accuracy: 0.7968\n",
      "Epoch 46/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3180 - accuracy: 0.8158 - val_loss: 0.3892 - val_accuracy: 0.7968\n",
      "Epoch 47/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3206 - accuracy: 0.8158 - val_loss: 0.3903 - val_accuracy: 0.7968\n",
      "Epoch 48/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3195 - accuracy: 0.8158 - val_loss: 0.3922 - val_accuracy: 0.7968\n",
      "Epoch 49/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.3196 - accuracy: 0.8158 - val_loss: 0.3931 - val_accuracy: 0.7968\n",
      "Epoch 50/100\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.3198 - accuracy: 0.8158 - val_loss: 0.3964 - val_accuracy: 0.7968\n",
      "Epoch 51/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.3202 - accuracy: 0.8158 - val_loss: 0.3970 - val_accuracy: 0.7968\n",
      "Epoch 52/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3183 - accuracy: 0.8158 - val_loss: 0.3977 - val_accuracy: 0.7968\n",
      "Epoch 53/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3175 - accuracy: 0.8158 - val_loss: 0.4010 - val_accuracy: 0.7968\n",
      "Epoch 54/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3195 - accuracy: 0.8158 - val_loss: 0.4025 - val_accuracy: 0.7968\n",
      "Epoch 55/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3188 - accuracy: 0.8158 - val_loss: 0.4032 - val_accuracy: 0.7968\n",
      "Epoch 56/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3173 - accuracy: 0.8158 - val_loss: 0.4052 - val_accuracy: 0.7968\n",
      "Epoch 57/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.3190 - accuracy: 0.8158 - val_loss: 0.4061 - val_accuracy: 0.7968\n",
      "Epoch 58/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.3199 - accuracy: 0.8158 - val_loss: 0.4028 - val_accuracy: 0.7968\n",
      "Epoch 59/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3171 - accuracy: 0.8158 - val_loss: 0.4017 - val_accuracy: 0.7968\n",
      "Epoch 60/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3194 - accuracy: 0.8158 - val_loss: 0.4031 - val_accuracy: 0.7968\n",
      "Epoch 61/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3185 - accuracy: 0.8158 - val_loss: 0.4053 - val_accuracy: 0.7968\n",
      "Epoch 62/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.3194 - accuracy: 0.8158 - val_loss: 0.4058 - val_accuracy: 0.7968\n",
      "Epoch 63/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3182 - accuracy: 0.8158 - val_loss: 0.4057 - val_accuracy: 0.7968\n",
      "Epoch 64/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3187 - accuracy: 0.8158 - val_loss: 0.4079 - val_accuracy: 0.7968\n",
      "Epoch 65/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3185 - accuracy: 0.8158 - val_loss: 0.4085 - val_accuracy: 0.7968\n",
      "Epoch 66/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3178 - accuracy: 0.8158 - val_loss: 0.4100 - val_accuracy: 0.7968\n",
      "Epoch 67/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3180 - accuracy: 0.8158 - val_loss: 0.4085 - val_accuracy: 0.7968\n",
      "Epoch 68/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3180 - accuracy: 0.8158 - val_loss: 0.4092 - val_accuracy: 0.7968\n",
      "Epoch 69/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3169 - accuracy: 0.8158 - val_loss: 0.4091 - val_accuracy: 0.7968\n",
      "Epoch 70/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.3180 - accuracy: 0.8158 - val_loss: 0.4117 - val_accuracy: 0.7968\n",
      "Epoch 71/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3190 - accuracy: 0.8158 - val_loss: 0.4126 - val_accuracy: 0.7968\n",
      "Epoch 72/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3176 - accuracy: 0.8158 - val_loss: 0.4132 - val_accuracy: 0.7968\n",
      "Epoch 73/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3169 - accuracy: 0.8158 - val_loss: 0.4158 - val_accuracy: 0.7968\n",
      "Epoch 74/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3191 - accuracy: 0.8158 - val_loss: 0.4159 - val_accuracy: 0.7968\n",
      "Epoch 75/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3185 - accuracy: 0.8158 - val_loss: 0.4158 - val_accuracy: 0.7968\n",
      "Epoch 76/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3183 - accuracy: 0.8158 - val_loss: 0.4176 - val_accuracy: 0.7968\n",
      "Epoch 77/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3174 - accuracy: 0.8158 - val_loss: 0.4156 - val_accuracy: 0.7968\n",
      "Epoch 78/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3183 - accuracy: 0.8158 - val_loss: 0.4183 - val_accuracy: 0.7968\n",
      "Epoch 79/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3187 - accuracy: 0.8158 - val_loss: 0.4154 - val_accuracy: 0.7968\n",
      "Epoch 80/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3185 - accuracy: 0.8158 - val_loss: 0.4187 - val_accuracy: 0.7968\n",
      "Epoch 81/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3190 - accuracy: 0.8158 - val_loss: 0.4190 - val_accuracy: 0.7968\n",
      "Epoch 82/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3176 - accuracy: 0.8158 - val_loss: 0.4196 - val_accuracy: 0.7968\n",
      "Epoch 83/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3176 - accuracy: 0.8158 - val_loss: 0.4165 - val_accuracy: 0.7968\n",
      "Epoch 84/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3184 - accuracy: 0.8158 - val_loss: 0.4196 - val_accuracy: 0.7968\n",
      "Epoch 85/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3179 - accuracy: 0.8158 - val_loss: 0.4196 - val_accuracy: 0.7968\n",
      "Epoch 86/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3173 - accuracy: 0.8158 - val_loss: 0.4249 - val_accuracy: 0.7968\n",
      "Epoch 87/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3174 - accuracy: 0.8158 - val_loss: 0.4249 - val_accuracy: 0.7968\n",
      "Epoch 88/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3179 - accuracy: 0.8158 - val_loss: 0.4243 - val_accuracy: 0.7968\n",
      "Epoch 89/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3165 - accuracy: 0.8158 - val_loss: 0.4252 - val_accuracy: 0.7968\n",
      "Epoch 90/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3161 - accuracy: 0.8158 - val_loss: 0.4266 - val_accuracy: 0.7968\n",
      "Epoch 91/100\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.3161 - accuracy: 0.8158 - val_loss: 0.4271 - val_accuracy: 0.7968\n",
      "Epoch 92/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3164 - accuracy: 0.8158 - val_loss: 0.4290 - val_accuracy: 0.7968\n",
      "Epoch 93/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3170 - accuracy: 0.8158 - val_loss: 0.4266 - val_accuracy: 0.7968\n",
      "Epoch 94/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3192 - accuracy: 0.8158 - val_loss: 0.4286 - val_accuracy: 0.7968\n",
      "Epoch 95/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.3178 - accuracy: 0.8158 - val_loss: 0.4271 - val_accuracy: 0.7968\n",
      "Epoch 96/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3178 - accuracy: 0.8158 - val_loss: 0.4269 - val_accuracy: 0.7968\n",
      "Epoch 97/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3175 - accuracy: 0.8158 - val_loss: 0.4288 - val_accuracy: 0.7968\n",
      "Epoch 98/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3172 - accuracy: 0.8158 - val_loss: 0.4294 - val_accuracy: 0.7968\n",
      "Epoch 99/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.3181 - accuracy: 0.8158 - val_loss: 0.4236 - val_accuracy: 0.7968\n",
      "Epoch 100/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3188 - accuracy: 0.8158 - val_loss: 0.4250 - val_accuracy: 0.7968\n",
      "13/13 - 0s - loss: 0.5076 - accuracy: 0.7938 - 119ms/epoch - 9ms/step\n",
      "Test loss:  0.5075554847717285\n",
      "Test accuracy:  0.7938144207000732\n"
     ]
    }
   ],
   "source": [
    "model_ransomware.fit(x_train, y_train, batch_size=32, epochs=100, validation_split=0.2)\n",
    "test_score = model_ransomware.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss: \", test_score[0])\n",
    "print(\"Test accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e730ce15",
   "metadata": {},
   "source": [
    "## Specialized pua detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a5c8487f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_265475/1450387477.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_pua['Labels'] = df_pua['Labels'].replace(5, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    968\n",
       "1    968\n",
       "Name: Labels, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pua = df_master[(df_master.Labels == 0) | (df_master.Labels == 5)] \n",
    "df_pua['Labels'] = df_pua['Labels'].replace(5, 1)\n",
    "df_pua.Labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9e5970b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_pua.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dfc3e454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_pua['Labels']\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "38549775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1548, 1737)\n",
      "(1548,)\n",
      "(388, 1737)\n",
      "(388,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = tts(X,y,test_size=0.2) \n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d81dca99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 1737)]            0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 40)                69520     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 20)                820       \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,361\n",
      "Trainable params: 70,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(1737,))\n",
    "\n",
    "x = tf.keras.layers.Dense(40,activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dense(20,activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model_pua = tf.keras.Model(inputs=inputs,outputs=output)\n",
    "model_pua.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7833968e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pua.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "04817a4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ok_sikha/anaconda3/envs/tf_gpu_segnet/lib/python3.9/site-packages/keras/backend.py:5673: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 9ms/step - loss: 0.6635 - accuracy: 0.6333 - val_loss: 0.6157 - val_accuracy: 0.7677\n",
      "Epoch 2/100\n",
      "14/39 [=========>....................] - ETA: 0s - loss: 0.5920 - accuracy: 0.7701"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ok_sikha/anaconda3/envs/tf_gpu_segnet/lib/python3.9/site-packages/keras/backend.py:5673: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5730 - accuracy: 0.7585 - val_loss: 0.5215 - val_accuracy: 0.7710\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.4966 - accuracy: 0.7641 - val_loss: 0.4706 - val_accuracy: 0.7903\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.4508 - accuracy: 0.7835 - val_loss: 0.4676 - val_accuracy: 0.7903\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.4331 - accuracy: 0.7900 - val_loss: 0.4525 - val_accuracy: 0.7871\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.4030 - accuracy: 0.8005 - val_loss: 0.4660 - val_accuracy: 0.7871\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.7916 - val_loss: 0.4857 - val_accuracy: 0.7903\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.3891 - accuracy: 0.8037 - val_loss: 0.4552 - val_accuracy: 0.8000\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3768 - accuracy: 0.8134 - val_loss: 0.4682 - val_accuracy: 0.8032\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.3704 - accuracy: 0.8134 - val_loss: 0.4638 - val_accuracy: 0.8065\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.3626 - accuracy: 0.8102 - val_loss: 0.4681 - val_accuracy: 0.7968\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3613 - accuracy: 0.8158 - val_loss: 0.4709 - val_accuracy: 0.8000\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3594 - accuracy: 0.8126 - val_loss: 0.4771 - val_accuracy: 0.8065\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.3566 - accuracy: 0.8142 - val_loss: 0.4815 - val_accuracy: 0.8097\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.3549 - accuracy: 0.8134 - val_loss: 0.4698 - val_accuracy: 0.8032\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3490 - accuracy: 0.8158 - val_loss: 0.4777 - val_accuracy: 0.8097\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3476 - accuracy: 0.8174 - val_loss: 0.4853 - val_accuracy: 0.8129\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3480 - accuracy: 0.8158 - val_loss: 0.4792 - val_accuracy: 0.8097\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.3441 - accuracy: 0.8183 - val_loss: 0.4974 - val_accuracy: 0.8161\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3423 - accuracy: 0.8183 - val_loss: 0.4956 - val_accuracy: 0.8161\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.3430 - accuracy: 0.8183 - val_loss: 0.5075 - val_accuracy: 0.8129\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3437 - accuracy: 0.8207 - val_loss: 0.5136 - val_accuracy: 0.8161\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3354 - accuracy: 0.8231 - val_loss: 0.5032 - val_accuracy: 0.8161\n",
      "Epoch 24/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3369 - accuracy: 0.8223 - val_loss: 0.5088 - val_accuracy: 0.8161\n",
      "Epoch 25/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.3349 - accuracy: 0.8231 - val_loss: 0.5300 - val_accuracy: 0.8129\n",
      "Epoch 26/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3367 - accuracy: 0.8223 - val_loss: 0.5131 - val_accuracy: 0.8194\n",
      "Epoch 27/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.3352 - accuracy: 0.8223 - val_loss: 0.5309 - val_accuracy: 0.8129\n",
      "Epoch 28/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3324 - accuracy: 0.8223 - val_loss: 0.5294 - val_accuracy: 0.8129\n",
      "Epoch 29/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.3315 - accuracy: 0.8239 - val_loss: 0.5363 - val_accuracy: 0.8161\n",
      "Epoch 30/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3353 - accuracy: 0.8231 - val_loss: 0.5309 - val_accuracy: 0.8161\n",
      "Epoch 31/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3345 - accuracy: 0.8223 - val_loss: 0.5349 - val_accuracy: 0.8161\n",
      "Epoch 32/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3337 - accuracy: 0.8231 - val_loss: 0.5471 - val_accuracy: 0.8161\n",
      "Epoch 33/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.3327 - accuracy: 0.8239 - val_loss: 0.5504 - val_accuracy: 0.8161\n",
      "Epoch 34/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.3300 - accuracy: 0.8247 - val_loss: 0.5576 - val_accuracy: 0.8129\n",
      "Epoch 35/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3296 - accuracy: 0.8239 - val_loss: 0.5642 - val_accuracy: 0.8161\n",
      "Epoch 36/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3291 - accuracy: 0.8239 - val_loss: 0.5581 - val_accuracy: 0.8161\n",
      "Epoch 37/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3282 - accuracy: 0.8239 - val_loss: 0.5548 - val_accuracy: 0.8129\n",
      "Epoch 38/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3335 - accuracy: 0.8231 - val_loss: 0.5762 - val_accuracy: 0.8097\n",
      "Epoch 39/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3301 - accuracy: 0.8231 - val_loss: 0.5713 - val_accuracy: 0.8129\n",
      "Epoch 40/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.3284 - accuracy: 0.8247 - val_loss: 0.5841 - val_accuracy: 0.8097\n",
      "Epoch 41/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3283 - accuracy: 0.8239 - val_loss: 0.5796 - val_accuracy: 0.8129\n",
      "Epoch 42/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3304 - accuracy: 0.8223 - val_loss: 0.5844 - val_accuracy: 0.8161\n",
      "Epoch 43/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.3307 - accuracy: 0.8239 - val_loss: 0.5819 - val_accuracy: 0.8161\n",
      "Epoch 44/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3283 - accuracy: 0.8239 - val_loss: 0.5991 - val_accuracy: 0.8161\n",
      "Epoch 45/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3297 - accuracy: 0.8231 - val_loss: 0.5857 - val_accuracy: 0.8161\n",
      "Epoch 46/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.3298 - accuracy: 0.8239 - val_loss: 0.6011 - val_accuracy: 0.8129\n",
      "Epoch 47/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3308 - accuracy: 0.8239 - val_loss: 0.6026 - val_accuracy: 0.8129\n",
      "Epoch 48/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.3302 - accuracy: 0.8231 - val_loss: 0.6014 - val_accuracy: 0.8161\n",
      "Epoch 49/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3281 - accuracy: 0.8247 - val_loss: 0.6018 - val_accuracy: 0.8161\n",
      "Epoch 50/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3259 - accuracy: 0.8231 - val_loss: 0.5972 - val_accuracy: 0.8161\n",
      "Epoch 51/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3233 - accuracy: 0.8239 - val_loss: 0.6218 - val_accuracy: 0.8097\n",
      "Epoch 52/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.8239 - val_loss: 0.6004 - val_accuracy: 0.8161\n",
      "Epoch 53/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3272 - accuracy: 0.8239 - val_loss: 0.6073 - val_accuracy: 0.8161\n",
      "Epoch 54/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.3281 - accuracy: 0.8247 - val_loss: 0.6267 - val_accuracy: 0.8097\n",
      "Epoch 55/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3250 - accuracy: 0.8247 - val_loss: 0.6171 - val_accuracy: 0.8161\n",
      "Epoch 56/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.3252 - accuracy: 0.8239 - val_loss: 0.6197 - val_accuracy: 0.8161\n",
      "Epoch 57/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3292 - accuracy: 0.8239 - val_loss: 0.6146 - val_accuracy: 0.8161\n",
      "Epoch 58/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.3269 - accuracy: 0.8231 - val_loss: 0.6279 - val_accuracy: 0.8129\n",
      "Epoch 59/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3269 - accuracy: 0.8239 - val_loss: 0.6412 - val_accuracy: 0.8097\n",
      "Epoch 60/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3255 - accuracy: 0.8247 - val_loss: 0.6213 - val_accuracy: 0.8129\n",
      "Epoch 61/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.3275 - accuracy: 0.8231 - val_loss: 0.6245 - val_accuracy: 0.8161\n",
      "Epoch 62/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.3257 - accuracy: 0.8231 - val_loss: 0.6334 - val_accuracy: 0.8129\n",
      "Epoch 63/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3260 - accuracy: 0.8231 - val_loss: 0.6329 - val_accuracy: 0.8129\n",
      "Epoch 64/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.3279 - accuracy: 0.8239 - val_loss: 0.6456 - val_accuracy: 0.8129\n",
      "Epoch 65/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3260 - accuracy: 0.8247 - val_loss: 0.6401 - val_accuracy: 0.8129\n",
      "Epoch 66/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3275 - accuracy: 0.8231 - val_loss: 0.6432 - val_accuracy: 0.8097\n",
      "Epoch 67/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3235 - accuracy: 0.8239 - val_loss: 0.7203 - val_accuracy: 0.7968\n",
      "Epoch 68/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3308 - accuracy: 0.8207 - val_loss: 0.6961 - val_accuracy: 0.7968\n",
      "Epoch 69/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3266 - accuracy: 0.8239 - val_loss: 0.6960 - val_accuracy: 0.8000\n",
      "Epoch 70/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3259 - accuracy: 0.8239 - val_loss: 0.6733 - val_accuracy: 0.8097\n",
      "Epoch 71/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3286 - accuracy: 0.8239 - val_loss: 0.6757 - val_accuracy: 0.8097\n",
      "Epoch 72/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3249 - accuracy: 0.8231 - val_loss: 0.6970 - val_accuracy: 0.8065\n",
      "Epoch 73/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3248 - accuracy: 0.8247 - val_loss: 0.6997 - val_accuracy: 0.8065\n",
      "Epoch 74/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3264 - accuracy: 0.8239 - val_loss: 0.7025 - val_accuracy: 0.8065\n",
      "Epoch 75/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3276 - accuracy: 0.8231 - val_loss: 0.7051 - val_accuracy: 0.8097\n",
      "Epoch 76/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3275 - accuracy: 0.8239 - val_loss: 0.6969 - val_accuracy: 0.8065\n",
      "Epoch 77/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3279 - accuracy: 0.8231 - val_loss: 0.6945 - val_accuracy: 0.8065\n",
      "Epoch 78/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3250 - accuracy: 0.8247 - val_loss: 0.6885 - val_accuracy: 0.8097\n",
      "Epoch 79/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3248 - accuracy: 0.8231 - val_loss: 0.6919 - val_accuracy: 0.8065\n",
      "Epoch 80/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.3257 - accuracy: 0.8239 - val_loss: 0.7134 - val_accuracy: 0.8065\n",
      "Epoch 81/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3269 - accuracy: 0.8239 - val_loss: 0.6980 - val_accuracy: 0.8129\n",
      "Epoch 82/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3262 - accuracy: 0.8231 - val_loss: 0.7234 - val_accuracy: 0.8065\n",
      "Epoch 83/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3251 - accuracy: 0.8231 - val_loss: 0.7053 - val_accuracy: 0.8097\n",
      "Epoch 84/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3250 - accuracy: 0.8239 - val_loss: 0.7113 - val_accuracy: 0.8097\n",
      "Epoch 85/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3274 - accuracy: 0.8239 - val_loss: 0.7192 - val_accuracy: 0.8097\n",
      "Epoch 86/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3249 - accuracy: 0.8231 - val_loss: 0.7129 - val_accuracy: 0.8065\n",
      "Epoch 87/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3253 - accuracy: 0.8239 - val_loss: 0.7049 - val_accuracy: 0.8065\n",
      "Epoch 88/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3252 - accuracy: 0.8239 - val_loss: 0.6945 - val_accuracy: 0.8097\n",
      "Epoch 89/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3236 - accuracy: 0.8247 - val_loss: 0.7228 - val_accuracy: 0.8065\n",
      "Epoch 90/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3226 - accuracy: 0.8239 - val_loss: 0.7259 - val_accuracy: 0.8065\n",
      "Epoch 91/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3189 - accuracy: 0.8231 - val_loss: 0.7205 - val_accuracy: 0.8065\n",
      "Epoch 92/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3256 - accuracy: 0.8231 - val_loss: 0.7236 - val_accuracy: 0.8065\n",
      "Epoch 93/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3246 - accuracy: 0.8231 - val_loss: 0.7149 - val_accuracy: 0.8097\n",
      "Epoch 94/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.3271 - accuracy: 0.8239 - val_loss: 0.7214 - val_accuracy: 0.8097\n",
      "Epoch 95/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3267 - accuracy: 0.8239 - val_loss: 0.7460 - val_accuracy: 0.8065\n",
      "Epoch 96/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3280 - accuracy: 0.8239 - val_loss: 0.7280 - val_accuracy: 0.8097\n",
      "Epoch 97/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3221 - accuracy: 0.8247 - val_loss: 0.7269 - val_accuracy: 0.8065\n",
      "Epoch 98/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3223 - accuracy: 0.8239 - val_loss: 0.7315 - val_accuracy: 0.8065\n",
      "Epoch 99/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3255 - accuracy: 0.8231 - val_loss: 0.7276 - val_accuracy: 0.8097\n",
      "Epoch 100/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.3278 - accuracy: 0.8223 - val_loss: 0.7279 - val_accuracy: 0.8097\n",
      "13/13 - 0s - loss: 0.5488 - accuracy: 0.7655 - 201ms/epoch - 15ms/step\n",
      "Test loss:  0.5488463640213013\n",
      "Test accuracy:  0.7654638886451721\n"
     ]
    }
   ],
   "source": [
    "model_pua.fit(x_train, y_train, batch_size=32, epochs=100, validation_split=0.2)\n",
    "test_score = model_pua.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss: \", test_score[0])\n",
    "print(\"Test accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfb8099",
   "metadata": {},
   "source": [
    "## Specialized downloader detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6fe7b70c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_265475/1248347057.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_downloader['Labels'] = df_downloader['Labels'].replace(6, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    968\n",
       "1    968\n",
       "Name: Labels, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_downloader = df_master[(df_master.Labels == 0) | (df_master.Labels == 6)] \n",
    "df_downloader['Labels'] = df_downloader['Labels'].replace(6, 1)\n",
    "df_downloader.Labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "109dee22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_downloader.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "30bbe61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_downloader['Labels']\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e86163f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1548, 1737)\n",
      "(1548,)\n",
      "(388, 1737)\n",
      "(388,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = tts(X,y,test_size=0.2) \n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a5c5d0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 1737)]            0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 40)                69520     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 20)                820       \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,361\n",
      "Trainable params: 70,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(1737,))\n",
    "\n",
    "x = tf.keras.layers.Dense(40,activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dense(20,activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model_downloader = tf.keras.Model(inputs=inputs,outputs=output)\n",
    "model_downloader.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6f1d93ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_downloader.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "435eb73c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ok_sikha/anaconda3/envs/tf_gpu_segnet/lib/python3.9/site-packages/keras/backend.py:5673: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 9ms/step - loss: 0.6326 - accuracy: 0.7585 - val_loss: 0.5442 - val_accuracy: 0.8194\n",
      "Epoch 2/100\n",
      " 7/39 [====>.........................] - ETA: 0s - loss: 0.5452 - accuracy: 0.7946"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ok_sikha/anaconda3/envs/tf_gpu_segnet/lib/python3.9/site-packages/keras/backend.py:5673: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 5ms/step - loss: 0.4818 - accuracy: 0.8215 - val_loss: 0.4053 - val_accuracy: 0.8323\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3792 - accuracy: 0.8481 - val_loss: 0.3495 - val_accuracy: 0.8452\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3390 - accuracy: 0.8595 - val_loss: 0.3304 - val_accuracy: 0.8516\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3220 - accuracy: 0.8683 - val_loss: 0.3246 - val_accuracy: 0.8613\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3116 - accuracy: 0.8740 - val_loss: 0.3209 - val_accuracy: 0.8613\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2956 - accuracy: 0.8788 - val_loss: 0.3136 - val_accuracy: 0.8645\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2923 - accuracy: 0.8788 - val_loss: 0.3092 - val_accuracy: 0.8645\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2826 - accuracy: 0.8829 - val_loss: 0.3137 - val_accuracy: 0.8645\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2797 - accuracy: 0.8821 - val_loss: 0.3101 - val_accuracy: 0.8645\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2800 - accuracy: 0.8837 - val_loss: 0.3178 - val_accuracy: 0.8645\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2729 - accuracy: 0.8853 - val_loss: 0.3222 - val_accuracy: 0.8645\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2687 - accuracy: 0.8861 - val_loss: 0.3199 - val_accuracy: 0.8613\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2687 - accuracy: 0.8861 - val_loss: 0.3197 - val_accuracy: 0.8613\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2635 - accuracy: 0.8869 - val_loss: 0.3325 - val_accuracy: 0.8581\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2606 - accuracy: 0.8893 - val_loss: 0.3241 - val_accuracy: 0.8581\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2609 - accuracy: 0.8877 - val_loss: 0.3256 - val_accuracy: 0.8581\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2580 - accuracy: 0.8885 - val_loss: 0.3313 - val_accuracy: 0.8581\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.2611 - accuracy: 0.8869 - val_loss: 0.3365 - val_accuracy: 0.8613\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.2543 - accuracy: 0.8893 - val_loss: 0.3356 - val_accuracy: 0.8581\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2577 - accuracy: 0.8893 - val_loss: 0.3384 - val_accuracy: 0.8581\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2569 - accuracy: 0.8893 - val_loss: 0.3449 - val_accuracy: 0.8581\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2564 - accuracy: 0.8885 - val_loss: 0.3480 - val_accuracy: 0.8581\n",
      "Epoch 24/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2527 - accuracy: 0.8901 - val_loss: 0.3524 - val_accuracy: 0.8581\n",
      "Epoch 25/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2564 - accuracy: 0.8901 - val_loss: 0.3499 - val_accuracy: 0.8581\n",
      "Epoch 26/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2543 - accuracy: 0.8893 - val_loss: 0.3500 - val_accuracy: 0.8581\n",
      "Epoch 27/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2525 - accuracy: 0.8885 - val_loss: 0.3524 - val_accuracy: 0.8581\n",
      "Epoch 28/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2519 - accuracy: 0.8901 - val_loss: 0.3528 - val_accuracy: 0.8581\n",
      "Epoch 29/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2563 - accuracy: 0.8893 - val_loss: 0.3555 - val_accuracy: 0.8581\n",
      "Epoch 30/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2535 - accuracy: 0.8901 - val_loss: 0.3534 - val_accuracy: 0.8548\n",
      "Epoch 31/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2509 - accuracy: 0.8901 - val_loss: 0.3593 - val_accuracy: 0.8613\n",
      "Epoch 32/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2511 - accuracy: 0.8901 - val_loss: 0.3546 - val_accuracy: 0.8548\n",
      "Epoch 33/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2523 - accuracy: 0.8901 - val_loss: 0.3610 - val_accuracy: 0.8581\n",
      "Epoch 34/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2526 - accuracy: 0.8893 - val_loss: 0.3639 - val_accuracy: 0.8581\n",
      "Epoch 35/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.2538 - accuracy: 0.8901 - val_loss: 0.3576 - val_accuracy: 0.8548\n",
      "Epoch 36/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2551 - accuracy: 0.8893 - val_loss: 0.3680 - val_accuracy: 0.8581\n",
      "Epoch 37/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2493 - accuracy: 0.8893 - val_loss: 0.3690 - val_accuracy: 0.8581\n",
      "Epoch 38/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2513 - accuracy: 0.8893 - val_loss: 0.3634 - val_accuracy: 0.8613\n",
      "Epoch 39/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2501 - accuracy: 0.8901 - val_loss: 0.3659 - val_accuracy: 0.8548\n",
      "Epoch 40/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2543 - accuracy: 0.8893 - val_loss: 0.3659 - val_accuracy: 0.8581\n",
      "Epoch 41/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.2513 - accuracy: 0.8901 - val_loss: 0.3730 - val_accuracy: 0.8581\n",
      "Epoch 42/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2468 - accuracy: 0.8901 - val_loss: 0.3671 - val_accuracy: 0.8581\n",
      "Epoch 43/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2550 - accuracy: 0.8893 - val_loss: 0.3682 - val_accuracy: 0.8581\n",
      "Epoch 44/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2521 - accuracy: 0.8901 - val_loss: 0.3669 - val_accuracy: 0.8581\n",
      "Epoch 45/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.2508 - accuracy: 0.8901 - val_loss: 0.3699 - val_accuracy: 0.8581\n",
      "Epoch 46/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.2524 - accuracy: 0.8910 - val_loss: 0.3748 - val_accuracy: 0.8581\n",
      "Epoch 47/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2508 - accuracy: 0.8893 - val_loss: 0.3690 - val_accuracy: 0.8581\n",
      "Epoch 48/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.2529 - accuracy: 0.8893 - val_loss: 0.3787 - val_accuracy: 0.8581\n",
      "Epoch 49/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2517 - accuracy: 0.8893 - val_loss: 0.3703 - val_accuracy: 0.8581\n",
      "Epoch 50/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2494 - accuracy: 0.8901 - val_loss: 0.3715 - val_accuracy: 0.8516\n",
      "Epoch 51/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2499 - accuracy: 0.8901 - val_loss: 0.3828 - val_accuracy: 0.8581\n",
      "Epoch 52/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2502 - accuracy: 0.8893 - val_loss: 0.3809 - val_accuracy: 0.8548\n",
      "Epoch 53/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2484 - accuracy: 0.8893 - val_loss: 0.3836 - val_accuracy: 0.8548\n",
      "Epoch 54/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2515 - accuracy: 0.8910 - val_loss: 0.3829 - val_accuracy: 0.8581\n",
      "Epoch 55/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2484 - accuracy: 0.8893 - val_loss: 0.3925 - val_accuracy: 0.8581\n",
      "Epoch 56/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2518 - accuracy: 0.8901 - val_loss: 0.3901 - val_accuracy: 0.8581\n",
      "Epoch 57/100\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.2445 - accuracy: 0.8901 - val_loss: 0.3869 - val_accuracy: 0.8581\n",
      "Epoch 58/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2540 - accuracy: 0.8901 - val_loss: 0.3840 - val_accuracy: 0.8581\n",
      "Epoch 59/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2504 - accuracy: 0.8893 - val_loss: 0.3936 - val_accuracy: 0.8581\n",
      "Epoch 60/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2481 - accuracy: 0.8893 - val_loss: 0.3987 - val_accuracy: 0.8613\n",
      "Epoch 61/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2544 - accuracy: 0.8901 - val_loss: 0.3921 - val_accuracy: 0.8581\n",
      "Epoch 62/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2505 - accuracy: 0.8901 - val_loss: 0.3878 - val_accuracy: 0.8548\n",
      "Epoch 63/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2524 - accuracy: 0.8893 - val_loss: 0.4009 - val_accuracy: 0.8581\n",
      "Epoch 64/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2507 - accuracy: 0.8885 - val_loss: 0.3995 - val_accuracy: 0.8581\n",
      "Epoch 65/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2497 - accuracy: 0.8901 - val_loss: 0.4011 - val_accuracy: 0.8613\n",
      "Epoch 66/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2539 - accuracy: 0.8901 - val_loss: 0.3949 - val_accuracy: 0.8581\n",
      "Epoch 67/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2474 - accuracy: 0.8901 - val_loss: 0.3982 - val_accuracy: 0.8613\n",
      "Epoch 68/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2467 - accuracy: 0.8901 - val_loss: 0.3976 - val_accuracy: 0.8581\n",
      "Epoch 69/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2511 - accuracy: 0.8885 - val_loss: 0.4113 - val_accuracy: 0.8613\n",
      "Epoch 70/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.2488 - accuracy: 0.8901 - val_loss: 0.4018 - val_accuracy: 0.8581\n",
      "Epoch 71/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2490 - accuracy: 0.8901 - val_loss: 0.4020 - val_accuracy: 0.8581\n",
      "Epoch 72/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2474 - accuracy: 0.8901 - val_loss: 0.4007 - val_accuracy: 0.8581\n",
      "Epoch 73/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2448 - accuracy: 0.8901 - val_loss: 0.4051 - val_accuracy: 0.8613\n",
      "Epoch 74/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2492 - accuracy: 0.8885 - val_loss: 0.4038 - val_accuracy: 0.8613\n",
      "Epoch 75/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2494 - accuracy: 0.8901 - val_loss: 0.4003 - val_accuracy: 0.8613\n",
      "Epoch 76/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2506 - accuracy: 0.8901 - val_loss: 0.3956 - val_accuracy: 0.8613\n",
      "Epoch 77/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2486 - accuracy: 0.8885 - val_loss: 0.4132 - val_accuracy: 0.8613\n",
      "Epoch 78/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2480 - accuracy: 0.8901 - val_loss: 0.4105 - val_accuracy: 0.8613\n",
      "Epoch 79/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2486 - accuracy: 0.8901 - val_loss: 0.4118 - val_accuracy: 0.8613\n",
      "Epoch 80/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2463 - accuracy: 0.8901 - val_loss: 0.4120 - val_accuracy: 0.8613\n",
      "Epoch 81/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2486 - accuracy: 0.8901 - val_loss: 0.4165 - val_accuracy: 0.8581\n",
      "Epoch 82/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2494 - accuracy: 0.8901 - val_loss: 0.4153 - val_accuracy: 0.8581\n",
      "Epoch 83/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2502 - accuracy: 0.8901 - val_loss: 0.4201 - val_accuracy: 0.8581\n",
      "Epoch 84/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2456 - accuracy: 0.8901 - val_loss: 0.4170 - val_accuracy: 0.8613\n",
      "Epoch 85/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2446 - accuracy: 0.8901 - val_loss: 0.4162 - val_accuracy: 0.8581\n",
      "Epoch 86/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2460 - accuracy: 0.8901 - val_loss: 0.4159 - val_accuracy: 0.8581\n",
      "Epoch 87/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2499 - accuracy: 0.8885 - val_loss: 0.4327 - val_accuracy: 0.8613\n",
      "Epoch 88/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2499 - accuracy: 0.8893 - val_loss: 0.4227 - val_accuracy: 0.8613\n",
      "Epoch 89/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2510 - accuracy: 0.8901 - val_loss: 0.4177 - val_accuracy: 0.8581\n",
      "Epoch 90/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2478 - accuracy: 0.8910 - val_loss: 0.4165 - val_accuracy: 0.8613\n",
      "Epoch 91/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2500 - accuracy: 0.8910 - val_loss: 0.4275 - val_accuracy: 0.8613\n",
      "Epoch 92/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2471 - accuracy: 0.8901 - val_loss: 0.4171 - val_accuracy: 0.8613\n",
      "Epoch 93/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2487 - accuracy: 0.8901 - val_loss: 0.4180 - val_accuracy: 0.8581\n",
      "Epoch 94/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.2468 - accuracy: 0.8885 - val_loss: 0.4247 - val_accuracy: 0.8613\n",
      "Epoch 95/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2497 - accuracy: 0.8893 - val_loss: 0.4245 - val_accuracy: 0.8613\n",
      "Epoch 96/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2469 - accuracy: 0.8901 - val_loss: 0.4292 - val_accuracy: 0.8613\n",
      "Epoch 97/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2478 - accuracy: 0.8893 - val_loss: 0.4222 - val_accuracy: 0.8613\n",
      "Epoch 98/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2485 - accuracy: 0.8901 - val_loss: 0.4204 - val_accuracy: 0.8581\n",
      "Epoch 99/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.2513 - accuracy: 0.8885 - val_loss: 0.4311 - val_accuracy: 0.8613\n",
      "Epoch 100/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.2473 - accuracy: 0.8893 - val_loss: 0.4379 - val_accuracy: 0.8613\n",
      "13/13 - 0s - loss: 0.5849 - accuracy: 0.8222 - 64ms/epoch - 5ms/step\n",
      "Test loss:  0.5849368572235107\n",
      "Test accuracy:  0.8221649527549744\n"
     ]
    }
   ],
   "source": [
    "model_downloader.fit(x_train, y_train, batch_size=32, epochs=100, validation_split=0.2)\n",
    "test_score = model_downloader.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss: \", test_score[0])\n",
    "print(\"Test accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9332b2",
   "metadata": {},
   "source": [
    "## Specialized deceptor detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "43f68e79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_265475/3158243288.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_deceptor['Labels'] = df_deceptor['Labels'].replace(7, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    968\n",
       "1    968\n",
       "Name: Labels, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_deceptor = df_master[(df_master.Labels == 0) | (df_master.Labels == 7)] \n",
    "df_deceptor['Labels'] = df_deceptor['Labels'].replace(7, 1)\n",
    "df_deceptor.Labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c625db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_deceptor.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ff8dfc2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_deceptor['Labels']\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "23dba69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1548, 1737)\n",
      "(1548,)\n",
      "(388, 1737)\n",
      "(388,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = tts(X,y,test_size=0.2) \n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "73d4bf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 1737)]            0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 40)                69520     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 20)                820       \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,361\n",
      "Trainable params: 70,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(1737,))\n",
    "\n",
    "x = tf.keras.layers.Dense(40,activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dense(20,activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model_deceptor = tf.keras.Model(inputs=inputs,outputs=output)\n",
    "model_deceptor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1a042864",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deceptor.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5bf59668",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ok_sikha/anaconda3/envs/tf_gpu_segnet/lib/python3.9/site-packages/keras/backend.py:5673: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 11ms/step - loss: 0.6829 - accuracy: 0.5679 - val_loss: 0.6623 - val_accuracy: 0.6935\n",
      "Epoch 2/100\n",
      "16/39 [===========>..................] - ETA: 0s - loss: 0.6555 - accuracy: 0.6699"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ok_sikha/anaconda3/envs/tf_gpu_segnet/lib/python3.9/site-packages/keras/backend.py:5673: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 5ms/step - loss: 0.6388 - accuracy: 0.7044 - val_loss: 0.6034 - val_accuracy: 0.7097\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.5734 - accuracy: 0.7270 - val_loss: 0.5411 - val_accuracy: 0.7355\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.5194 - accuracy: 0.7472 - val_loss: 0.5151 - val_accuracy: 0.7387\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.4970 - accuracy: 0.7561 - val_loss: 0.5056 - val_accuracy: 0.7516\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.4800 - accuracy: 0.7464 - val_loss: 0.4893 - val_accuracy: 0.7613\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.4674 - accuracy: 0.7601 - val_loss: 0.4936 - val_accuracy: 0.7742\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4554 - accuracy: 0.7658 - val_loss: 0.4812 - val_accuracy: 0.7742\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7666 - val_loss: 0.4752 - val_accuracy: 0.7645\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.7763 - val_loss: 0.4706 - val_accuracy: 0.7677\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4345 - accuracy: 0.7763 - val_loss: 0.4650 - val_accuracy: 0.7742\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7779 - val_loss: 0.4661 - val_accuracy: 0.7774\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.4241 - accuracy: 0.7851 - val_loss: 0.4689 - val_accuracy: 0.7806\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.4165 - accuracy: 0.7771 - val_loss: 0.4645 - val_accuracy: 0.7806\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4164 - accuracy: 0.7819 - val_loss: 0.4689 - val_accuracy: 0.7806\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.4129 - accuracy: 0.7859 - val_loss: 0.4687 - val_accuracy: 0.7806\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.7835 - val_loss: 0.4708 - val_accuracy: 0.7774\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.4148 - accuracy: 0.7859 - val_loss: 0.4689 - val_accuracy: 0.7774\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4107 - accuracy: 0.7843 - val_loss: 0.4658 - val_accuracy: 0.7806\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.7835 - val_loss: 0.4731 - val_accuracy: 0.7806\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.4096 - accuracy: 0.7851 - val_loss: 0.4717 - val_accuracy: 0.7774\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.7851 - val_loss: 0.4707 - val_accuracy: 0.7806\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.4010 - accuracy: 0.7827 - val_loss: 0.4735 - val_accuracy: 0.7774\n",
      "Epoch 24/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.7868 - val_loss: 0.4812 - val_accuracy: 0.7742\n",
      "Epoch 25/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4083 - accuracy: 0.7819 - val_loss: 0.4826 - val_accuracy: 0.7774\n",
      "Epoch 26/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.7843 - val_loss: 0.4816 - val_accuracy: 0.7774\n",
      "Epoch 27/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.4010 - accuracy: 0.7835 - val_loss: 0.4950 - val_accuracy: 0.7806\n",
      "Epoch 28/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.7884 - val_loss: 0.4865 - val_accuracy: 0.7774\n",
      "Epoch 29/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.4004 - accuracy: 0.7843 - val_loss: 0.4865 - val_accuracy: 0.7806\n",
      "Epoch 30/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.7868 - val_loss: 0.4800 - val_accuracy: 0.7774\n",
      "Epoch 31/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3999 - accuracy: 0.7868 - val_loss: 0.4859 - val_accuracy: 0.7774\n",
      "Epoch 32/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.7868 - val_loss: 0.4858 - val_accuracy: 0.7774\n",
      "Epoch 33/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.4003 - accuracy: 0.7876 - val_loss: 0.4897 - val_accuracy: 0.7806\n",
      "Epoch 34/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3975 - accuracy: 0.7859 - val_loss: 0.4868 - val_accuracy: 0.7806\n",
      "Epoch 35/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3982 - accuracy: 0.7851 - val_loss: 0.4938 - val_accuracy: 0.7774\n",
      "Epoch 36/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.7868 - val_loss: 0.4999 - val_accuracy: 0.7774\n",
      "Epoch 37/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.7859 - val_loss: 0.4926 - val_accuracy: 0.7839\n",
      "Epoch 38/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.7884 - val_loss: 0.4958 - val_accuracy: 0.7839\n",
      "Epoch 39/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.7843 - val_loss: 0.4988 - val_accuracy: 0.7839\n",
      "Epoch 40/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3972 - accuracy: 0.7884 - val_loss: 0.4971 - val_accuracy: 0.7806\n",
      "Epoch 41/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3962 - accuracy: 0.7884 - val_loss: 0.4987 - val_accuracy: 0.7806\n",
      "Epoch 42/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.7900 - val_loss: 0.5057 - val_accuracy: 0.7774\n",
      "Epoch 43/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.7908 - val_loss: 0.5049 - val_accuracy: 0.7806\n",
      "Epoch 44/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.7868 - val_loss: 0.5119 - val_accuracy: 0.7742\n",
      "Epoch 45/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3937 - accuracy: 0.7868 - val_loss: 0.5102 - val_accuracy: 0.7806\n",
      "Epoch 46/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.7868 - val_loss: 0.5062 - val_accuracy: 0.7806\n",
      "Epoch 47/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.7876 - val_loss: 0.5090 - val_accuracy: 0.7806\n",
      "Epoch 48/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3934 - accuracy: 0.7884 - val_loss: 0.5098 - val_accuracy: 0.7806\n",
      "Epoch 49/100\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.3953 - accuracy: 0.7884 - val_loss: 0.5146 - val_accuracy: 0.7806\n",
      "Epoch 50/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.3950 - accuracy: 0.7892 - val_loss: 0.5168 - val_accuracy: 0.7839\n",
      "Epoch 51/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3927 - accuracy: 0.7884 - val_loss: 0.5171 - val_accuracy: 0.7806\n",
      "Epoch 52/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3948 - accuracy: 0.7892 - val_loss: 0.5296 - val_accuracy: 0.7774\n",
      "Epoch 53/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3947 - accuracy: 0.7884 - val_loss: 0.5257 - val_accuracy: 0.7806\n",
      "Epoch 54/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3924 - accuracy: 0.7884 - val_loss: 0.5337 - val_accuracy: 0.7742\n",
      "Epoch 55/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3945 - accuracy: 0.7884 - val_loss: 0.5341 - val_accuracy: 0.7774\n",
      "Epoch 56/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.7884 - val_loss: 0.5277 - val_accuracy: 0.7806\n",
      "Epoch 57/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.7868 - val_loss: 0.5348 - val_accuracy: 0.7806\n",
      "Epoch 58/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.7884 - val_loss: 0.5327 - val_accuracy: 0.7806\n",
      "Epoch 59/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3883 - accuracy: 0.7892 - val_loss: 0.5394 - val_accuracy: 0.7774\n",
      "Epoch 60/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3948 - accuracy: 0.7876 - val_loss: 0.5347 - val_accuracy: 0.7806\n",
      "Epoch 61/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3918 - accuracy: 0.7892 - val_loss: 0.5460 - val_accuracy: 0.7774\n",
      "Epoch 62/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3935 - accuracy: 0.7884 - val_loss: 0.5392 - val_accuracy: 0.7774\n",
      "Epoch 63/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3933 - accuracy: 0.7892 - val_loss: 0.5506 - val_accuracy: 0.7774\n",
      "Epoch 64/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.7884 - val_loss: 0.5371 - val_accuracy: 0.7774\n",
      "Epoch 65/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.7884 - val_loss: 0.5431 - val_accuracy: 0.7774\n",
      "Epoch 66/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3940 - accuracy: 0.7876 - val_loss: 0.5402 - val_accuracy: 0.7806\n",
      "Epoch 67/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3930 - accuracy: 0.7900 - val_loss: 0.5490 - val_accuracy: 0.7774\n",
      "Epoch 68/100\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.3918 - accuracy: 0.7876 - val_loss: 0.5434 - val_accuracy: 0.7806\n",
      "Epoch 69/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.3928 - accuracy: 0.7884 - val_loss: 0.5443 - val_accuracy: 0.7806\n",
      "Epoch 70/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3940 - accuracy: 0.7884 - val_loss: 0.5650 - val_accuracy: 0.7742\n",
      "Epoch 71/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3913 - accuracy: 0.7892 - val_loss: 0.5518 - val_accuracy: 0.7806\n",
      "Epoch 72/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.7876 - val_loss: 0.5711 - val_accuracy: 0.7742\n",
      "Epoch 73/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.7892 - val_loss: 0.5531 - val_accuracy: 0.7774\n",
      "Epoch 74/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3947 - accuracy: 0.7876 - val_loss: 0.5574 - val_accuracy: 0.7774\n",
      "Epoch 75/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.3914 - accuracy: 0.7868 - val_loss: 0.5557 - val_accuracy: 0.7806\n",
      "Epoch 76/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3920 - accuracy: 0.7900 - val_loss: 0.5528 - val_accuracy: 0.7806\n",
      "Epoch 77/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.7892 - val_loss: 0.5539 - val_accuracy: 0.7806\n",
      "Epoch 78/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3906 - accuracy: 0.7900 - val_loss: 0.5725 - val_accuracy: 0.7742\n",
      "Epoch 79/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.7884 - val_loss: 0.5724 - val_accuracy: 0.7806\n",
      "Epoch 80/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.7884 - val_loss: 0.5768 - val_accuracy: 0.7774\n",
      "Epoch 81/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.7892 - val_loss: 0.5802 - val_accuracy: 0.7774\n",
      "Epoch 82/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3953 - accuracy: 0.7892 - val_loss: 0.5702 - val_accuracy: 0.7774\n",
      "Epoch 83/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.7876 - val_loss: 0.5756 - val_accuracy: 0.7839\n",
      "Epoch 84/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3900 - accuracy: 0.7884 - val_loss: 0.5834 - val_accuracy: 0.7774\n",
      "Epoch 85/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3919 - accuracy: 0.7884 - val_loss: 0.5757 - val_accuracy: 0.7806\n",
      "Epoch 86/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3902 - accuracy: 0.7892 - val_loss: 0.5771 - val_accuracy: 0.7806\n",
      "Epoch 87/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3903 - accuracy: 0.7884 - val_loss: 0.5810 - val_accuracy: 0.7774\n",
      "Epoch 88/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.7892 - val_loss: 0.5849 - val_accuracy: 0.7774\n",
      "Epoch 89/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3918 - accuracy: 0.7884 - val_loss: 0.5924 - val_accuracy: 0.7774\n",
      "Epoch 90/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3913 - accuracy: 0.7892 - val_loss: 0.5940 - val_accuracy: 0.7742\n",
      "Epoch 91/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.7884 - val_loss: 0.5890 - val_accuracy: 0.7742\n",
      "Epoch 92/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3892 - accuracy: 0.7892 - val_loss: 0.5925 - val_accuracy: 0.7742\n",
      "Epoch 93/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3900 - accuracy: 0.7884 - val_loss: 0.5834 - val_accuracy: 0.7774\n",
      "Epoch 94/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.7892 - val_loss: 0.6061 - val_accuracy: 0.7742\n",
      "Epoch 95/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.3921 - accuracy: 0.7892 - val_loss: 0.5918 - val_accuracy: 0.7774\n",
      "Epoch 96/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.3873 - accuracy: 0.7892 - val_loss: 0.5976 - val_accuracy: 0.7774\n",
      "Epoch 97/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3914 - accuracy: 0.7892 - val_loss: 0.5920 - val_accuracy: 0.7774\n",
      "Epoch 98/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3892 - accuracy: 0.7892 - val_loss: 0.5951 - val_accuracy: 0.7742\n",
      "Epoch 99/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.7900 - val_loss: 0.6150 - val_accuracy: 0.7742\n",
      "Epoch 100/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3910 - accuracy: 0.7892 - val_loss: 0.5936 - val_accuracy: 0.7774\n",
      "13/13 - 0s - loss: 0.5844 - accuracy: 0.7320 - 66ms/epoch - 5ms/step\n",
      "Test loss:  0.5844281911849976\n",
      "Test accuracy:  0.7319587469100952\n"
     ]
    }
   ],
   "source": [
    "model_deceptor.fit(x_train, y_train, batch_size=32, epochs=100, validation_split=0.2)\n",
    "test_score = model_deceptor.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss: \", test_score[0])\n",
    "print(\"Test accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729572b0",
   "metadata": {},
   "source": [
    "## Specialized cryptominer detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7a999f28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_265475/928835577.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cryptominer['Labels'] = df_cryptominer['Labels'].replace(8, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    968\n",
       "1    968\n",
       "Name: Labels, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cryptominer = df_master[(df_master.Labels == 0) | (df_master.Labels == 8)] \n",
    "df_cryptominer['Labels'] = df_cryptominer['Labels'].replace(8, 1)\n",
    "df_cryptominer.Labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f4c3ce93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process Profiling-&gt;Thread Exit</th>\n",
       "      <th>Process Profiling-&gt;Thread Create</th>\n",
       "      <th>Thread Exit-&gt;Process Profiling</th>\n",
       "      <th>Thread Exit-&gt;Thread Exit</th>\n",
       "      <th>Thread Exit-&gt;Thread Create</th>\n",
       "      <th>Thread Exit-&gt;ReadFile</th>\n",
       "      <th>Thread Exit-&gt;RegQueryKey</th>\n",
       "      <th>Thread Exit-&gt;RegOpenKey</th>\n",
       "      <th>Thread Exit-&gt;RegQueryValue</th>\n",
       "      <th>Thread Exit-&gt;CreateFileMapping</th>\n",
       "      <th>...</th>\n",
       "      <th>QueryDeviceRelations-&gt;ReadFile</th>\n",
       "      <th>QueryDeviceRelations-&gt;RegQueryKey</th>\n",
       "      <th>QueryDeviceRelations-&gt;RegOpenKey</th>\n",
       "      <th>QueryDeviceRelations-&gt;RegQueryValue</th>\n",
       "      <th>QueryDeviceRelations-&gt;CreateFile</th>\n",
       "      <th>QueryDeviceRelations-&gt;QueryBasicInformationFile</th>\n",
       "      <th>TCP Accept-&gt;TCP TCPCopy</th>\n",
       "      <th>CreatePipe-&gt;CreateFile</th>\n",
       "      <th>RegSaveKey-&gt;WriteFile</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8707</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8708</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8709</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8710</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8711</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1936 rows Ã— 1738 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Process Profiling->Thread Exit  Process Profiling->Thread Create  \\\n",
       "0                                  1                                 0   \n",
       "1                                  1                                 0   \n",
       "2                                  0                                 1   \n",
       "3                                  0                                 0   \n",
       "4                                  1                                 0   \n",
       "...                              ...                               ...   \n",
       "8707                               0                                 0   \n",
       "8708                               0                                 0   \n",
       "8709                               0                                 0   \n",
       "8710                               0                                 0   \n",
       "8711                               0                                 0   \n",
       "\n",
       "      Thread Exit->Process Profiling  Thread Exit->Thread Exit  \\\n",
       "0                                  0                         0   \n",
       "1                                  0                         0   \n",
       "2                                  0                         0   \n",
       "3                                  0                         0   \n",
       "4                                  0                         0   \n",
       "...                              ...                       ...   \n",
       "8707                               0                         0   \n",
       "8708                               0                         0   \n",
       "8709                               0                         0   \n",
       "8710                               0                         0   \n",
       "8711                               0                         0   \n",
       "\n",
       "      Thread Exit->Thread Create  Thread Exit->ReadFile  \\\n",
       "0                            1.0                    0.0   \n",
       "1                            1.0                    0.0   \n",
       "2                            0.0                    0.0   \n",
       "3                            0.0                    0.0   \n",
       "4                            1.0                    0.0   \n",
       "...                          ...                    ...   \n",
       "8707                         0.0                    0.0   \n",
       "8708                         0.0                    0.0   \n",
       "8709                         0.0                    0.0   \n",
       "8710                         0.0                    0.0   \n",
       "8711                         0.0                    0.0   \n",
       "\n",
       "      Thread Exit->RegQueryKey  Thread Exit->RegOpenKey  \\\n",
       "0                          0.0                      0.0   \n",
       "1                          0.0                      0.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          0.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "8707                       0.0                      0.0   \n",
       "8708                       0.0                      0.0   \n",
       "8709                       0.0                      0.0   \n",
       "8710                       0.0                      0.0   \n",
       "8711                       0.0                      0.0   \n",
       "\n",
       "      Thread Exit->RegQueryValue  Thread Exit->CreateFileMapping  ...  \\\n",
       "0                            0.0                             0.0  ...   \n",
       "1                            0.0                             0.0  ...   \n",
       "2                            0.0                             0.0  ...   \n",
       "3                            0.0                             0.0  ...   \n",
       "4                            0.0                             0.0  ...   \n",
       "...                          ...                             ...  ...   \n",
       "8707                         0.0                             0.0  ...   \n",
       "8708                         0.0                             0.0  ...   \n",
       "8709                         0.0                             0.0  ...   \n",
       "8710                         0.0                             0.0  ...   \n",
       "8711                         0.0                             0.0  ...   \n",
       "\n",
       "      QueryDeviceRelations->ReadFile  QueryDeviceRelations->RegQueryKey  \\\n",
       "0                                0.0                                0.0   \n",
       "1                                0.0                                0.0   \n",
       "2                                0.0                                0.0   \n",
       "3                                0.0                                0.0   \n",
       "4                                0.0                                0.0   \n",
       "...                              ...                                ...   \n",
       "8707                             0.0                                0.0   \n",
       "8708                             0.0                                0.0   \n",
       "8709                             0.0                                0.0   \n",
       "8710                             0.0                                0.0   \n",
       "8711                             0.0                                0.0   \n",
       "\n",
       "      QueryDeviceRelations->RegOpenKey  QueryDeviceRelations->RegQueryValue  \\\n",
       "0                                  0.0                                  0.0   \n",
       "1                                  0.0                                  0.0   \n",
       "2                                  0.0                                  0.0   \n",
       "3                                  0.0                                  0.0   \n",
       "4                                  0.0                                  0.0   \n",
       "...                                ...                                  ...   \n",
       "8707                               0.0                                  0.0   \n",
       "8708                               0.0                                  0.0   \n",
       "8709                               0.0                                  0.0   \n",
       "8710                               0.0                                  0.0   \n",
       "8711                               0.0                                  0.0   \n",
       "\n",
       "      QueryDeviceRelations->CreateFile  \\\n",
       "0                                  0.0   \n",
       "1                                  0.0   \n",
       "2                                  0.0   \n",
       "3                                  0.0   \n",
       "4                                  0.0   \n",
       "...                                ...   \n",
       "8707                               0.0   \n",
       "8708                               0.0   \n",
       "8709                               0.0   \n",
       "8710                               0.0   \n",
       "8711                               0.0   \n",
       "\n",
       "      QueryDeviceRelations->QueryBasicInformationFile  \\\n",
       "0                                                 0.0   \n",
       "1                                                 0.0   \n",
       "2                                                 0.0   \n",
       "3                                                 0.0   \n",
       "4                                                 0.0   \n",
       "...                                               ...   \n",
       "8707                                              0.0   \n",
       "8708                                              0.0   \n",
       "8709                                              0.0   \n",
       "8710                                              0.0   \n",
       "8711                                              0.0   \n",
       "\n",
       "      TCP Accept->TCP TCPCopy  CreatePipe->CreateFile  RegSaveKey->WriteFile  \\\n",
       "0                           0                       0                      0   \n",
       "1                           0                       0                      0   \n",
       "2                           0                       0                      0   \n",
       "3                           0                       0                      0   \n",
       "4                           0                       0                      0   \n",
       "...                       ...                     ...                    ...   \n",
       "8707                        0                       0                      0   \n",
       "8708                        0                       0                      0   \n",
       "8709                        0                       0                      0   \n",
       "8710                        0                       0                      0   \n",
       "8711                        0                       0                      0   \n",
       "\n",
       "      Labels  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "8707       1  \n",
       "8708       1  \n",
       "8709       1  \n",
       "8710       1  \n",
       "8711       1  \n",
       "\n",
       "[1936 rows x 1738 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cryptominer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f07e24a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cryptominer.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6c16aa6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Process Profiling-&gt;Thread Exit</th>\n",
       "      <th>Process Profiling-&gt;Thread Create</th>\n",
       "      <th>Thread Exit-&gt;Process Profiling</th>\n",
       "      <th>Thread Exit-&gt;Thread Exit</th>\n",
       "      <th>Thread Exit-&gt;Thread Create</th>\n",
       "      <th>Thread Exit-&gt;ReadFile</th>\n",
       "      <th>Thread Exit-&gt;RegQueryKey</th>\n",
       "      <th>Thread Exit-&gt;RegOpenKey</th>\n",
       "      <th>Thread Exit-&gt;RegQueryValue</th>\n",
       "      <th>Thread Exit-&gt;CreateFileMapping</th>\n",
       "      <th>...</th>\n",
       "      <th>QueryPositionInformationFile-&gt;SetEndOfFileInformationFile</th>\n",
       "      <th>QueryDeviceRelations-&gt;ReadFile</th>\n",
       "      <th>QueryDeviceRelations-&gt;RegQueryKey</th>\n",
       "      <th>QueryDeviceRelations-&gt;RegOpenKey</th>\n",
       "      <th>QueryDeviceRelations-&gt;RegQueryValue</th>\n",
       "      <th>QueryDeviceRelations-&gt;CreateFile</th>\n",
       "      <th>QueryDeviceRelations-&gt;QueryBasicInformationFile</th>\n",
       "      <th>TCP Accept-&gt;TCP TCPCopy</th>\n",
       "      <th>CreatePipe-&gt;CreateFile</th>\n",
       "      <th>RegSaveKey-&gt;WriteFile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8707</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8708</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8709</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8710</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8711</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1936 rows Ã— 1737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Process Profiling->Thread Exit  Process Profiling->Thread Create  \\\n",
       "0                                  1                                 0   \n",
       "1                                  1                                 0   \n",
       "2                                  0                                 1   \n",
       "3                                  0                                 0   \n",
       "4                                  1                                 0   \n",
       "...                              ...                               ...   \n",
       "8707                               0                                 0   \n",
       "8708                               0                                 0   \n",
       "8709                               0                                 0   \n",
       "8710                               0                                 0   \n",
       "8711                               0                                 0   \n",
       "\n",
       "      Thread Exit->Process Profiling  Thread Exit->Thread Exit  \\\n",
       "0                                  0                         0   \n",
       "1                                  0                         0   \n",
       "2                                  0                         0   \n",
       "3                                  0                         0   \n",
       "4                                  0                         0   \n",
       "...                              ...                       ...   \n",
       "8707                               0                         0   \n",
       "8708                               0                         0   \n",
       "8709                               0                         0   \n",
       "8710                               0                         0   \n",
       "8711                               0                         0   \n",
       "\n",
       "      Thread Exit->Thread Create  Thread Exit->ReadFile  \\\n",
       "0                            1.0                    0.0   \n",
       "1                            1.0                    0.0   \n",
       "2                            0.0                    0.0   \n",
       "3                            0.0                    0.0   \n",
       "4                            1.0                    0.0   \n",
       "...                          ...                    ...   \n",
       "8707                         0.0                    0.0   \n",
       "8708                         0.0                    0.0   \n",
       "8709                         0.0                    0.0   \n",
       "8710                         0.0                    0.0   \n",
       "8711                         0.0                    0.0   \n",
       "\n",
       "      Thread Exit->RegQueryKey  Thread Exit->RegOpenKey  \\\n",
       "0                          0.0                      0.0   \n",
       "1                          0.0                      0.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          0.0                      0.0   \n",
       "4                          0.0                      0.0   \n",
       "...                        ...                      ...   \n",
       "8707                       0.0                      0.0   \n",
       "8708                       0.0                      0.0   \n",
       "8709                       0.0                      0.0   \n",
       "8710                       0.0                      0.0   \n",
       "8711                       0.0                      0.0   \n",
       "\n",
       "      Thread Exit->RegQueryValue  Thread Exit->CreateFileMapping  ...  \\\n",
       "0                            0.0                             0.0  ...   \n",
       "1                            0.0                             0.0  ...   \n",
       "2                            0.0                             0.0  ...   \n",
       "3                            0.0                             0.0  ...   \n",
       "4                            0.0                             0.0  ...   \n",
       "...                          ...                             ...  ...   \n",
       "8707                         0.0                             0.0  ...   \n",
       "8708                         0.0                             0.0  ...   \n",
       "8709                         0.0                             0.0  ...   \n",
       "8710                         0.0                             0.0  ...   \n",
       "8711                         0.0                             0.0  ...   \n",
       "\n",
       "      QueryPositionInformationFile->SetEndOfFileInformationFile  \\\n",
       "0                                                     0           \n",
       "1                                                     0           \n",
       "2                                                     0           \n",
       "3                                                     0           \n",
       "4                                                     0           \n",
       "...                                                 ...           \n",
       "8707                                                  0           \n",
       "8708                                                  0           \n",
       "8709                                                  0           \n",
       "8710                                                  0           \n",
       "8711                                                  0           \n",
       "\n",
       "      QueryDeviceRelations->ReadFile  QueryDeviceRelations->RegQueryKey  \\\n",
       "0                                0.0                                0.0   \n",
       "1                                0.0                                0.0   \n",
       "2                                0.0                                0.0   \n",
       "3                                0.0                                0.0   \n",
       "4                                0.0                                0.0   \n",
       "...                              ...                                ...   \n",
       "8707                             0.0                                0.0   \n",
       "8708                             0.0                                0.0   \n",
       "8709                             0.0                                0.0   \n",
       "8710                             0.0                                0.0   \n",
       "8711                             0.0                                0.0   \n",
       "\n",
       "      QueryDeviceRelations->RegOpenKey  QueryDeviceRelations->RegQueryValue  \\\n",
       "0                                  0.0                                  0.0   \n",
       "1                                  0.0                                  0.0   \n",
       "2                                  0.0                                  0.0   \n",
       "3                                  0.0                                  0.0   \n",
       "4                                  0.0                                  0.0   \n",
       "...                                ...                                  ...   \n",
       "8707                               0.0                                  0.0   \n",
       "8708                               0.0                                  0.0   \n",
       "8709                               0.0                                  0.0   \n",
       "8710                               0.0                                  0.0   \n",
       "8711                               0.0                                  0.0   \n",
       "\n",
       "      QueryDeviceRelations->CreateFile  \\\n",
       "0                                  0.0   \n",
       "1                                  0.0   \n",
       "2                                  0.0   \n",
       "3                                  0.0   \n",
       "4                                  0.0   \n",
       "...                                ...   \n",
       "8707                               0.0   \n",
       "8708                               0.0   \n",
       "8709                               0.0   \n",
       "8710                               0.0   \n",
       "8711                               0.0   \n",
       "\n",
       "      QueryDeviceRelations->QueryBasicInformationFile  \\\n",
       "0                                                 0.0   \n",
       "1                                                 0.0   \n",
       "2                                                 0.0   \n",
       "3                                                 0.0   \n",
       "4                                                 0.0   \n",
       "...                                               ...   \n",
       "8707                                              0.0   \n",
       "8708                                              0.0   \n",
       "8709                                              0.0   \n",
       "8710                                              0.0   \n",
       "8711                                              0.0   \n",
       "\n",
       "      TCP Accept->TCP TCPCopy  CreatePipe->CreateFile  RegSaveKey->WriteFile  \n",
       "0                           0                       0                      0  \n",
       "1                           0                       0                      0  \n",
       "2                           0                       0                      0  \n",
       "3                           0                       0                      0  \n",
       "4                           0                       0                      0  \n",
       "...                       ...                     ...                    ...  \n",
       "8707                        0                       0                      0  \n",
       "8708                        0                       0                      0  \n",
       "8709                        0                       0                      0  \n",
       "8710                        0                       0                      0  \n",
       "8711                        0                       0                      0  \n",
       "\n",
       "[1936 rows x 1737 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b98c67a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_cryptominer['Labels']\n",
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "788f8668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1548, 1737)\n",
      "(1548,)\n",
      "(388, 1737)\n",
      "(388,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = tts(X,y,test_size=0.2) \n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4c7bf7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 1737)]            0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 40)                69520     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 20)                820       \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,361\n",
      "Trainable params: 70,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(1737,))\n",
    "\n",
    "x = tf.keras.layers.Dense(40,activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dense(20,activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model_cryptominer = tf.keras.Model(inputs=inputs,outputs=output)\n",
    "model_cryptominer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bad9958c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cryptominer.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4c9e92c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ok_sikha/anaconda3/envs/tf_gpu_segnet/lib/python3.9/site-packages/keras/backend.py:5673: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 13ms/step - loss: 0.5704 - accuracy: 0.8974 - val_loss: 0.4257 - val_accuracy: 0.9419\n",
      "Epoch 2/100\n",
      "17/39 [============>.................] - ETA: 0s - loss: 0.3580 - accuracy: 0.9559"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ok_sikha/anaconda3/envs/tf_gpu_segnet/lib/python3.9/site-packages/keras/backend.py:5673: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 4ms/step - loss: 0.3007 - accuracy: 0.9556 - val_loss: 0.2241 - val_accuracy: 0.9516\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.1515 - accuracy: 0.9653 - val_loss: 0.1730 - val_accuracy: 0.9516\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 1s 12ms/step - loss: 0.1071 - accuracy: 0.9677 - val_loss: 0.1634 - val_accuracy: 0.9516\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.0970 - accuracy: 0.9709 - val_loss: 0.1602 - val_accuracy: 0.9516\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0877 - accuracy: 0.9758 - val_loss: 0.1670 - val_accuracy: 0.9516\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0782 - accuracy: 0.9766 - val_loss: 0.1587 - val_accuracy: 0.9548\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0778 - accuracy: 0.9782 - val_loss: 0.1745 - val_accuracy: 0.9548\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0658 - accuracy: 0.9814 - val_loss: 0.1587 - val_accuracy: 0.9613\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0739 - accuracy: 0.9782 - val_loss: 0.1803 - val_accuracy: 0.9548\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.0749 - accuracy: 0.9782 - val_loss: 0.1638 - val_accuracy: 0.9645\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0683 - accuracy: 0.9822 - val_loss: 0.1646 - val_accuracy: 0.9645\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0645 - accuracy: 0.9838 - val_loss: 0.1644 - val_accuracy: 0.9645\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0670 - accuracy: 0.9838 - val_loss: 0.1641 - val_accuracy: 0.9645\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0628 - accuracy: 0.9830 - val_loss: 0.1672 - val_accuracy: 0.9645\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0649 - accuracy: 0.9830 - val_loss: 0.1643 - val_accuracy: 0.9645\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0651 - accuracy: 0.9838 - val_loss: 0.1593 - val_accuracy: 0.9645\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0613 - accuracy: 0.9830 - val_loss: 0.1771 - val_accuracy: 0.9645\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0604 - accuracy: 0.9838 - val_loss: 0.1665 - val_accuracy: 0.9645\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0615 - accuracy: 0.9838 - val_loss: 0.1742 - val_accuracy: 0.9645\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.0622 - accuracy: 0.9838 - val_loss: 0.1739 - val_accuracy: 0.9645\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0587 - accuracy: 0.9838 - val_loss: 0.1739 - val_accuracy: 0.9645\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0624 - accuracy: 0.9838 - val_loss: 0.1686 - val_accuracy: 0.9645\n",
      "Epoch 24/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.0582 - accuracy: 0.9838 - val_loss: 0.1749 - val_accuracy: 0.9645\n",
      "Epoch 25/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0591 - accuracy: 0.9838 - val_loss: 0.1751 - val_accuracy: 0.9645\n",
      "Epoch 26/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0585 - accuracy: 0.9838 - val_loss: 0.1820 - val_accuracy: 0.9645\n",
      "Epoch 27/100\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.0611 - accuracy: 0.9838 - val_loss: 0.1848 - val_accuracy: 0.9645\n",
      "Epoch 28/100\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0587 - accuracy: 0.9838 - val_loss: 0.1859 - val_accuracy: 0.9645\n",
      "Epoch 29/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0566 - accuracy: 0.9838 - val_loss: 0.1902 - val_accuracy: 0.9645\n",
      "Epoch 30/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0569 - accuracy: 0.9838 - val_loss: 0.1864 - val_accuracy: 0.9645\n",
      "Epoch 31/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0587 - accuracy: 0.9838 - val_loss: 0.1887 - val_accuracy: 0.9645\n",
      "Epoch 32/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.9838 - val_loss: 0.1895 - val_accuracy: 0.9645\n",
      "Epoch 33/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0571 - accuracy: 0.9838 - val_loss: 0.1929 - val_accuracy: 0.9645\n",
      "Epoch 34/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0550 - accuracy: 0.9838 - val_loss: 0.1933 - val_accuracy: 0.9645\n",
      "Epoch 35/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0573 - accuracy: 0.9838 - val_loss: 0.1947 - val_accuracy: 0.9645\n",
      "Epoch 36/100\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0597 - accuracy: 0.9838 - val_loss: 0.1930 - val_accuracy: 0.9645\n",
      "Epoch 37/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0574 - accuracy: 0.9838 - val_loss: 0.1949 - val_accuracy: 0.9645\n",
      "Epoch 38/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0568 - accuracy: 0.9838 - val_loss: 0.1982 - val_accuracy: 0.9645\n",
      "Epoch 39/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0537 - accuracy: 0.9838 - val_loss: 0.1990 - val_accuracy: 0.9645\n",
      "Epoch 40/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0583 - accuracy: 0.9838 - val_loss: 0.2009 - val_accuracy: 0.9645\n",
      "Epoch 41/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.9838 - val_loss: 0.2045 - val_accuracy: 0.9645\n",
      "Epoch 42/100\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0600 - accuracy: 0.9838 - val_loss: 0.2041 - val_accuracy: 0.9645\n",
      "Epoch 43/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.9838 - val_loss: 0.2046 - val_accuracy: 0.9645\n",
      "Epoch 44/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0580 - accuracy: 0.9838 - val_loss: 0.2064 - val_accuracy: 0.9645\n",
      "Epoch 45/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0552 - accuracy: 0.9838 - val_loss: 0.2082 - val_accuracy: 0.9645\n",
      "Epoch 46/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0571 - accuracy: 0.9838 - val_loss: 0.2109 - val_accuracy: 0.9645\n",
      "Epoch 47/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0589 - accuracy: 0.9838 - val_loss: 0.2130 - val_accuracy: 0.9645\n",
      "Epoch 48/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0554 - accuracy: 0.9838 - val_loss: 0.2157 - val_accuracy: 0.9645\n",
      "Epoch 49/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0573 - accuracy: 0.9838 - val_loss: 0.2143 - val_accuracy: 0.9645\n",
      "Epoch 50/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0512 - accuracy: 0.9838 - val_loss: 0.2156 - val_accuracy: 0.9645\n",
      "Epoch 51/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0574 - accuracy: 0.9838 - val_loss: 0.2190 - val_accuracy: 0.9645\n",
      "Epoch 52/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0674 - accuracy: 0.9822 - val_loss: 0.1964 - val_accuracy: 0.9645\n",
      "Epoch 53/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0598 - accuracy: 0.9838 - val_loss: 0.2083 - val_accuracy: 0.9645\n",
      "Epoch 54/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.0558 - accuracy: 0.9838 - val_loss: 0.2054 - val_accuracy: 0.9645\n",
      "Epoch 55/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.9838 - val_loss: 0.2040 - val_accuracy: 0.9645\n",
      "Epoch 56/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0579 - accuracy: 0.9838 - val_loss: 0.2053 - val_accuracy: 0.9645\n",
      "Epoch 57/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0544 - accuracy: 0.9838 - val_loss: 0.2055 - val_accuracy: 0.9645\n",
      "Epoch 58/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.0558 - accuracy: 0.9838 - val_loss: 0.2074 - val_accuracy: 0.9645\n",
      "Epoch 59/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.9838 - val_loss: 0.2069 - val_accuracy: 0.9645\n",
      "Epoch 60/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0574 - accuracy: 0.9838 - val_loss: 0.2079 - val_accuracy: 0.9645\n",
      "Epoch 61/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0545 - accuracy: 0.9838 - val_loss: 0.2105 - val_accuracy: 0.9645\n",
      "Epoch 62/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0568 - accuracy: 0.9838 - val_loss: 0.2119 - val_accuracy: 0.9645\n",
      "Epoch 63/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0579 - accuracy: 0.9838 - val_loss: 0.2130 - val_accuracy: 0.9645\n",
      "Epoch 64/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0600 - accuracy: 0.9838 - val_loss: 0.2129 - val_accuracy: 0.9645\n",
      "Epoch 65/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0564 - accuracy: 0.9830 - val_loss: 0.2156 - val_accuracy: 0.9645\n",
      "Epoch 66/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.0575 - accuracy: 0.9838 - val_loss: 0.2138 - val_accuracy: 0.9645\n",
      "Epoch 67/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0578 - accuracy: 0.9838 - val_loss: 0.2138 - val_accuracy: 0.9645\n",
      "Epoch 68/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0562 - accuracy: 0.9838 - val_loss: 0.2168 - val_accuracy: 0.9645\n",
      "Epoch 69/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0565 - accuracy: 0.9838 - val_loss: 0.2163 - val_accuracy: 0.9645\n",
      "Epoch 70/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0551 - accuracy: 0.9838 - val_loss: 0.2172 - val_accuracy: 0.9645\n",
      "Epoch 71/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0563 - accuracy: 0.9838 - val_loss: 0.2216 - val_accuracy: 0.9645\n",
      "Epoch 72/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0576 - accuracy: 0.9838 - val_loss: 0.2233 - val_accuracy: 0.9645\n",
      "Epoch 73/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0586 - accuracy: 0.9838 - val_loss: 0.2261 - val_accuracy: 0.9645\n",
      "Epoch 74/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0541 - accuracy: 0.9838 - val_loss: 0.2256 - val_accuracy: 0.9645\n",
      "Epoch 75/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0576 - accuracy: 0.9838 - val_loss: 0.2260 - val_accuracy: 0.9645\n",
      "Epoch 76/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0565 - accuracy: 0.9838 - val_loss: 0.2335 - val_accuracy: 0.9645\n",
      "Epoch 77/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0578 - accuracy: 0.9838 - val_loss: 0.2335 - val_accuracy: 0.9645\n",
      "Epoch 78/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0601 - accuracy: 0.9838 - val_loss: 0.2363 - val_accuracy: 0.9645\n",
      "Epoch 79/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0541 - accuracy: 0.9838 - val_loss: 0.2365 - val_accuracy: 0.9645\n",
      "Epoch 80/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0546 - accuracy: 0.9838 - val_loss: 0.2375 - val_accuracy: 0.9645\n",
      "Epoch 81/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0588 - accuracy: 0.9838 - val_loss: 0.2399 - val_accuracy: 0.9645\n",
      "Epoch 82/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.9838 - val_loss: 0.2421 - val_accuracy: 0.9645\n",
      "Epoch 83/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0552 - accuracy: 0.9838 - val_loss: 0.2386 - val_accuracy: 0.9645\n",
      "Epoch 84/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0558 - accuracy: 0.9838 - val_loss: 0.2407 - val_accuracy: 0.9645\n",
      "Epoch 85/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.0538 - accuracy: 0.9838 - val_loss: 0.2420 - val_accuracy: 0.9645\n",
      "Epoch 86/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.9838 - val_loss: 0.2409 - val_accuracy: 0.9645\n",
      "Epoch 87/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0563 - accuracy: 0.9838 - val_loss: 0.2429 - val_accuracy: 0.9645\n",
      "Epoch 88/100\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0560 - accuracy: 0.9838 - val_loss: 0.2433 - val_accuracy: 0.9645\n",
      "Epoch 89/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0563 - accuracy: 0.9838 - val_loss: 0.2441 - val_accuracy: 0.9645\n",
      "Epoch 90/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0580 - accuracy: 0.9838 - val_loss: 0.2450 - val_accuracy: 0.9645\n",
      "Epoch 91/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0559 - accuracy: 0.9838 - val_loss: 0.2443 - val_accuracy: 0.9645\n",
      "Epoch 92/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0593 - accuracy: 0.9838 - val_loss: 0.2422 - val_accuracy: 0.9645\n",
      "Epoch 93/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0564 - accuracy: 0.9838 - val_loss: 0.2482 - val_accuracy: 0.9645\n",
      "Epoch 94/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0568 - accuracy: 0.9838 - val_loss: 0.2480 - val_accuracy: 0.9645\n",
      "Epoch 95/100\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 0.0541 - accuracy: 0.9838 - val_loss: 0.2503 - val_accuracy: 0.9645\n",
      "Epoch 96/100\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0544 - accuracy: 0.9838 - val_loss: 0.2530 - val_accuracy: 0.9645\n",
      "Epoch 97/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0585 - accuracy: 0.9838 - val_loss: 0.2761 - val_accuracy: 0.9645\n",
      "Epoch 98/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0556 - accuracy: 0.9838 - val_loss: 0.2673 - val_accuracy: 0.9645\n",
      "Epoch 99/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0546 - accuracy: 0.9838 - val_loss: 0.2657 - val_accuracy: 0.9645\n",
      "Epoch 100/100\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.0549 - accuracy: 0.9838 - val_loss: 0.2577 - val_accuracy: 0.9645\n",
      "13/13 - 0s - loss: 0.1887 - accuracy: 0.9691 - 62ms/epoch - 5ms/step\n",
      "Test loss:  0.1886872947216034\n",
      "Test accuracy:  0.969072163105011\n"
     ]
    }
   ],
   "source": [
    "model_cryptominer.fit(x_train, y_train, batch_size=32, epochs=100, validation_split=0.2)\n",
    "test_score = model_cryptominer.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test loss: \", test_score[0])\n",
    "print(\"Test accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7dc1f6",
   "metadata": {},
   "source": [
    "## Input for the meta-learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "da798e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6969, 1737)\n",
      "(6969,)\n",
      "(1743, 1737)\n",
      "(1743,)\n"
     ]
    }
   ],
   "source": [
    "X = df_master.iloc[:,:-1]\n",
    "X = np.asarray(X).astype(np.float32)\n",
    "y = df_master['Labels'].replace([1, 2, 3, 4, 5, 6, 7, 8], 1)\n",
    "x_train, x_test, y_train, y_test = tts(X,y,test_size=0.2) \n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "78c97a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 2ms/step\n",
      "55/55 [==============================] - 0s 2ms/step\n",
      "55/55 [==============================] - 0s 1ms/step\n",
      "55/55 [==============================] - 0s 2ms/step\n",
      "55/55 [==============================] - 0s 1ms/step\n",
      "55/55 [==============================] - 0s 1ms/step\n",
      "55/55 [==============================] - 0s 2ms/step\n",
      "55/55 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "banker_preds = model_banker.predict(x_test)\n",
    "banker_preds = (banker_preds > 0.5).astype(int)\n",
    "\n",
    "spyware_preds = model_spyware.predict(x_test)\n",
    "spyware_preds = (spyware_preds > 0.5).astype(int)\n",
    "\n",
    "backdoor_preds = model_backdoor.predict(x_test)\n",
    "backdoor_preds = (backdoor_preds > 0.5).astype(int)\n",
    "\n",
    "ransomware_preds = model_ransomware.predict(x_test)\n",
    "ransomware_preds = (ransomware_preds > 0.5).astype(int)\n",
    "\n",
    "pua_preds = model_pua.predict(x_test)\n",
    "pua_preds = (pua_preds > 0.5).astype(int)\n",
    "\n",
    "downloader_preds = model_downloader.predict(x_test)\n",
    "downloader_preds = (downloader_preds > 0.5).astype(int)\n",
    "\n",
    "deceptor_preds = model_deceptor.predict(x_test)\n",
    "deceptor_preds = (deceptor_preds > 0.5).astype(int)\n",
    "\n",
    "cryptominer_preds = model_cryptominer.predict(x_test)\n",
    "cryptominer_preds = (cryptominer_preds > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b6a2695c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>banker</th>\n",
       "      <th>spyware</th>\n",
       "      <th>backdoor</th>\n",
       "      <th>ransomware</th>\n",
       "      <th>pua</th>\n",
       "      <th>downloader</th>\n",
       "      <th>deceptor</th>\n",
       "      <th>cryptominer</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4615</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4165</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4304</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2528</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1743 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      banker  spyware  backdoor  ransomware  pua  downloader  deceptor  \\\n",
       "455        1        1         1           0    1           1         0   \n",
       "2912       1        1         1           1    1           1         1   \n",
       "987        0        1         1           0    1           1         1   \n",
       "661        1        1         0           1    1           0         1   \n",
       "4615       1        1         1           0    1           1         1   \n",
       "...      ...      ...       ...         ...  ...         ...       ...   \n",
       "4165       1        1         1           0    1           1         1   \n",
       "1567       1        0         0           0    0           0         0   \n",
       "4304       0        1         0           0    0           0         1   \n",
       "1460       0        1         1           0    1           1         1   \n",
       "2528       1        1         1           1    1           1         0   \n",
       "\n",
       "      cryptominer  Target  \n",
       "455             1       1  \n",
       "2912            1       1  \n",
       "987             0       1  \n",
       "661             0       1  \n",
       "4615            1       1  \n",
       "...           ...     ...  \n",
       "4165            1       1  \n",
       "1567            0       1  \n",
       "4304            0       1  \n",
       "1460            0       1  \n",
       "2528            1       1  \n",
       "\n",
       "[1743 rows x 9 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta = pd.DataFrame({\n",
    "    'banker': banker_preds[:,0],\n",
    "    'spyware': spyware_preds[:,0],\n",
    "    'backdoor': backdoor_preds[:,0], \n",
    "    'ransomware': ransomware_preds[:,0],\n",
    "    'pua': pua_preds[:,0],\n",
    "    'downloader': downloader_preds[:,0],\n",
    "    'deceptor': deceptor_preds[:,0],\n",
    "    'cryptominer': cryptominer_preds[:,0],\n",
    "    'Target': y_test\n",
    "})\n",
    "df_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd7bafc",
   "metadata": {},
   "source": [
    "### Max voting as meta learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "75680978",
   "metadata": {},
   "outputs": [],
   "source": [
    "voted_predictions = df_meta.iloc[:, :-1].mode(axis=1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "166bf859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6586345381526104\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(df_meta['Target'], voted_predictions)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "30ff154d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "55/55 [==============================] - 1s 4ms/step - loss: 0.4597 - accuracy: 0.8623\n",
      "Epoch 2/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2862 - accuracy: 0.8778\n",
      "Epoch 3/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2662 - accuracy: 0.8801\n",
      "Epoch 4/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2504 - accuracy: 0.9116\n",
      "Epoch 5/100\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.2390 - accuracy: 0.9220\n",
      "Epoch 6/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2429 - accuracy: 0.9225\n",
      "Epoch 7/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2312 - accuracy: 0.9225\n",
      "Epoch 8/100\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.2290 - accuracy: 0.9225\n",
      "Epoch 9/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2225 - accuracy: 0.9237\n",
      "Epoch 10/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.2252 - accuracy: 0.9237\n",
      "Epoch 11/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.2213 - accuracy: 0.9231\n",
      "Epoch 12/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.2268 - accuracy: 0.9237\n",
      "Epoch 13/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2168 - accuracy: 0.9237\n",
      "Epoch 14/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.2178 - accuracy: 0.9237\n",
      "Epoch 15/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2188 - accuracy: 0.9237\n",
      "Epoch 16/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2175 - accuracy: 0.9237\n",
      "Epoch 17/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2169 - accuracy: 0.9237\n",
      "Epoch 18/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2198 - accuracy: 0.9237\n",
      "Epoch 19/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2149 - accuracy: 0.9237\n",
      "Epoch 20/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2159 - accuracy: 0.9225\n",
      "Epoch 21/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2153 - accuracy: 0.9237\n",
      "Epoch 22/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2124 - accuracy: 0.9243\n",
      "Epoch 23/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2220 - accuracy: 0.9237\n",
      "Epoch 24/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2155 - accuracy: 0.9237\n",
      "Epoch 25/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2198 - accuracy: 0.9237\n",
      "Epoch 26/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2146 - accuracy: 0.9243\n",
      "Epoch 27/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2129 - accuracy: 0.9237\n",
      "Epoch 28/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2145 - accuracy: 0.9237\n",
      "Epoch 29/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2144 - accuracy: 0.9231\n",
      "Epoch 30/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2104 - accuracy: 0.9243\n",
      "Epoch 31/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2160 - accuracy: 0.9231\n",
      "Epoch 32/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2118 - accuracy: 0.9237\n",
      "Epoch 33/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.2114 - accuracy: 0.9243\n",
      "Epoch 34/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2124 - accuracy: 0.9243\n",
      "Epoch 35/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2149 - accuracy: 0.9237\n",
      "Epoch 36/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2144 - accuracy: 0.9243\n",
      "Epoch 37/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2101 - accuracy: 0.9243\n",
      "Epoch 38/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2154 - accuracy: 0.9237\n",
      "Epoch 39/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2115 - accuracy: 0.9243\n",
      "Epoch 40/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.2129 - accuracy: 0.9237\n",
      "Epoch 41/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2111 - accuracy: 0.9243\n",
      "Epoch 42/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2122 - accuracy: 0.9243\n",
      "Epoch 43/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2129 - accuracy: 0.9243\n",
      "Epoch 44/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.2156 - accuracy: 0.9243\n",
      "Epoch 45/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2126 - accuracy: 0.9243\n",
      "Epoch 46/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2147 - accuracy: 0.9243\n",
      "Epoch 47/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2097 - accuracy: 0.9243\n",
      "Epoch 48/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2106 - accuracy: 0.9243\n",
      "Epoch 49/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2093 - accuracy: 0.9243\n",
      "Epoch 50/100\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.2081 - accuracy: 0.9243\n",
      "Epoch 51/100\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.2093 - accuracy: 0.9243\n",
      "Epoch 52/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9243\n",
      "Epoch 53/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2067 - accuracy: 0.9243\n",
      "Epoch 54/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2103 - accuracy: 0.9243\n",
      "Epoch 55/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.2117 - accuracy: 0.9243\n",
      "Epoch 56/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2066 - accuracy: 0.9243\n",
      "Epoch 57/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.2103 - accuracy: 0.9243\n",
      "Epoch 58/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2125 - accuracy: 0.9243\n",
      "Epoch 59/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2075 - accuracy: 0.9243\n",
      "Epoch 60/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2072 - accuracy: 0.9243\n",
      "Epoch 61/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2095 - accuracy: 0.9243\n",
      "Epoch 62/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.2095 - accuracy: 0.9231\n",
      "Epoch 63/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.2080 - accuracy: 0.9243\n",
      "Epoch 64/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2116 - accuracy: 0.9248\n",
      "Epoch 65/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2109 - accuracy: 0.9248\n",
      "Epoch 66/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2095 - accuracy: 0.9237\n",
      "Epoch 67/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2091 - accuracy: 0.9243\n",
      "Epoch 68/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2101 - accuracy: 0.9243\n",
      "Epoch 69/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2047 - accuracy: 0.9248\n",
      "Epoch 70/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2072 - accuracy: 0.9237\n",
      "Epoch 71/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2061 - accuracy: 0.9248\n",
      "Epoch 72/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2076 - accuracy: 0.9248\n",
      "Epoch 73/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2044 - accuracy: 0.9243\n",
      "Epoch 74/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2103 - accuracy: 0.9237\n",
      "Epoch 75/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.2098 - accuracy: 0.9248\n",
      "Epoch 76/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2037 - accuracy: 0.9248\n",
      "Epoch 77/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2061 - accuracy: 0.9243\n",
      "Epoch 78/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2080 - accuracy: 0.9248\n",
      "Epoch 79/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2082 - accuracy: 0.9243\n",
      "Epoch 80/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2070 - accuracy: 0.9237\n",
      "Epoch 81/100\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.2053 - accuracy: 0.9248\n",
      "Epoch 82/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2067 - accuracy: 0.9243\n",
      "Epoch 83/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9248\n",
      "Epoch 84/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2056 - accuracy: 0.9243\n",
      "Epoch 85/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2049 - accuracy: 0.9248\n",
      "Epoch 86/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2095 - accuracy: 0.9248\n",
      "Epoch 87/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9243\n",
      "Epoch 88/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2040 - accuracy: 0.9243\n",
      "Epoch 89/100\n",
      "55/55 [==============================] - 0s 7ms/step - loss: 0.2040 - accuracy: 0.9248\n",
      "Epoch 90/100\n",
      "55/55 [==============================] - 0s 8ms/step - loss: 0.2065 - accuracy: 0.9248\n",
      "Epoch 91/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2103 - accuracy: 0.9248\n",
      "Epoch 92/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2070 - accuracy: 0.9248\n",
      "Epoch 93/100\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.2080 - accuracy: 0.9248\n",
      "Epoch 94/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2077 - accuracy: 0.9248\n",
      "Epoch 95/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2070 - accuracy: 0.9248\n",
      "Epoch 96/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2069 - accuracy: 0.9243\n",
      "Epoch 97/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2045 - accuracy: 0.9248\n",
      "Epoch 98/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2060 - accuracy: 0.9248\n",
      "Epoch 99/100\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.2057 - accuracy: 0.9248\n",
      "Epoch 100/100\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.2056 - accuracy: 0.9248\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.2018 - accuracy: 0.9248\n",
      "Accuracy: 0.9248422384262085\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# Assuming you have an input DataFrame called 'input_df' with 8+1 columns,\n",
    "# where the first 8 columns are predictions from base learners and the last column is the target variable.\n",
    "\n",
    "# Split the input data into features (X) and target variable (y)\n",
    "X = df_meta.iloc[:, :-1]  # Features (predictions from base learners)\n",
    "y = df_meta.iloc[:, -1]   # Target variable\n",
    "\n",
    "# Convert the features and target variable to NumPy arrays\n",
    "X = X.values\n",
    "y = y.values\n",
    "\n",
    "# Define the dimensions of the input and output layers\n",
    "input_dim = X.shape[1]\n",
    "output_dim = 1\n",
    "\n",
    "# Build the meta-learner model\n",
    "model = Sequential()\n",
    "model.add(Dense(40, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(output_dim, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the meta-learner model\n",
    "model.fit(X, y, epochs=100, batch_size=32)\n",
    "\n",
    "# Evaluate the performance of the meta-learner model on the training data\n",
    "loss, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
